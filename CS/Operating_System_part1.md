# 운영체제 개요

- 운영체제(OS, Operating System)
  - 정의
    - 사용자가 보다 편리하게 컴퓨터를 조작할 수 있도록 인터페이스를 제공하고, 컴퓨터 시스템의 자원을 효율적으로 관리하기 위한 소프트웨어.
  - 펌웨어(Firmware)
    - 운영체제 역시 일종의 소프트웨어이다.
    - 또한 하드웨어를 조정하고 관리하는 역할을 하는 운영체제의 특성 상 하드웨어의 도움 없이 작동하기 어렵다. 
    - 따라서 운영체제를 부를 때 소프트웨어와 하드웨어를 결합한 형태인 펌웨어라고 부르기도 한다.
  - 임베디드 운영체제(Embeded operating system, 임베디드 시스템)
    - CPU의 성능이 낮고 메모리 크기도 작은 시스템에 내장하도록 만든 운영체제.
    - 일반 운영체제에 비해 몇 가지 기능이 빠져있다.
    - 임베디드 운영체제를 사용하는 기계와 그렇지 않은 기계는 많은 차이가 있다.
    - 예를 들어 임베디드 운영체제가 없는 유선전화는 통화 외에 다른 기능을 추가할 수 없는 반면, 운영체제를 사용하는 스마트폰은 응용 프로그램인 앱을 설치하여 게임을 하거나 내비게이션 등으로 사용할 수 있다.



- 운영체제의 목표
  - 효율성
    - 운영체제의 목표는 자원을 효율적으로 관리하는 것이다.
    - 적은 자원을 사용하여 더 많은 작업량을 처리하거나, 같은 작업량을 처리하는 데 보다 적은 자원을 사용해야 한다는 의미이다.
  - 안정성
    - 운영체제는 하드웨어 전체를 관리하는 소프트웨어이므로 운영체제가 불안정하면 모든 작업이 불안정할 수 밖에 없다.
    - 따라서 운영체제는 안정적으로 자원을 보호하고, 자원을 관리해야한다.
  - 확장성
    - 다양한 시스템 자원을 추가하거나 제거하기 편리해야한다.
    - 운영체제는 하드웨어의 종류에 상관없이 연결하면 바로 실행할 수 있는 플러그 앤 플레이(Plug & Play) 기능을 제공해야한다.
  - 편리성
    - 사용자가 편리하게 작업할 수 있는 환경을 제공해야한다.
    - 응용 프로그램과 사용자에게 대양한 편리성을 제공하면서도 자원의 낭비는 막아야한다.



- 운영체제의 필요성
  - 컴퓨터는 운영체제 없이도 작동한다.
    - 초기의 컴퓨터는 정해진 계산만 수행했기에 특별한 사용 규칙이 필요없었다.
  - 그러나 메모리, CPU의 성능이 향상되고, 여러 작업을 동시에 할 수 있는 컴퓨팅 환경이 조성되면서 사용 규칙이 필요해졌다.
  - 복잡한 작업 환경에 규칙이 없으면 기계를 망가뜨릴 수도 있기 때문에 등장한 것이 운영체제이다.



- 운영체제의 역할
  - 운영체제는 컴퓨터 자원(computer resource)을 관리한다.
    - 컴퓨터에 부착된 모든 장치를 컴퓨터 자원이라한다.
    - 운영체제는 컴퓨터에서 사용하는 자원을 관리(resource management)하는 역할을 수행한다.
    - 컴퓨터에서 여러 응용 프로그램(application program)을 동시에 실행할 경우 각 응용프로그램은 컴퓨터 자원을 독차지하려고 한다.
    - 운영체제는 이러한 응용 프로그램들 사이에서 컴퓨터 자원을 적절하게 분배하는 역할을 한다.
    - 예를 들어 채팅 프로그램과 문서 작성 프로그램은 둘 다 키보드와 모니터라는 공통의 컴퓨터 자원을 필요로 한다.
    - 이 때 운영체제는 누구에게 먼저 키보드의 제어권을 주어야할지, 누구에게 모니터의 제어권을 주어야 할지 등을 결정한다.
  - 사용자와 하드웨어 사이의 중계자 역할을 한다.
    - 운영체제는 사용자가 컴퓨터 자원에 직접 접근하는 것을 막는다.
    - 예를 들어 사용자가 하드디스크의 특정 위치에 데이터를 저장하려 한다고 생각해보자.
    - 사용자는 하드디스크의 특정 위치에 데이터를 저장할 수 없으며, 운영체제에게 데이터의 저장을 요청하면 운영체제가 하드디스크의 적절한 위치에 데이터를 저장한다.
    - 이처럼 운영체제는 사용자와 하드웨어 사이의 중계자 역할을 함으로써 컴퓨터 자원을 보호하고 관리한다.
  - 하드웨어 인터페이스를 제공한다.
    - 하드웨어 장치와 상호작용하기 위해 만들어진 응용 프로그램을 드라이버(장치 드라이버, 디바이스 드라이버, 소프트웨어 드라이버 등으로도 부른다)라고 부른다. 
    - 일반적으로 드라이버는 운영체제를 설치할 때 자동으로 설치되지만, 일부 하드웨어의 경우 따로 설치해야 하는데, 이렇게 따로 설치해야하는 드라이버를 하드웨어 인터페이스라 부른다.  
    - 운영체제는 일관된 하드웨어 인터페이스를 제공함으로써 하드웨어가 변경되더라도, 사용자가 일관된 방식으로 컴퓨터를 사용할 수 있게 해준다.
  - 운영체제를 통해 새로운 기능의 추가나 성능의 향상이 가능하다.
    - 운영체제가 없는 기계는 기능을 추가하거나 성능을 향상시키기 위해선 기계 자체를 변경시켜야한다.
    - 그러나 운영체제가 있을 경우, 많은 경우 기계 자체를 변경시키지 않고도 운영체제를 통해 기능의 추가와 성능의 향상이 가능하다.



- 컴퓨팅 환경의 역사
  - 초창기 컴퓨터(1940년대)
    - 최초의 컴퓨터는 미사일 탄도를 계산하기 위해 제작된 에니악으로 18,000개 가량의 백열전구 모양의 진공관을 조합하여 제작된 30톤 큐모의 거대한 계산기였으며, 운영체제는 없었다.
    - 사용하여 진공관이 켜지면 1, 꺼지면 0이 되는 방식으로 계산이 이루어졌는데, 이는 컴퓨터가 2진법을 사용하는 계기가 되었다.
    - 각 진공관을 전선으로 연결하는 방식으로 프로그래밍이 이루어졌는데, 이렇게 전선을 연결하여 논리회로를 구성하는 것을 하드 와이어링 방식이라고 한다.
    - 하드 와이어링은 전선으로 논리회로를 구성하여 원하는 결과만 얻는 방식이므로 다른 계산이나 수식을 사용하려면 전선을 다시 연결해야 했다. 
  - 일괄 작업 시스템(1950년대)
    - 초창기 컴퓨터는 기술 발전을 거쳐 IC(integrated Circuit)라는 칩으로 만들어졌다.
    - 진공관과 전선으로 만들어진 논리회로를 아주 작은 크기로 구현한 것으로, 현대적인 모습의 컴퓨터가 탄생했다.
    - 카드에 구멍을 뚫어 문자나 숫자를 표현하고, 이 카드를 읽는 천공카드 리더를 입력장치로, 문자를 한 번에 한 줄씩 출력하는 라인 프린터를 출력장치로 사용했다.
    - 이를 통해 현재의 프로그래밍과 유사한 방식으로 다양한 소프트웨어를 개발할 수 있게 되었다.
    - 하드 와이어링은 다른 작업을 하려면 전선을 일일이 다시 연결해야 가능했지만, 천공 카드 리더를 사용하면, 천공카드만 바꾸면 다른 작업이 가능했다.
    - 현재와는 달리 작업에 필요한 프로그램과 데이터를 한꺼번에 입력해야 작업이 가능했는데, 이처럼 모든 작업을 한꺼번에 처리해야 하고 프로그램 실행 중간에 사용자가 데이터를 입력하거나 수정하는 것이 불가능한 시스템을 일괄 작업 시스템(batch job system) 혹은 일괄 처리 시스템(batch processing system)이라 부른다.
    - 일괄 작업 시스템은 작기는 하지만 운영체제가 사용되었기에 현재까지도 그 흔적이 남아있는데, 대표적으로 `.bat` 파일은 batch job을 의미한다.
  - 대화형 시스템(1960년대 초반)
    - 1960년대 초반에 키보드와 모니터가 등장했는데, 이로 인해 비효율적이었던 일괄 작업 시스템 방식이 획기적으로 변화되었다.
    - 키보드와 모니터가 개발됨으로써 프로그램 실행 중에 중간 결과값을 확인할 수 있게 되었고, 중간에 데이터를 입력할 수 있게 되었다.
    - 프로그램이 실행되는 도중에 사용자로부터 입력을 받아 입력값에 따라 작업의 흐름을 바꾸는 것도 가능했는데, 이 모습이 사용자와 컴퓨터 간의 대화를 통해 이루어지는 것 같다 하여 대화형 시스템(interactive system)이라고 부른다.
    - 단, 중간에 입출력 될 일이 없어 작업 시간을 예측하기 쉬웠던 일괄 작업 시스템과 달리, 대화형 시스템의 경우 중간에 어떤 값이 입력되는지에 따라 작업 시간이 달라지기에 작업 시간을 예측하기도 어렵다는 문제가 있었다.
  - 시분할 시스템(1960년대 후반)
    - 1960년 후반에 컴퓨터의 크기가 작아지고 계산 능력이 향상이 이루어졌다.
    - 향상된 컴퓨터의 성능을 보다 효율적으로 사용하기 위해서 다중 프로그래밍(multiprogramming) 기술이 개발되었다.
    - 다중 프로그래밍은 하나의 CPU로 여러 작업을 동시에 실행하는 기술로, 한 번에 하나의 작업만 가능한 일괄 작업 시스템에 비해서 효율이 뛰어났다.
    - 실제로 여러 작업이 동시에 실행되는 것은 아니고 CPU 사용 시간을 잘게 쪼개에 여러 작업들에 나눠주고, 각 작업들이 매우 짦은 간격으로 돌아가면서 CPU를 사용하는 방식이었는데, 그 간격이 매우 짧아 마치 동시에 실행되는 것 처럼 보이는 것이다.
    - 이처럼 여러 작업을 조금씩 처리하여 작업이 동시에 이루어지는 것처럼 보이게 하는 것을 시분할 시스템(time sharing system, 혹은 multitasking)이라 부르며, 오늘날 대부분의 컴퓨터에서 사용된다.
    - 이 때 잘게 나뉜 시간 한 조각을 time slice 혹은 time quantum이라 부르고, 시분할 시스템에서 동시에 실행되는 작업의 개수를 멀티 프로그래밍 수준(level of multoprogramming) 혹은 멀티 프로그래밍 정도(multiprogramming degree)라 부른다.
    - 시분할 시스템을 통해 여러 사용자가 하나의 컴퓨터에서 작업하는 다중 사용자 시스템이 가능해졌다.
    - 시분할 시스템의 단점은 여러 작업을 동시에 처리하기 위한 추가 작업이 필요하다는 것이다.
    - 또한 시스템 내에 많은 양의 작업이 있을 경우, 특정 작업이 일정 시간 내에 끝날 것을 보장하지 못한다.
  - 분산 시스템(1970년대 후반)
    - 스티브 잡스가 최초의 개인용 컴퓨터인 애플Ⅱ를 발표했으며, 이후 개인용 컴퓨터가 이전보다 널리 보급되기 시작한다.
    - 또한 소프트웨어도 급속도로 발전하여 개인용 컴퓨터 운영체제로 애플의 매킨토시와 MS의 MS-DOS등이 등장했다.
    - 인터넷이 등장한 것도 이 시기이다.
    - 개인용 컴퓨터의 보급과 인터넷의 등장으로 값이 싸고 크기가 작은 컴퓨터들을 하나로 묶어 대형 컴퓨터에 버금가는 시스템을 만들게 되었는데, 이를 분산 시스템이라 부른다.
    - 분산 시스템은 네트워크상에 분산되어 있는 여러 컴퓨터로 작업을 처리하고 그 결과를 상호 교환하도록 구성한 시스템이다.
  - 클라이언트/서버 시스템(1990년대 ~ 현재)
    - 분산 시스템은 시스템에 참가하는 모든 컴퓨터가 동일한 지위를 가지기에 새로운 컴퓨터가 추가되거나 기존 컴퓨터가 제거되면 작업을 분배하고 결과를 모으기 쉽지 않다.
    - 클라이언트/서버 시스템은 이러한 문제를 해결하기 위한 기술로, 모든 컴퓨터의 지위가 동일한 분산 시스템과 달리 요청하는 클라이언트와 응답하는 서버의 이중 구조로 구성된다.
    - 서버가 과부화 될 수 있다는 문제가 있다.
  - P2P 시스템(2000년대 초반 ~ 현재)
    - 서버를 거치지 않고 사용자와 사용자를 직접 연결하는 시스템으로, 서버의 과부하 문제를 해결하기 위해 등장했다.
    - 메신저, 파일 공유 등에 널리 쓰인다.



## 운영체제의 구조

- 커널과 인터페이스
  - 운영체제는 크게 커널과 인터페이스로 구성된다.
  - 커널(Kernel)
    - 프로세스 관리, 메모리 관리, 저장장치 관리와 같은 운영체제의 핵심적인 기능을 모아놓은 것이다.
    - 운영체제의 성능은 커널이 좌우한다.
  - 인터페이스
    - 인터페이스는 사용자의 명령을 커널에 전달하고 실행 결과를 사용자에게 전달하는 역할을 한다.
    - 커널과 인터페이스가 분리되어 있으므로 같은 커널이라도 다른 인터페이스를 사용할 수 있다.
    - 예를 들어 유닉스의 사용자 인터페이스은 shell은 Cshell(csh), Tshell(tsh), bash 등 여러 종류의 shell이 있다.



- 시스템 호출(System Call)과 드라이버(Driver)
  - 시스템 호출
    - 커널이 제공하는 시스템 관련 서비스를 모아놓은 것으로, 함수 형태로 제공된다.
    - 커널이 자신을 보호하기 위해 만든 인터페이스로, 사용자나 응용 프로그램으로부터 컴퓨터 자원을 보호하기 위해 자원에 직접 접근하는 것을 차단한다.
    - 따라서 자원을 이용하려면 시스템 호출이라는 인터페이스를 이용하여 접근해야한다.

  - 시스템 호출을 통한 접근의 이점
    - 사용자가 컴퓨터 자원에 직접 접근할 경우 사용자가 모든 것을 처리해야한다.
    - 따라서 사용자가 잘못된 방식으로 컴퓨터 자원에 접근할 경우 컴퓨터 자원에 이상이 생길 수 있다.
    - 반면에 시스템 호출을 통해 접근할 경우 커널을 통해 시스템 자원에 접근하므로 이러한 위험이 줄어들게 된다.

  - 드라이버
    - 커널과 응용 프로그램 사이의 인터페이스가 시스템 호출이라면, 커널과 하드웨어의 인터페이스가 드라이버이다.
    - 운영체제가 많은 하드웨어를 다 사용할 수 있는 환경을 제공하려면 각 하드웨어에 맞는 프로그램을 직접 개발해야하지만, 커널이 모든 하드웨어에 맞는 인터페이스를 다 개발하기는 어렵다.
    - 따라서 커널은 입출력의 기본적인 부분만 제작하고, 하드웨어의 특성을 반영한 소프트웨어를 하드웨어에 대해서 가장 잘 아는 하드웨어를 제작한 사람에게 전달받아 커널이 실행될 때 함께 실행되도록 한다.
    - 여기서 하드웨어를 제작자가 만든 소프트웨어를 드라이버라한다.
    - 물론 마우스, 키보드 같은 간단한 하드웨어를 위한 드라이버의 경우 커널에 포함되어 있는 경우도 있다.
  - API와 SDK
    - API(Application Programming Interface)란 응용 프로그램이 자신과 연관된 프로그램을 만들 수 있도록 제공하는 인터페이스이다.
    - SDK(Software Developer's Kit)는 프로그램 개발자를 위해 API 및 API 용 메뉴얼뿐만 아니라 개발에 필요한 코드 편집기와 에뮬레이터 같은 각종 개발용 응용 프로그램까지 하나로 묶어서 배포하는 개발 툴이다.




- 커널의 구성

  - 커널의 주요 역할

  | 역할                                                   | 설명                                                         |
  | ------------------------------------------------------ | ------------------------------------------------------------ |
  | 프로세스 관리                                          | 프로세스에 CPU를 배분하고, 작업에 필요한 제반 환경을 제공한다. |
  | 메모리 관리                                            | 프로세스에 작업 공간을 배치하고 실제 메모리보다 큰 가상공간을 제공한다. |
  | 파일 시스템 관리                                       | 데이터를 저장하고 접근할 수 있는 인터페이스를 제공한다.      |
  | 입출력 관리                                            | 필요한 입력과 출력 서비스를 제공한다.                        |
  | 프로세스간 통신(IPC, Inter-Process Communication) 관리 | 공동 작업을 위해 각 프로세스 간 통신 환경을 지원한다.        |

  - 커널의 종류
    - 커널의 주요 기능들을 어떻게 구현하는가에 따라 아래와 같이 나뉜다.
    - 단일형 구조 커널
    - 계층형 구조 커널
    - 마이크로 구조 커널
  - 단일형 구조 커널(Monolithic Architecture Kernel)
    - 초창기의 운영체제 구조로 커널의 핵심 기능을 구현하는 모듈들이 구분 없이 하나로 구성되어 있다.
    - 모듈이 거의 분리되지 않았기 때문에 모듈 간의 통신 비용이 줄어 효율적인 운영이 가능하다는 장점이 있지만, 아래와 같은 단점들이 있다.
    - 버그나 오류를 처리하기 힘들다.
    - 상호 의존성이 높아 기능상의 작은 결함이 시스템 전체로 확산될 수 있다.
    - 수정이 어렵기에 다양한 환경의 시스템에 적용하기 어렵다.
    - 현대의 크고 복잡한 운영체제를 구현하기에는 부적절하다.
    - MS-DOS, VMS, 초기의 유닉스 등이 이에 해당한다.
  - 계층형 구조 커널(Layered Archtecture Kernel)
    - 단일형 구조 커널이 발전된 형태로, 비슷한 기능을 가진 모듈을 묶어서 하나의 계층으로 만들고 계층 간의 통신을 통해 운영체제를 구현하는 방식이다.
    - 비슷한 기능을 모아 모듈화했기 때문에 단일형 구조보다 버그나 오류를 쉽게 처리할 수 있다.
    - 오류가 발생했을 때 해당 계층만 수정하면 되기에 디버깅도 쉽다.
    - Windows를 비롯한 오늘날 대부분의 운영체제는 이 구조로 개발되었다.
  - 마이크로 구조 커널(Micro Architecture Kernel)
    - 하드웨어의 다양화, 이에 따른 운영체제의 기능 추가에 따라 계층형 커널 구조에  점차 새로운 계층이 추가됐다.
    - 이에 따라 커널의 크기도 지속적으로 증가하고 소스도 방대해져 오류를 잡기가 점점 힘들어졌다.
    - 이러한 한계를 극복하기 위해 등장한 것이 마이크로 구조 커널이다.
    - 마이크로 구조 커널의 운영체제는 프로세스 관리, 메모리 관리, IPC 관리 등의 가장 기본적인 기능만 제공하고, 운영체제의 많은 부분이 사용자 영역에 구현되어 있다.
    - 각 모듈이 독립적으로 작동하고, IPC 모듈로 각 모듈 사이의 통신이 이루어지므로, 하나의 모듈이 실패하더라도 전체 운영체제가 멈추지 않는다.
    - 애플의 OS X와 iOS가 사용하는 마하(Mach)가 이 구조를 사용한다.



- 가상머신
  - 초기의 응용 프로그램은 일반적으로 운영체제에 종속적이었다.
    - 예를 들어 유닉스에서 개발한 응용 프로그램은 Windows에서는 동작하지 않았다.
  - 따라서 각 운영체제별로 응용프로그램을 따로 제작해야했다.
  - 이러한 호환성 문제를 해결한 것이 바로 가상머신이다.
    - 가상머신은 운영체제와 응용 프로그램 사이에서 동작하는 프로그램으로, 응용 프로그램이 운영체제와 독립적으로 실행되도록 해준다.
    - JVM이 대표적인 예이다.



- Unix의 간략한 역사
  - 유닉스(Unix)
    - 1969년, AT&T의 연구원인 켄 톰프슨(Ken Tompson), 데니스 리치(Dennis Ritchie), 피터 뉴만(Peter Neumann)은 어셈블리어를 사용하여 프로그램을 실행하는 데에만 중점을 둔 단순한 운영체제를 개발했다.
    - 단순함을 강조하기 위해 유닉스라는 이름을 붙였다.
    - 데니스 리치는 B언어에서 출발한 C 언어를 고안했다.
    - C 언어는 어셈블리어로 번역하기 쉬워 많은 컴퓨터에 이식할 수 있었다.
    - 1973년 어셈블리어로 개발된 유닉스를 C 언어로 다시 제작했고, 다른 기계로 이식이 쉬웠던 C 언어 특성 덕에 많은 인기를 끌게 되었다.
    - 또한 유닉스는 소스코드가 공개되어 계속 다른 기종의 컴퓨터로 이식되며 여러 기업과 연구 기관에서 이를 이용한 연구가 거듭되며 발전해나갔다.
  - BSD(Berkeley Software Distribution) Unix
    - 1970년대 말 캘리포니아 대학의 버클리 캠퍼스에서 빌 조이(Bill Joy)와 척 헤일리(Chuck Haley)라는 학생이 소스코드를 조금 수정한 유닉스를 BSD라는 이름으로 발표했다.
    - 기존 AT&T 유닉스와는 달리 다중 작업과 네트워킹 기능이 추가되어 큰 인기를 끌었다.
    - AT&T는 이에 위협을 느껴 USG(Unix Support Group)을 설립하고 자신의 유닉스를 AT&T System V라고 명명했다.
    - 이때부터 유닉스는 크게 System V 계열과 BSD 계열로 나뉘게 되었다.
  - GNU(GNU is Not Unix)
    - 리터드 스톨먼(Richard Stallman)이 창설한 프로젝트로, 소프트웨어를 돈 주고 사지 말고 누구나 자유롭게 실행, 복사, 수정, 배포할 수 있게 하자는 프로젝트이다.
    - 이러한 정신에 입각해서 만든 소프트웨어에 주어진 라이선스를 GPL(General Public Licence)라고 부른다.
    - GPL은 copyright의 반대 개념으로 copyleft를 내세웠다.
  - Linux
    - 1991년 리누스 토르발스(Linus Torvalds)가 PC에서 동작하는 유닉스 호환 커널의 작성하여 GPL로 배포하고, 소스코드도 공개했다.
    - 이것이 바로 리눅스이다.





# 컴퓨터의 구조

## 컴퓨터의 기본 구성

- 하드웨어의 구성

  - 컴퓨터는 중앙처리장치(CPU), 메인메모리, 입력장치, 출력장치, 저장장치로 구성된다.
    - 컴퓨터로 하는 작업의 대부분은 중앙처리장치와 메인메모리의 협업으로 이루어지기에 중앙처리장치와 메인메모리는 필수 장치로 분류된다.
    - 그 외의 부품은 주변장치라 부른다.
  - CPU
    - 명령어를 해석하여 실행하는 장치.
  - 메인 메모리
    - 메모리의 경우 전력이 끊기면 데이터를 잃어버리기에 데이터를 영구히 보관하려면 하드디스크나 USB 메모리를 사용해야한다.
    - 따라서 메인메모리를 제1저장장치(first storage), 하드 디스크 혹은 USB 메모리를 제2저장장치(second storage)라 부른다.
  - 입출력장치
    - 외부의 데이터를 컴퓨터에 입력하고, 컴퓨터에서 처리한 결과를 사용자가 원하는 형태로 출력하는 장치이다.

  - 저장장치
    - 메인 메모리와 달리 데이터를 영구적으로 저장하는 장치이다.
    - 메모리보다 느리지만 저렴하고 용량이 크다.
  - 메인보드
    - 컴퓨터의 다양한 부품은 버스로 연결된다.
    - 실제 세상의 버스와 마찬가지로 컴퓨터의 버스도 일정한 규칙에 따러 각 장치에 데이터를 전송하는 역할을 한다.
    - 메인보드는 다양한 부품을 연결하는 커다란 판이다.



- 폰노이만 구조(von Neumann achitecture)
  - 폰 노이만 구조는 CPU, 메모리 입출력장치, 저장장치가 버스로 연결되어 있는 구조를 말한다.
    - 폰 노이만 구조가 등장하기 이전의 컴퓨터는 전선을 연결하여 회로를 구성하는 하드와이어링 형태였기에 다른 용도로 사용하여면 전선을 바꿔야했다.
    - 존 폰 노이만(John von Neumann)은 이를 해결하기 위해 메모리를 이용하여 프로그래밍이 가능한 구조를 제안했다.
    - 하드웨어는 그대로 두고 실행할 프로그램만 교체하여 메모리에 올리는 방식이었다.
  - 폰노이만 구조에서 가장 중요한 점은 모든 프로그램은 메모리에 올라와야 실행할 수 있다는 것이다.



- 하드웨어 사양 관련 용어
  - 클록(clock)
    - CPU의 속도오 관련된 단위.
    - CPU가 작업을 실행할 때 일정한 박자가 있는데, 이 박자를 만들어내는 것이 클록이다.
    - 클록이 일정 간격으로 tick을 만들면 거기에 맞추어 CPU안의 모든 구성 부품이 작업을 한다.
    - 틱은 펄스(pulse) 혹은 clock tick이라고도 부른다.
    - 메인보드의 클록이 틱을 보낼 때 마다 버스를 통해 데이터를 보내거나 받는다.
  - 헤르츠(Hz)
    - 클록틱이 발생하는 속도를 나타내는 단위이다.
    - 1초에 클록틱이 몇 번 발생하는지를 나타낼 때 1초에 클록틱이 한 번 발생하면 1Hz와 같은 식이다.
    - 예를 들어 1kHz(==1000Hz)이면 초당 1천 번의 데이터 이동이 가능하다는 의미이다.
  - 시스템 버스와 CPU 내부 버스
    - 시스템 버스는 메모리와 주변장치를 연결하는 버스로 FSB(Front-Side Bus)라고 부른다.
    - CPU 내부 버스는 CPU 내부에 있는 장치를 연결하는 버스로 BSB(Back Side Bus)라고 부른다.
    - CPU 내부 버스의 속도는 CPU의 클록과 같아서 시스템 버스보다 훨씬 빠르다.
    - CPU는 BSB의 속도로 작동하고, 메모리는 FSB의 속도로 작동하기에 두 버스의 속도 차이로 인해 작업이 지연되는 문제가 있다.







## CPU와 메모리

- CPU의 구성
  - 아래와 같은 장치들의 협업으로 작업이 이루어진다.
  - 산술논리 연산장치(Arithmetic and Logic Unit, ALU)
    - CPU에서 데이터를 연산하는 장치
    - 덧셈, 뺄셈, 곱셈, 나눗셈과 같은 산술 연산과 and, or과 같은 논리 연산을 수행한다.
  - 제어장치(Cotrol Unit)
    - CPU에서 작업을 지시하는 장치이다.
  - 레지스터(Register)
    - CPU 내에 데이터를 임시로 보관하는 곳이다.



- 물리 코어(physical core)와 논리 코어(logical core)

  - 물리 코어는 하드웨어 적으로 CPU 내부에 존재하는 실행 유닛이다.
    - 자체적인 산술논리 연산 장치(ALU), register, 뒤에서 살펴볼 L1 캐시 등을 가지고 있다.
    - 물리 코어의 개수에 따라 멀티 코어, 쿼드 코어, 헥사 코어, 옥타 코어, 데카 코어 등으로 부른다.
  - 논리 코어는 OS 입장에서 보이는 실행 가능한 코어의 개수를 의미한다.
    - SMT(Simultaneous Multi-Threading) 기술을 통해 하나의 물리 코어가 둘 이상의 논리 코어로 분리되어 보이게 할 수 있는데, 이렇게 분리된 각각의 코어를 논리 코어라고 부른다.
    - 각 논리 코어는 독립적인 컨텍스트를 갖고, OS로부터 스케줄링 단위로 취급된다.
  - 따라서 CPU core의 개수는 사용되는 맥락에 따라 달라질 수 있다.
    - 하드웨어의 스펙에 따라 이야기 할 때는 물리 코어의 개수를 의미한다.
    - OS 관점에서 이야기 할 때는 논리 코어의 개수를 의미한다.
  - SMT(Simultaneous Multi-Threading)
    - 하나의 물리 코어에서 여러 스레드를 동시에 실행할 수 있도록 하여 CPU 자원을 더 효율적으로 사용하는 기술이다.
    - CPU의 파이프라인, ALU, FPU 같은 하드웨어 자원을 정적으로 분할하지 않고 공유한다.
    - Hyper-Threading 은 Intel이 구현한 SMT의 구현체이며, AMD 등의 다른 CPU 벤더들은 SMT라고 부르기도 한다.
    - Intel이 처음 개발한 기술이기에 hyper-threading이라고 부르기도 한다.
  - CPU core의 개수 확인하기
    - Linux에서는 아래와 같이 확인이 가능하다.

  ```bash
  $ lscpu
  ```

  - `lscpu`의 결과중 CPU 코어를 확인하기 위해 봐야 하는 결과들은 아래와 같다.
    - `CPU(s)`: 논리 코어의 개수
    - `Sockets(s)`: 물리 CPU 소켓의 개수
    - `Core(s) per Socket`: 물리 CPU의 물리 코어 개수
    - `Thread(s) per core`: CPU 물리 코어 하나 당 논리 코어의 개수
    - 주의할 점은 서버에 따라 `Socket(s)`의 값이 2라고 해서 2개의 소켓에 모두 CPU가 장착되어 있다는 것은 아닐 수도 있다는 점이다.



- CPU의 명령어 처리 과정

  - C언어로 작성된 아래와 같은 짧은 코드가 있을 때, CPU는 어떻게 아래 코드를 처리하는가.

  ```c
  int D2=2, D3=3, sum;
  sum=D2+D3
  ```

  - 위에서 작성된 코드는 어셈블리어로 변환된 뒤 게계어로 변환되어 CPU에 의해 실행된다.
    - 우선 선언된 변수들이 메모리에 저장된다.
    - 제어장치는 레지스터에게 신호를 보내 레지스터가 메모리에 저장된 변수들을 읽어와서 레지스터에 저장하도록 한다.
    - 제어장치는 산술논리 연산장치에게 신호를 보내 덧셈을 수행하게 하며, 이 값은 다시 레지스터에 저장된다.
    - 제어장치는 레지스터에게 신호를 보내 결과값을 메모리에 옮겨놓도록 한다.



- 레지스터의 종류

  - 데이터 레지스터(Data Register, DR)

    - 메모리에서 가져온 데이터를 임시로 보관할 때 사용한다.
    - CPU에 있는 대부분의 레지스터가 데이터 레지스터이기 때문에 일반 레지스터 또는 범용 레지스터라고 부른다.

  - 주소 레지스터(Address Register, AR)

    - 데이터 또는 명령어가 저장된 메모리의 주소는 주소 레지스터에 저장된다.

  - 특수 레지스터

    - 데이터 레지스터와 주소 레지스터 외에 특별한 용도로 사용되는 레지스터들로, 사용자가 임의로 변경할 수 없기에 사용자 불가 레지스터(User-Invisible Register)라고 부른다.
    - 프로그램 카운터(Program Counter, PC)는 다음에 실행할 명령어의 주소를 기억하고 있다가 제어장치에 알려주는 역할을 하는데, 이 때문에 명령어 포인터(instruction pointer)라고도 부른다.

    - 명령어 레지스터(Instruction Register, IR)은 현재 실행중인 명령어를 저장하며, 제어장치는 명령어 레지스터에 있는 명령을 해석하여 적절한 제어 신호를 보낸다.
    - 메모리 주소 레지스터(Memory Address Register, MAR)는 메모리에서 데이터를 가져오거나 반대로 메모리로 데이터를 보낼 때 주소를 지정하기위해 사용한다.
    - 메모리 버퍼 레지스터(Memory Buffer Register, MBR)는 메모리에서 가져온 데이터나 메모리로 옮겨 갈 데이터를 임시로 저장하며, 항상 메모리 주소 레지스터와 함께 동작한다.
    - 프로그램 상태 레지스터(Program Status Register, PSR)는 산술논리 연산장치와 관련이 있으며, 연산 결과가 양수인지 음수인지, 0인지 아닌지, 자리 올림 여부 등을 저장한다.



- 버스의 종류
  - 버스는 CPU와 메모리, 주변장치 간에 데이터를 주고받을 때 사용하며, 아래와 같은 종류가 있다.
  - 제어 버스(Control Bus)
    - 다음에 어떤 작업을 할지 지시하는 제어 신호가 오고 간다.
    - 제어버스는 CPU의 제어장치와 연결되어 있다.
    - CPU, 메모리, 주변장치와 양방향으로 오고 간다.
  - 주소 버스(Address Bus)
    - 메모리의 데이터를 읽거나 쓸 때 어느 위치에서 작업할 것인지를 알려주는 주소가 오고 간다.
    - 주변 장치의 경우도 마찬가지로, 하드디스크의 어느 위치에서 데이터를 읽어올지, 어느 위치에 저장할지에 대한 정보가 주소 버스를 통해 전달된다.
    - 메모리 주소 레지스터와 단방향으로 연결되어 있다.
    - 즉 CPU에서 메모리나 주변장치로 나가는 주소 정보는 있지만 주소 버스를 통해 CPU로 전달되는 정보는 없다.
  - 데이터 버스(Data Bus)
    - 제어 버스가 어떤 작업을 할지 신호를 보내고, 주소 버스가 위치 정보를 전달하면 데이터가 데이터 버스에 실려 목적지까지 이동한다.
    - 메모리 버퍼 레지스터와 연결되어 있으며 양방향이다.



- 메모리의 종류
  - RAM과 ROM으로 구분된다.
    - RAM(Random Access Memory): 읽기와 쓰기가 모두 가능한 메모리.
    - ROM(Read Only Memory): 읽기만 가능한 메모리
    - ROM은 RAM과 달리 전력이 끊겨도 데이터를 보관할 수 있지만, 한 번 저장하면 바꿀 수 없다는 단점이 있다.
  - 휘발성 메모리(Volatility memory)
    - 전력이 끊기면 데이터가 사라지는 휘발성 메모리.
    - DRAM(Dynamic RAM)과 SRAM(Static RAM)이 있다.
    - DRAM은 저장된 데이터가 일정 시간이 지나면 사라지므로, 일정 시간마다 다시 재생시켜한다.
    - SRAM은 전력이 공급되는 동안에는 데이터를 보관할 수 있어 재생할 필요가 없으므로 속도가 빠르지만 가격이 빘다ㅏ.
    - 일반적으로 메인메모리에는 DRAM을 사용하고, 캐시 같은 고속 메모리에는 SRAM을 사용한다.
    - SDRAM(Synchronous Dynamic Random Access Memory)은 DRAM이 발전된 형태로, 클록틱(펄스)이 발생할 때마다 데이터를 저장하는 동기 DRAM이다.
  - 비휘발성 메모리(Non-volatility memory)
    - 플래시 메모리(flash memory), FRAM(Ferroelectric RAM), PRAM(Phase change RAM) 등이 있다.
    - 이 중 플래시 메모리는 디지털카메라, MP3, USB 드라이버 같이 전력 없이도 데이터를 보관하는 저장장치로 많이 사용된다.
    - 그러나 플래시 메모리의 각 소자는 사용 횟수가 제한되어 보통 소자 하나당 몇 천번에서 만 번 정도 사용하면 기능을 잃게 된다.
    - 하드디스크를 대체하도록 만든 SSD도 비휘발성 메모리이다. 



- 메모리 보호
  - 일괄 작업 시스템에서는 메모리가 운영체제 영역과 사용자 영역으로 구분된다.
    - 운영체제는 시분할 기법을 사용하여 여러 프로그램을 동시에 실행하므로 사용자 영역이 여러 개의 작업 공간으로 나뉘어 있다.
  - 일괄 작업 시스템에서 메모리 보호는 사용자 영역의 작업이 운영체제 영역으로 침범하지 못하도록 막는 것이다.
    - 메모리가 보호되지 않으면 어떤 작업이 다른 작업의 영역을 침범하여 프로그램을 파괴하거나 데이터를 지울 수도 있으며 최악의 경우 운영체제 영역을 침범하여 시스템이 멈출 수도 있다.
    - 이처럼 운영체제 영역이나 다른 프로그램 영역으로 침범하려는 악성 소프트웨어를 바이러스라고한다.
  - 사용자의 작업이 진행되는 동안안에는 운영체제의 작업이 잠시 중단된다.
    - 운영체제도 CPU를 사용하는 소프트웨어이기 때문이다.
    - 운영체제의 작업이 중단된 상태에서 사용자의 작업으로부터 메모리를 보호하려면 하드웨어의 도움이 필요하다.
  - 메모리 보호 방법
    - CPU는 현재 진행 중인 작업의 메모리 시작 주소를 경계 레지스터(bound register)에 저장한 후 작업을 한다.
    - 또한 현재 진행중인 작업이 차지하고 있는 메모리의 크기, 즉 현재 진행 중인 작업의 메모리 시작 주소부터 마지막 주소까지의 차이를 한계 레지스터(limit register)에 저장한다.
    - 그리고 사용자의 작업이 진행되는 동안 이 두 레지스터의 주소 범위를 벗어나는지 하드웨어적으로 점검함으로써 메모리를 보호한다.
    - CPU는 작업이 경계 레지스터와 한계 레지스터의 주소값 안에서 이루어지는지 검사한다.
    - 만약 두 레지스터의 값을 벗어난다면 메모리 오류와 관련된 인터럽트가 발생한다.
    - 인터럽트가 발생하면 모든 작업이 중단되고 CPU는 운영체제를 깨워서 인터럽트를 처리하도록 시킨다.
    - 메모리 영역을 벗어나서 발생한 인터럽트의 경우 운영체제가 해당 프로그램을 강제 종료시킨다.
    - 이처럼 모든 메모리 영역은 하드웨어와 운영체제의 협업에 의해 보호받는다.



- 부팅(Booting)
  - 부팅이란
    - 응용프로그램은 운영체제가 메모리에 올려서 실행하는데, 그렇다면 운영체제는 누가 메모리에 올려서 실행할까?
    - 운영체제도 CPU에 의해 실행되는 프로그램이게에 메모리에 올라가야한다.
    - 따라서 컴퓨터를 켰을 때 누군가가 운영체제를 메모리에 올려서 실행해야한다.
    - 컴퓨터를 켰을 때 운영체제를 메모리에 올리는 과정을 부팅이라한다.
  - 부팅 과정
    - 사용자가 컴퓨터의 전원을 키면 롬에 저장된 바이오스가 실행된다.
    - 바이오스는 CPU, 메모리, 하드디스크, 키보드 와 같은 주요 하드웨어가 정상적으로 작동하는지 확인한다.
    - 만약 이상이 있으면 비프음과 함께 오류 메시지를 출력한다.
    - 이상이 없으면 하드디스크의 마스터 부트 레코드(Master Boot Record, MBR)에 저장된 부트스트랩이라 불리는 작은 프로그램을 메모리로 가져와 실행한다.
    - 부트스트랩이 메모리에 올라와 부트스트랩 코드를 실행하면 하드디스크에 저장된 운영체제가 메모리로 올라온다. 
  - MBR
    - 하드디스크의 첫 번째 섹터를 가리키며, 운영체제를 실행하기 위한 코드인 부트스트랩이 이곳에 저장되어 있다.
    - 부트스트랩 코드는 운영체제를 메모리로 가져와 실행하는 역할을 하는 작은 프로그램이다.
    - 예를 들어 유닉스용 부트스트랩이 실행되면 유닉스 운영체제가 메모리에 올라오고, 윈도우용 부트스트랩이 실행되면 윈도우 운영체제가 메모리에 올라온다.
    - USB 드라이버에도 MBR을 탑재할 수 있다.





### Cache 상세

> https://parksb.github.io/article/29.html

- Principle of Locality
  - 자주 사용하는 데이터에 대한 판단은 지역성의 원리를 따른다.
  - 시간 지역성(Temporal Locality)
    - 최근 접근한 데이터에 다시 접근하는 경향을 의미한다.
  - 공간 지역성(Spatial Locality)
    - 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 말한다.



- L1~L3 cache
  - L1 cache
    - 프로세서(CPU)와 가장 가까운 캐시.
    - 속도를 위해 I\$와 D$로 나눈다(cache가 현금을 뜻하는 cash와 발음이 동일해서 달러 기호로 표기한다).
    - Instruction cache(I$)는 메모리의 text영역 데이터를 다룬다.
    - Data cache(D$)는 text영역을 제외한 모든 데이터를 다룬다.
  - L2 cache
    - 용량이 큰 캐시.
    - 용량이 큰 것이 중요하므로 L1 cache처럼 따로 나누지는 않는다.
  - L3 cache
    - 멀티 코어 시스템에서 여러 코어가 공유하는 캐시



- Cache의 성능 측정 지표

  - Hit latency

    - Hit가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다.

  - Miss latency

    - Miss가 발생해서 상위 cache에서 데이터를 가져오거나(L1에서 찾을 수 없어서 L2에서 가져오는 경우 등) 메모리에서 데이터를 가져올 때 소요되는 시간을 의미한다.

  - Average access time

    - 평균 접근 시간은 `hit latency + miss rate * miss latency`으로 구한다.

    - 이 중 miss rate은 `cache misses/cache accesses`로 구한다.

  - 캐시의 성능을 높이는 방법 

    - 캐시의 크기를 줄여 히트 레이턴시를 줄인다.
    - 캐시의 크기를 늘려 미스 비율을 줄인다. 
    - 더 빠른 캐시를 이용해 레이턴시를 줄인다.



- Cache의 구조
  - 캐시는 반응 속도가 빠른 SRAM(Static Ramdom Access Memory)이다.
    - 주소가 키로 주어지면 해당 공간에 즉시 접근할 수 있다.
    - DRAM(Dynamic Random Access Memory)도 마찬가지지만, 하드웨어 설계상 DRAM은 SRAM보다 느리다.
    - 통상적으로 메인 메모리라고 할 때는 DRAM을 의미한다.
  - 주소가 키로 주어졌을 때 그 공간에 즉시 접근할 수 있기에, cache는 하드웨어로 구현한 해시 테이블과 같다.
    - 캐시가 빠른 이유는 자주 사용하는 데이터만을 담아두기 때문이기도 히지만 해시 테이블과 같이 동작하여 시간 복잡도가 O(1)로 매우 빠르기 때문이다.



- Indexing
  - Cache는 주소값 전체를 키로 사용하지는 않고, 일부만을 사용한다. 
  - 예시 
    - 블록 개수가 1024개이고, 블록 사이즈가 32bytes일 때, 32bit 주소가 주어진다면 전체 주소에서 하위 5bit를 ,offset으로 쓰고, 이후 10bit를 인덱스로 사용하여 블록에 접근한다.
    - 인덱스가 10bits인 이유는 2<sup>n</sup>개의 블록의 모든 인덱스를 표현하기 위해서는 log<sub>2</sub>num_blocks만큼의 bits가 필요하기 때문이다.
    - 여기선 블록 개수가 1024(2<sup>10</sup>)개이므로, log<sub>2</sub>1024 = 10이 되어 10bit를 인덱스로 사용한다.
  - 그러나 이렇게만 하면 서로 다른 데이터의 인덱스가 중복될 위험이 크다.



- Tag Matching

  - 인덱스의 충돌을 줄이기 위해 주소값의 일부를 태그로 사용한다.

  - Tag matching 과정

    - 예를 들어 블록 개수가 1024개이고, 블록 사이즈가 32 bytes일 때, 32bit 주소 0x000c14B8에 접근하려 한다고 가정해보자.
    - 태그 비트의 크기는 `Address bits - (logBlock Size + Index bits)`로 결정된다.

    - 먼저 인덱스 0x000c14B8에 대응하는 태그 배열의 필드에 접근한다.

    - 해당 태그 필드의 유효 비트를 확인한다(유효 비트가 1이라는 것은 해당 블록에 올바른 값이 존재한다는 의미이다.).

    - 유효 비트가 1이라면 태그 필드와 주소의 태그가 같은지 비교한다.

    - 비교 결과(같으면 1, 다르면 0)를 유효 비트와 AND 연산한다.

    - 만약 유효 비트가 1이고 태그 필드와 주소의 태그가 같다면 hit가 발생하고, hit가 발생하면 데이터 배열에서 해당 인덱스의 데이터를 참조한다.

    - 만약 유효 비트가 0이라면 블록에 값이 없거나 올바르지 않다는 뜻이므로 미스가 발생한다.

  - Miss가 발생하는 경우

    - 주소의 태그를 태그 필드에 작성하고, 데이터 필드에도 상위 캐시나 메모리에서 요청한 값을 가져와 작성한 뒤 유효 비트를 1로 바꿔준다.

    - 유효 비트가 1이라도 태그가 일치하지 않으면 미스가 발생한다.
    - 이 경우 교체 정책에 따라 처리가 달리진다.
    - 만약 먼저 입력된 데이터가 먼저 교체되는 FIFO 정책을 사용한다면 무조건 기존 블록을 교체한다.
    - 태그 배열의 필드를 주소의 태그로 바꾸고, 상위 캐시나 메모리에서 요청한 데이터를 가져(실제로는 요청한 데이터뿐 아니라 그 주변 데이터까지 가져온다)와 필드의 값도 새 데이터로 바꿔주고, 기존 데이터는 상위 캐시로 밀려난다.



- Tag Overhead
  - 태그 배열이 추가되면서 더 많은 공간이 필요하게 된다.
    - 하지만 여전히 32KB cache는 32KB 데이터를 저장할 수 있는 캐시라는 의미이다.
    - 태그를 위한 공간은 블록 크기와 상관 없는 오버헤드로 취급하기 때문이다.
  - 1024개의 32B 블록으로 구성된 32KB 캐시의 태그 오버헤드는 아래와 같이 구한다.
    - 17bit tag + 1bit valid = 18bit
    - 18bit * 1024 = 18Kb tags = 2.25KB
    - 7%의 태그 오버헤드가 발생한다.
  - 공간뿐 아니라 시간 비용도 발생한다.
    - 태그 배열에 접근해 hit를 확인하고, 기 이후에 데이터 배열에 접근해 데이터를 가져오기 때문에 결과적으로 hit latency가 증가하게 된다.
    - 따라서 태그 배열에서 히트 여부를 확인하는 과정과 데이터 배열에 접근하는 과정을 병렬적으로 접근한다.
    - 즉 태그 배열에서 히트 여부를 확인하는 동시에 미리 데이터 배열에 접근한다.
    - 이를 통해 hit latency는 감소하지만, miss가 발생할 경우 리소스의 낭비를 감수해야한다.



- Associative Cache

  - 서로 다른 두 주소가 같은 인덱스를 가지면 충돌이 발생하고, 교체 정책에 따라 블록을 교체한다.
    - 충돌이 발생할 때 마다 캐시 내용을 변경하면 더 많은 미스가 발생하게 되고, 한 자리의 내용을 끝없이 바꾸는 핑퐁 문제(Ping-pong problem)가 발생할 수 있다.
  - 이 문제는 태그 배열과 데이터 배열을 여러 개 만드는 방식으로 개선할 수 있다.
    - 즉 인덱스가 가리키는 블록이 여러 개가 되는 것이다.

  - 인덱스가 가리키는 블록의 개수에 따라 캐시의 종류를 분류하면 아래와 같다.
    - Direct mapped: 인덱스가 가리키는 공간이 하나인 경우로 처리가 빠르지만 충돌이 잦다.
    - Fully associative: 인덱스가 모든 공간을 가리키는 경우로 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느리다.
    - Set associative(n-way associative): 인덱스가 가리키는 공간이 두 개 이상인 경우.
  - 보통 장단점이 극단적인 direct mapped나 fully associative 대신에 set associative를 사용한다.







## 컴퓨터 성능 향상 기술

- 하드웨어별로 작업 속도가 다르다.
  - CPU, 메모리, 주변장치의 작업 속도가 각기 다르다.
    - 메인보드 내 메모리와 주변 장치는 시스텀 버스로 연결되어 있어 메모리의 속도는 시스템 버스의 속도와 같고, CPU 내 레지스터, 산술논리 연산 장치, 제어장치는 CPU 내부 버스로 연결되어 있어, CPU의 속도는 CPU 내부 버스의 속도와 같다.
    - CPU 내부 버스의 속도가 시스템 버스의 속도보다 빠르기 때문에 메모리를 비롯한 주변 장치의 속도가 CPU의 속도를 따라가지 못한다.
  - 이러한 장치간 속도 차이를 개선하고, 시스템의 작업 속도를 올리기 위해 다양한 기술이 개발되었다.



- 버퍼(Buffer)

  - 속도에 차이가 있는 두 장치 사이에서 그 차이를 완화하는 역할을 한다.

    - 예를 들어 입출력 장치에서 데이터를 가져오는 경우를 생각해보자.
    - 느린 입출력장치에서 데이터를 읽을 때마다 하나씩 전송하면 작업량에 비헤 실제로 전송되는 데이터의 양이 매우 작지만, 일정랴의 데이터를 모아 한꺼번에 전송하면 적은 노력으로도 많은 양의 데이터를 옮길 수 있다.
    - 이렇게 일정량의 데이터를 모아 옮김으로써 속도의 차이를 완화하는 장치가 버퍼이다.

  - 버퍼는 소프트웨어적으로도 사용되는 개념이다.

    - 한 예로 스트리밍 서비스가 있다.
    - 동영상을 시청할 때 네트워크에서 데이터가 들어오는 시간과 플레이어가 재생되는 시간의 속도 차이가 발생하기도 하는데, 플레이어가 재생되는 도중에 데이터가 도착하지 않으면 동영상이 끊기게 될 것이다.
    - 이런 현상을 방지하기 위해 동영상의 일정 부분을 버퍼에 넣은 후 실행한다.

  - 스풀(SPOOL, Simultaneous Peripheral Operation On-Line)

    - CPU와 입출력장치가 독립적으로 동작하도록 고안된 소프트웨어적인 버퍼이다.
    - 대표적인 예로 프린터에 사용되는 스풀러가 있다.
    - 스풀러는 인쇄할 내용을 순차적으로 출력하는 소프트웨어로, 출력 명령을 내린 프로그램과 독립적으로 동작한다.
    - 워드프로세서로 작업하고 프린터로 출력하는 상황에서 스풀러가 없다면 인쇄가 끝날 때 까지 워드프로세러를 사용할 수 없을 것이다.

    - 버퍼의 일종이지만, 버퍼의 경우 모든 프로그램이 버퍼를 공유하며 어떤 프로그램이 사용하는 데이터든 버퍼가 차면 이동이 시작되는 반면에, 스풀러는 한 인쇄물이 완료될 때 까지 다른 인쇄물이 끼어들 수 없으므로 프로그램 간에 배타적이다.



- 캐시(Cache)

  - 메모리와 CPU 간의 속도 차이를 완화하기 위해 메모리의 데이터를 미리 가져와 저장해두는 임시 장소이다.
    - 필요한 데이터를 모아 한꺼번에 전달하는 버퍼의 일종으로 CPU가 앞으로 사용할 것으로 예상되는 데이터를 메모리로부터 미리 가져다놓는다.
    - 이렇게 미리 가져오는 작업을 prefetch라한다.
    - CPU의 칩 안에 들어가는 작고 빠른 메모리이다.
    - 오늘날 CPU 칩의 면적 30~70%는 캐시가 차지한다.
  - 캐시는 CPU 내부에 있으며 CPU 내부 버스의 속도로 작동한다.
    - 메모리의 경우 시스템 버스의 속도로 작동하기 때문에 느리지만, 캐시는 빠른 속도로 작동하는 CPU와 느린 속도로 작동하는 메모리 사이에서 두 장치의 속도 차이를 완화해준다.
  - Cache hit
    - 캐시는 메모리의 내용 중 일부를 미리 가져오고, CPU는 메모리에 접근해야 할 때 캐시를 먼저 방문하여 원하는 데이터가 있는지 찾아본다.
    - 캐시에서 원하는 데이터를 찾은 경우를 cache hit라 한다.
    - 만약 캐시에서 원하는 데이터를 찾지 못 한 경우 메모리로 가서 데이터를 찾는데, 이를 cache miss라 한다.
    - Cache hit가 되는 비율을 cache hit ratio라하며, 일반적인 컴퓨터의 경우 90% 정도 된다.
  - Cache hit ratio를 높이는 방법
    - 컴퓨터의 성능을 향상시키기 위해선 cache hit ratio가 높아야한다.
    - Cache hit ratio를 높이는 방법 중 하나는 캐시의 크기를 늘리는 것인데, 캐시는 가격이 비싸기 때문에 크기를 늘리는 데 한계가 있어 일반적으로 몇 메가바이트 정도만 사용한다.
    - 다른 방법으로는 앞으로 많이 사용될 데이터를 가져오는 방법이 있다.
    - 이와 관련된 이론으로 현재 위치에 가까운 데이터가 멀리 있는 데이터보다 사용될 확륭이 더 높다는 지역성 이론이 있다.
  - 즉시 쓰기와 지연 쓰기
    - 만일 캐시로 가져온 데이터에 변경이 발생한 경우 어떻게 해야할까?
    - 데이터에 변경이 생겼으므로, 당연히 메모리에도 반영을 해줘야 하는데, 두 가지 반영 방식이 있다.
    - 즉시 쓰기는 캐시에 있는 데이터가 변경될 경우 이를 즉시 메모리에 반영하는 방식으로, 메모리로 데이터를 빈번하게 전송해야 해서 성능이 저하될 수 있다는 단점이 있지만, 메모리의 값을 항상 최산값으로 유지할 수 있다는 장점이 있다.
    - 반면에 지연 쓰기는 캐시에 있는 데이터가 변경되면 즉시 메모리에 반영하지 않고, 변경된 내용을 모아서 주기적으로 반영하는 방식으로, 장단점은 즉시 쓰기의 반대이다.

  - L1(Level 1)캐시와 L2(Level2)캐시
    - 프로그램의 명령어는 크게 어떤 작업을 할지 나타내는 명령어 부분과 작업 대상인 데이터 부분으로 나눌 수 있다.
    - 캐시는 명령어와 데이터의 구분 없이 모든 자료를 가져오는 일반 캐시와, 명령어와 데이터를 구분하여 가져오는 특수 캐시라는 두 가지 레벨로 구분된다.
    - 명령어 캐시나 데이터 캐시는 CPU 레지스터에 직접 연결되기 때문에 L1캐시라고 부르며, 일반 캐시는 메모리와 연결되기 때문에 L2 캐시라고 부른다.
    - 메모리와 연결된 L2 캐시가 메모리로부터 데이터를 가져온 뒤, 이를 명령어와 데이터로 구분하여 L1 캐시에 속한 명령어 캐시와 데이터 캐시로 보낸다.
    - 명령어 캐시는 CPU의 명령어 레지스터와 연결되어 있고, 데이터 캐시는 CPU의 데이터 레지스터에 연결되어 있다.
  - 캐시 역시 소프트웨어적으로도 사용된다.
    - 대표적인 예시가 웹 브라우저의 캐시이다.
    - 웹 브라우저는 앞으로 다시 방문할 것을 예상하여 지우지 않은 데이터를 저장하고 있다.



- Principle of Locality
  - 자주 사용하는 데이터에 대한 판단은 지역성의 원리를 따른다.
  - 시간 지역성(Temporal Locality)
    - 최근 접근한 데이터에 다시 접근하는 경향을 의미한다.
  - 공간 지역성(Spatial Locality)
    - 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 말한다.



- L1~L3 cache
  - L1 cache
    - 프로세서(CPU)와 가장 가까운 캐시.
    - 속도를 위해 I\$와 D$로 나눈다(cache가 현금을 뜻하는 cash와 발음이 동일해서 달러 기호로 표기한다).
    - Instruction cache(I$)는 메모리의 text영역 데이터를 다룬다.
    - Data cache(D$)는 text영역을 제외한 모든 데이터를 다룬다.
  - L2 cache
    - 용량이 큰 캐시.
    - 용량이 큰 것이 중요하므로 L1 cache처럼 따로 나누지는 않는다.
  - L3 cache
    - 멀티 코어 시스템에서 여러 코어가 공유하는 캐시



- Cache의 성능 측정 지표

  - Hit latency

    - Hit가 발생해 캐싱된 데이터를 가져올 때 소요되는 시간을 의미한다.

  - Miss latency

    - Miss가 발생해서 상위 cache에서 데이터를 가져오거나(L1에서 찾을 수 없어서 L2에서 가져오는 경우 등) 메모리에서 데이터를 가져올 때 소요되는 시간을 의미한다.

  - Average access time

    - 평균 접근 시간은 `hit latency + miss rate * miss latency`으로 구한다.

    - 이 중 miss rate은 `cache misses/cache accesses`로 구한다.

  - 캐시의 성능을 높이는 방법 

    - 캐시의 크기를 줄여 히트 레이턴시를 줄인다.
    - 캐시의 크기를 늘려 미스 비율을 줄인다. 
    - 더 빠른 캐시를 이용해 레이턴시를 줄인다.



- Cache의 구조
  - 캐시는 반응 속도가 빠른 SRAM(Static Ramdom Access Memory)이다.
    - 주소가 키로 주어지면 해당 공간에 즉시 접근할 수 있다.
    - DRAM(Dynamic Random Access Memory)도 마찬가지지만, 하드웨어 설계상 DRAM은 SRAM보다 느리다.
    - 통상적으로 메인 메모리라고 할 때는 DRAM을 의미한다.
  - 주소가 키로 주어졌을 때 그 공간에 즉시 접근할 수 있기에, cache는 하드웨어로 구현한 해시 테이블과 같다.
    - 캐시가 빠른 이유는 자주 사용하는 데이터만을 담아두기 때문이기도 히지만 해시 테이블과 같이 동작하여 시간 복잡도가 O(1)로 매우 빠르기 때문이다.



- Indexing
  - Cache는 주소값 전체를 키로 사용하지는 않고, 일부만을 사용한다. 
  - 예시 
    - 블록 개수가 1024개이고, 블록 사이즈가 32bytes일 때, 32bit 주소가 주어진다면 전체 주소에서 하위 5bit를 ,offset으로 쓰고, 이후 10bit를 인덱스로 사용하여 블록에 접근한다.
    - 인덱스가 10bits인 이유는 2<sup>n</sup>개의 블록의 모든 인덱스를 표현하기 위해서는 log<sub>2</sub>num_blocks만큼의 bits가 필요하기 때문이다.
    - 여기선 블록 개수가 1024(2<sup>10</sup>)개이므로, log<sub>2</sub>1024 = 10이 되어 10bit를 인덱스로 사용한다.
  - 그러나 이렇게만 하면 서로 다른 데이터의 인덱스가 중복될 위험이 크다.



- Tag Matching

  - 인덱스의 충돌을 줄이기 위해 주소값의 일부를 태그로 사용한다.

  - Tag matching 과정

    - 예를 들어 블록 개수가 1024개이고, 블록 사이즈가 32 bytes일 때, 32bit 주소 0x000c14B8에 접근하려 한다고 가정해보자.
    - 태그 비트의 크기는 `Address bits - (logBlock Size + Index bits)`로 결정된다.

    - 먼저 인덱스 0x000c14B8에 대응하는 태그 배열의 필드에 접근한다.

    - 해당 태그 필드의 유효 비트를 확인한다(유효 비트가 1이라는 것은 해당 블록에 올바른 값이 존재한다는 의미이다.).

    - 유효 비트가 1이라면 태그 필드와 주소의 태그가 같은지 비교한다.

    - 비교 결과(같으면 1, 다르면 0)를 유효 비트와 AND 연산한다.

    - 만약 유효 비트가 1이고 태그 필드와 주소의 태그가 같다면 hit가 발생하고, hit가 발생하면 데이터 배열에서 해당 인덱스의 데이터를 참조한다.

    - 만약 유효 비트가 0이라면 블록에 값이 없거나 올바르지 않다는 뜻이므로 미스가 발생한다.

  - Miss가 발생하는 경우

    - 주소의 태그를 태그 필드에 작성하고, 데이터 필드에도 상위 캐시나 메모리에서 요청한 값을 가져와 작성한 뒤 유효 비트를 1로 바꿔준다.

    - 유효 비트가 1이라도 태그가 일치하지 않으면 미스가 발생한다.
    - 이 경우 교체 정책에 따라 처리가 달리진다.
    - 만약 먼저 입력된 데이터가 먼저 교체되는 FIFO 정책을 사용한다면 무조건 기존 블록을 교체한다.
    - 태그 배열의 필드를 주소의 태그로 바꾸고, 상위 캐시나 메모리에서 요청한 데이터를 가져(실제로는 요청한 데이터뿐 아니라 그 주변 데이터까지 가져온다)와 필드의 값도 새 데이터로 바꿔주고, 기존 데이터는 상위 캐시로 밀려난다.



- Tag Overhead
  - 태그 배열이 추가되면서 더 많은 공간이 필요하게 된다.
    - 하지만 여전히 32KB cache는 32KB 데이터를 저장할 수 있는 캐시라는 의미이다.
    - 태그를 위한 공간은 블록 크기와 상관 없는 오버헤드로 취급하기 때문이다.
  - 1024개의 32B 블록으로 구성된 32KB 캐시의 태그 오버헤드는 아래와 같이 구한다.
    - 17bit tag + 1bit valid = 18bit
    - 18bit * 1024 = 18Kb tags = 2.25KB
    - 7%의 태그 오버헤드가 발생한다.
  - 공간뿐 아니라 시간 비용도 발생한다.
    - 태그 배열에 접근해 hit를 확인하고, 기 이후에 데이터 배열에 접근해 데이터를 가져오기 때문에 결과적으로 hit latency가 증가하게 된다.
    - 따라서 태그 배열에서 히트 여부를 확인하는 과정과 데이터 배열에 접근하는 과정을 병렬적으로 접근한다.
    - 즉 태그 배열에서 히트 여부를 확인하는 동시에 미리 데이터 배열에 접근한다.
    - 이를 통해 hit latency는 감소하지만, miss가 발생할 경우 리소스의 낭비를 감수해야한다.



- Associative Cache

  - 서로 다른 두 주소가 같은 인덱스를 가지면 충돌이 발생하고, 교체 정책에 따라 블록을 교체한다.
    - 충돌이 발생할 때 마다 캐시 내용을 변경하면 더 많은 미스가 발생하게 되고, 한 자리의 내용을 끝없이 바꾸는 핑퐁 문제(Ping-pong problem)가 발생할 수 있다.
  - 이 문제는 태그 배열과 데이터 배열을 여러 개 만드는 방식으로 개선할 수 있다.
    - 즉 인덱스가 가리키는 블록이 여러 개가 되는 것이다.

  - 인덱스가 가리키는 블록의 개수에 따라 캐시의 종류를 분류하면 아래와 같다.
    - Direct mapped: 인덱스가 가리키는 공간이 하나인 경우로 처리가 빠르지만 충돌이 잦다.
    - Fully associative: 인덱스가 모든 공간을 가리키는 경우로 충돌이 적지만 모든 블록을 탐색해야 해서 속도가 느리다.
    - Set associative(n-way associative): 인덱스가 가리키는 공간이 두 개 이상인 경우.
  - 보통 장단점이 극단적인 direct mapped나 fully associative 대신에 set associative를 사용한다.







- 저장 장치의 계층 구조(Storage hierarchy)
  - 컴퓨터의 하드웨어는 성능에 비례해 가격이 올라간다.
    - 따라서 가격과 컴퓨터 성능 사이의 타협점으로 저장장치 계층 구조가 존재한다.
  - 저장장치의 계층 구조는 속도가 빠르고 값이 비싼 저장장치를 CPU와 가까운 쪽에 두고, 값이 싸고 용량이 큰 저장장치를 반대쪽에 배치하여 적당한 가격으로 빠른 속도와 큰 용량을 동시에 얻는 방법이다.
    - 예를 들어 CPU와 가까운 쪽에 속도가 빠른 레지스터나 캐시를 배치하여 CPU가 작업을 빨리 진행할 수 있도록 한다.
    - 또한 메모리에서 작업한 내용을 하드디스크와 같이 용랼이 큰 저장장치에 영구적으로 저장할 수 있게 하기위해서 메모리와 저장장치를 가까운 쪽에 배치한다.



- 인터럽트
  - Polling 방식
    - 초기의 컴퓨터 시스템에는 주변장치가 많지 않았다.
    - 이 때는 CPU가 직접 입출력장치에서 데이터를 가져오거나 보냈는데 이러한 방식을 폴링 방식이라고한다.
    - CPU가 입출력장치의 상태를 주기적으로 검사하여 일정한 조건을 만족할 때 데이터를 처리한다.
    - CPU가 명령어 해석과 실행이라는 본래 역할 외에 모든 입출력까지 관여해야 하므로 작업 효율이 떨어진다.
  - 인터럽트(interrupt) 방식
    - 오늘날의 컴퓨터에는 많은 주변장치가 있기에 CPU가 모든 입출력에 관여하면 작업 효율이 현저하게 떨어진다.
    - 이러한 문제를 해결하기 위해 등장한 것이 인터럽트 방식이다.
    - CPU의 작업과 저장장치의 데이터 이동을 독립적으로 운영함으로써 시스템의 효율을 높인다.
    - 즉 데이터의 입출력이 이루어지는 동안 CPU가 다른 작업을 할 수 있다.
  - 인터럽트 방식의 동작 과정
    - 입출력이 필요할 때 CPU가 입출력 관리자에게 입출력 명령을 보낸다.
    - 입출력 관리자는 명령 받은 데이터를 메모리에 가져다놓거나 메모리에 있는 데이터를 저장장치로 옮긴다.
    - 데이터 전송이 완료되면 입출력 관리자는 완료 신호를 CPU에 보낸다.
    - 입출력 관리자가 CPU에 보내는 완료 신호를 인터럽트라고 한다.
    - CPU는 입출력 관리자에게 작업 지시를 내리고 다른 일을 하다가 완료 신호를 받으면 하던 일을 중단하고 옮겨진 데이터를 처리한다.
    - 이처럼 하던 작업을 중단하고 처리해야 하는 신호라는 의미에서 인터럽트라고 불리게 되었다.
  - 인터럽트 번호(Interrupt number)
    - 수 많은 주변장치 중 어떤 것의 작업이 끝났는지를 CPU에 알려주기 위해 인터럽트 번호를 사용한다.
    - 인터럽트 번호는 완료 신호를 보낼 때 장치의 이름 대신 사용하는 장치의 고유 번호로서 운영체제마다 다르다.
    - 윈도우의 경우 IRQ(Interrupt ReQuest)라고 부른다.
  - 인터럽트 백터(Interrupt vector)
    - CPU 관리자는 입출력 관리자에게 여러 개의 입출력 작업을 동시에 시킬 수 있다.
    - 이 경우 여러 작업이 동시에 완료되고 그때마다 인터럽트를 여러 번 사용해야 하는데 이는 매우 비효율적이다.
    - 따라서 여러 개의 인터럽트를 하나의 배열로 만든 인터럽트 백터를 사용한다.
    - CPU가 인터럽트 벡터를 받으면 인터럽트 백터상에 기록된 작업들을 동시에 처리한다.
  - 입출력 작업이 완료되었음을 CPU에게 알리는 인터럽트 외에도 다양한 종류의 인터럽트가 있다.
    - 사용자가 컴퓨터의 전원 버튼을 눌러 강제로 종료하면 CPU는 하던 일을 모두 멈추고 처리 중인 데이터를 안전하게 보관한 뒤 시스템을 종료해야한다.
    - 또한 메모리에서 실행중인 어떤 작업이 자신에게 주어진 메모리 영역을 넘어서 작업을 하려 해도 인터럽트가 발생한다.



- DMA(Direct Memory Access)
  - 입출력 관리자의 권한 문제
    - 입출력이 필요할 때 CPU는 입출력 관리자에게 입출력 요청을 보낸다.
    - 명령을 받은 입출력 관리자는 CPU가 요청한 데이터를 메모리에 가져다놓아야 한다.
    - 문제는, 메모리는 CPU만 접근 권한을 가진 작업 공간이라 입출력 관리자는 접근이 불가능하다는 것이다.
    - 따라서 입출력 관리자에게는 CPU의 허락 없이 메모리에 접근할 수 있는 권한이 필요하다.
  - 직접 메모리 접근(DMA)
    - 입출력 관리자가 CPU의 허락 없이 메모리에 접근할 수 있는 권한을 의미한다.
    - 입출력 관리자는 이를 통해 CPU의 관여 없이 작업을 완료할 수 있다.
  - 메모리 매핑 입출력(MMIO, Memory Mapped I/O)
    - DMA는 인터럽트 방식의 시스템을 구성하는데 필수적이지만, 이를 사용하면 메모리가 복잡해진다.
    - 메모리에는 CPU가 사용하는 데이터와 입출력 장치가 사용하는 데이터가 섞여 있다.
    - DMA를 통해 들어온 데이터를 메모리에 아무렇게나 둔다면 CPU가 사용하는 데이터와 섞여서 관리하기가 어려워진다.
    - 이를 해결하기 위해 CPU가 사용하는 메모리 공간과 DMA를 통해 들어오거나 나가는 데이터를 위한 공간을 분리한다.
    - 이처럼 메모리의 일정 공간을 입출력에 할당하는 기법을 매핑 입출력이라 한다.
  - 사이클 훔치기(Cycle stealing)
    - CPU와 DMA가 동시에 메모리에 접근하려 할 경우 누군가는 양보를 해야 한다.
    - 보통 CPU가 메모리 사용 권한을 양보하는데, 이는 CPU의 작업 속도가 입출력장치의 속도 보다 빠르기 때문이다.
    - CPU 입장에서는 순서를 빼앗긴 것이기 때문에 이를 사이클 훔치기라 부른다.





## 병렬처리

- 병렬 처리의 개념

  - 병렬 처리(Parallel processing)는 동시에 여러 개의 명령을 처리하여 작업의 능률을 올리는 방식을 말한다.

  - 파이프라인 기법
    - 여러 개의 명령을 동시에 처리하는 병렬 처리는 코어가 하나인 CPU에서도 작동 가능하다.
    - 하나의 코어에서 여러 개의 스레드를 사용하는 방식으로 병렬 처리가 가능하다.
    - 병렬처리에서는 이를 파이프라인 기법이라 부른다.
    - 스레드는 CPU가 처리할 수 있는 작업의 단위를 나타내며, 여러 개의 스레드를 동시에 처리하는 방식을 CPU 멀티스레드라한다.

  - 슈퍼스칼라 기법
    - 코어란 CPU의 핵심 기능을 가진 부분을 말한다.
    - 여러 개의 CPU 코어에서 각 코어에서 작업을 하나씩 실행시키는 방식이다.



- 병렬 처리 시 고려 사항
  - 상호 의존성이 없어야한다.
    - 각 명령이 서로 독립적이고 앞의 결과가 뒤의 명령에 영향을 미치지 않아야한다.
  - 각 단계의 시간을 거의 일정하게 맞춰야한다.
    - 각 단계의 처리 시간이 제각각이면 가장 긴 시간이 걸리는 단계에서 병목 현상이 발생한다.
    - 즉 오랜 시간이 걸리는 작업 때문에 진행이 전반적으로 밀려서 전체 작업 시간이 늘어난다.
  - 전체 작업 시간을 몇 단계로 나눌지 잘 따져보아야 한다.
    - 병렬 처리에서 작업을 N개로 쪼갰을 때 N을 병렬 처리의 깊이(depth of parallel processing)라고 한다.
    - 병렬 처리의 깊이는 동시에 처리할 수 있는 작업의 개수를 의미한다.
    - 이론적으로는 N이 커질수록 동시에 작업할 수 있는 작업의 개수가 많아져서 성능이 높아질 것이다.
    - 하지만 작업을 너무 많이 나누면 각 단계마다 작업을 이동하고 새로운 작업을 불러오는데 시간이 너무 많이 걸려 오히려 성능이 떨어진다.



- 병렬 처리 기법

  - CPU 내에서 명령어는 제어장치가 처리한다.
    - 제어장치는 명령어를 가져와 해석한 후 실행하고 결과를 저장하는 과정을 반복한다.
    - 이러한 과정 전체를 하나의 스레드라고 하며, 스레드를 이루는 각 단계는 CPU 클록과 연동되어 한 클록에 한 번씩 이루어진다.
  - CPU에서 명령어가 실행되는 과정은 다음과 같이 4단계로 나뉘는데 더 세분화하기도 한다.
    - 명령어 패치(Instruction Fetch, IF): 다음에 실행할 명령어를 명령어 레지스터에 저장한다.
    - 명령어 해석(Instruction Decode, ID): 명령어를 해석한다.
    - 실행(EXecution, EX): 해석한 결과를 토대로 명령어를 실행한다.
    - 쓰기(Write Back, WB): 실행된 결과를 메모리에 저장한다.
  - 파이프라인 기법
    - CPU의 사용을 극대화하기 위해 명령을 겹쳐서 실행하는 방법
    - CPU의 사양과 연관지어 보면 하나의 코어에 여러 개의 스레드를 사용하는 것이다.
    - 명령어를 여러 개의 단계로 분할한 후, 각 단계를 동시에 처리하는 하드웨어를 독립적으로 구성한다.
    - 기존 방식에서는 한 명령어를 처리하기 위해 명령어 처리 4단계를 모두 마치고 다음 명령어를 처리하지만, 파이프라인 기법에서는 명령어 처리의 단계 마다 독립적으로 구성하여 각 단계가 쉬지 않고 명령어를 처리할 수 있게한다.

      | time    | t1   | t2   | t3   | t4   | t5   | t6   | t7   |
      | ------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | thread1 | IF   | ID   | EX   | WB   |      |      |      |
      | thread2 |      | IF   | ID   | EX   | WB   |      |      |
      | thread3 |      |      | IF   | ID   | EX   | WB   |      |
      | thread4 |      |      |      | IF   | ID   | EX   | WB   |

  - 파이프라인 기법의 위험
    - 데이터 위험(Data hazard): 데이터의 의존성 때문에 발생하는 문제로, 앞의 명령어에서 만들어진 어떤 데이터를 다음 명령어에서 사용할 경우 이 두 명령어는 동시에 실행되어서는 안 된다.
    - 제어 위험(Control hazard): 분기를 하는 if문 같은 명령어에서 발생하는 문제로, 프로그램 카운터 값을 갑자기 변화시켜서 발생하는 위험이다. 보통의 경우 모든 프로그램이 순차적으로 실행된다고 가정하므로 동시에 실행되는 명령어들이 순차적으로 실행된다. 그러나 다음 문장이 아니라 아예 다른 문장으로 이동하게 될 경우 현재 동시에 처리되고 있는 명령어들이 쓸모 없어진다.
    - 구조 위험(Structural hazard): 서로 다른 명령어가 같은 자원에 접근하려고 할 때 발생하는 문제로, 명령어 A가 레지스터 RX를 사용하고 있는데, 병렬 처리되는 명령어 B도 레지스터 RX를 사용해야 한다면 서로 충돌하게 된다.
  - 슈퍼스칼라 기법
  
    - 파이프라인을 처리할 수 있는 코어를 여러 개 구성하여 복수의 명령어가 동시에 실행되도록 하는 방식이다.
    - 즉 파이프라인 기법을 여러 개의 코어에서 실행하는 것이다.
    - 대부분의 CPU가 사용하는 방식이다.
  - 슈퍼파이프라인 기법
  
    - 파이프라인 기법은 한 클록마다 하나의 명령어를 실행하지만, 슈퍼파이프라인 기법에서는 파이프라인의 각 단계를 세분하여 한 클록 내에 여러 명령어를 처리할 수 있다.
    - 한 클록 내에 여러 명령어를 실행하면 다음 명령어가 빠른 시간 안에 시작될 수 있어 병렬처리 능력이 높아진다.
  
  - 슈퍼파이프라인 슈퍼스칼라 기법
    - 앞에서 살펴본 모든 기법을 모두 합쳐놓은 것이다.
    - 슈퍼파이프라인 기법을 여러 개의 코어에서 동시에 수행하는 방식이다.
  - VLIW(Very Long Instruction Word)
    - 앞의 방식들은 병렬 처리를 지원하는 하드웨어적인 방법들이지만, VLIW 기법은 CPU가 병렬 처리를 지원하지 않을 경우 소프트웨어적으로 병렬 처리를 하는 방법이다.
    - VLIW 기법에서는 동시에 수행할 수 있는 명령어들을 컴파일러가 추출하고 하나의 명령어로 압축하여 실행한다.
    - 앞의 방식들에 비해 동시에 처리하는 명령어의 개수가 적다.
    - 또한 앞의 기법들은 명령어 실행 시 병렬 처리가 이루어지지만 VLIW 기법은 컴파일 시 병렬 처리가 이루어진다.

