# Linked list

- 연결리스트는 일반 리스트에 비해 인덱스의 조회는 느리지만 추가, 삭제는 빠르다.

- 단일 연결 리스트에서 삽입, 삭제를 할 때에는 앞 쪽에 있는 노드에 대한 정보를 알아야 한다. 따라서 앞 쪽 노드에 대한 정보 탐색을 가장 먼저 해야 한다.

  - 각 노드는 데이터 필드와 다음 노드에 대한 주소를 가지고 있다.

  - 즉 이전 노드에는 다음 노드에 대한 주소가 존재한다.

  - 만일 새로운 노드를 추가하고자 한다면 앞의 노드가 가리키는 노드를 새로운 노드가 가르키도록 변경하고 앞쪽 노드는 추가한 노드를 가리키게 한다. 즉, 둘 다 앞 쪽 노드를 알아야 가능하다.

  - 삭제도 마찬가지로 앞쪽 노드가 가르키는 노드를 삭제할 노드가 가르키는 노드로 변경하면 된다.

    ex. 서울-부산이 있을 때 중간에 대전을 추가하고 싶다면 우선 첫 번째로 서울이 가리키는 부산이라는 주소를 읽어와서 대전의 주소로 만들고 서울이 가리키는 주소를 대전으로 변경한다. 만일 서울-대전-부산에서 대전을 빼고 싶다면 서울이 카르키던 대전을 부산으로 바꾸면 된다.

    

- 연결 리스트에서 뭘 먼저 연결해야 할지 헷갈린다면 삽입해야 할 노드의 주소를 먼저 수정하는 것이 안전하다.



- 삽입정렬(배열의 요소 별로 배열을 쭉 순회하면서 요소보다 작은 값과 큰 값 사이에 해당 요소를 삽입하여 정렬하는 방식)은 연결리스트로 구현하는 것이 더 효율적이다.
  - 일반리스트의 경우 삽입 후 삽입한 위치 뒤의 요소들은 모두 한 칸씩 뒤로 밀어야 한다는 단점이 있다.
  - 연결리스트로 구현하면 앞뒤 요소와 연결만 해주면 된다.

 

- 병합정렬 역시 연결 리스트로 구현하면 더 효율적이다.



- 원형 연결리스트는 원형이기에 tail은 잘 쓰지 않는다. head는 원형 연결 리스트의 시작점을 의미한다.
  - 모든 노드의 next와 prev에 None이 존재하지 않는다.







# Tree

1. 트리 개요

- 용어 정리
  - 노드: 트리의 원소
    - 루트 노드: 트리의 시작 노드
    - 조상 노드: 간선을 따라 루트 노드까지 이르는 경로에 있는 모든 노드들
    - 자손 노드: 서브 트리에 있는 하위 레벨의 노드들
    - 형제 노드: 같은 부모 노드의 자식 노드들
    - 단말 노드: 자식 노드가 없는 노드
  - 간선: 노드를 연결하는 선, 부모 노드와 자식 노드를 연결
    - 트리에서 간선의 수는 반드시 노드의 수-1개이다.
    - 즉 노드의 수>=간선의 수라면 트리가 아니다.
  - 서브트리: 부모 노드와 연결된 간선을 끊었을 때 생성되는 트리
    - 즉, 트리는 0개 이상의 하위 트리로 구성되어 있다.
  - 차수
    - 노드의 차수: 노드에 연결된 자식 노드의 수
    - 트리의 차수: 트리에 있는 노드의 차수 중에서 가장 큰 값
  - 높이(레벨)
    - 노드의 높이: 루트에서 노드에 이르는 간선의 수
    - 트리의 높이: 트리에 있는 노드의 높이 중에서 가장 큰 값
- 트리는 일종의 그래프이다. 
  - 그래프는 연결컴포넌트(어떤 임의의 두 노드를 선택하든지 둘 사이에 경로가 존재)
  - 트리 역시 연결컴포넌트 이지만 임의의 두 노드 사이에 유일한 경로가 존재한다. 즉 그래프와는 달리 두 노드 사이에 경로가 단 하나뿐이다.
  - 사이클이 존재하지 않는다. 즉 어떤 한 간선이라도 지우면 모든 노드가 연결된 상태는 아니게 되며 간선을 하나라도 추가하면 사이클이 생기게 된다(∵노드수=간선수+1).
- 트리의 특징
  - 트리는 어떤 자료를 더 낮은 시간복잡도로 찾거나 삽입하거나 삭제하기 위해 사용한다.
    - 수직으로 뻗은 리스트를 가정하고 그 리스트 내의 어떤 값을 찾으려 한다면 시간복잡도는 O(N)이 될 것이다. 그러나 만일 일정한 규칙에 따라 트리 형태로 구성되어 있다면 시간 복잡도는 O(logN)이 될 것이다. 
    - 예를 들어 왼쪽 자식 노드에는 부모 보다 작은 값, 오른쪽 자식 노드에는 부모보다 큰 값이 저장되어 있다고 할 때 찾으려는 값이 부모보다 작다면 오른쪽 서브트리는 탐색을 하지 않아도 된다. 또 다시 왼쪽 서브트리로 들어가서 여전히 왼쪽 서브트리의 부모 보다 찾으려는 값이 작다면 다시 왼쪽 서브트리의 오른쪽 서브트리는 탐색을 하지 않아도 된다. 이런 식으로 자료를 더 효율적으로 탐색, 수정, 삭제 할 수 있게 된다.
    - 편향 트리가 트리로서의 의미가 없다고 하는 이유도 여기에 있다. 한쪽으로 편향되어 있다면 수직으로 뻗은 리스트와 다를 것이 없으므로 트리를 쓰는 의미가 없다.
  - 루트(최상위 원소)에서 하위 원소로 내려가면서 확장되는 뿌리 모양의 구조
  - 가계도를 생각하면 쉽다.  실제로 가계도에서 많은 용어를 가져 왔다.
  - 비선형 자료구조
  - 하나(반드시 하나)의 부모 노드 아래에 0개 이상의 자식 노드가 존재하는 형태(원소들 간 1:n의 관계를 가진다)
  - 한 개 이상(∵루트는 반드시 존재)의 노드로 이루어진 유한 집합이다.
  - 루트를 제외한 나머지 노드들은 0개 이상의 분리집합(서로소)이다. 즉 한 집합 내부에 있는 원소가 다른 집합의 원소가 될 수는 없다.



2. 이진트리

- 이진트리

  - 모든 노드들이 최대 2개의 서브트리를 갖는 특별한 형태의 트리(0~2개의 자식 노드가 존재)
    - 레벨(높이) i에서 노드의 최대 개수는 2<sup>i</sup>개
    - 높이가 h인 이진 트리가 가질 수 있는 노드의 최소 개수는 (h+1)개(모든 높이에 노드가 1개씩만 있는 경우), 최대 개수는 (2<sup>h+1</sup>-1)개
  - 왼쪽 자식과 오른쪽 자식을 구분한다.

- 포화 이진 트리

  - 모든 레벨에 노드가 포화 상태로 차 있는 이진 트리(모든 높이에 노드가 2개씩 존재하는 트리)
  - 루트를 1번으로 하여 모든 노드가 번호를 가진다. 이 경우 가장 왼쪽의 노드를 쭉 타고 가면 번호는 2<sup>높이</sup>로 매겨진다. 오른쪽은 2<sup>높이+1</sup>-1로 매겨진다.

- 완전 이진 트리

  - 높이가 h이고 노드가 n개일 때, 포화 이진 트리의 노드 번호 1번부터 n번 까지 빈자리가 없는 이진 트리, 즉 포화 이진트리는 아니지만 n번째 노드까지는 포화 이진 트리의 형태를 지닌다.

- 편향 이진 트리(사실상 연결리스트이다)

  - 높이 h에 대한 최소 개수의 노드를 가지면서 한쪽 방향의 자식만을 가진 이진 트리, 즉 노드가 2개 이상이거나 왼쪽자식, 오른쪽 자식이 혼재되어 있으면 편향 이진 트리가 아니다.
    - 왼쪽 편향 이진 트리
    - 오른쪽 편향 이진 트리
  - 트리의 장점을 잘 살리지 못하기에 좋지 않은 구조다.

- 이진트리에서의 순회(DFS를 사용)

  - 기본적인 순회 방법
    - 왼쪽 자식을 오른쪽 자식보다 먼저 방문한다는 원칙 하에 부모 노드를 언제 방문할지에 따라 3가지로 나뉜다.
    - 레벨 순회: 부모부터 차례로 방문 후 자식을 방문(BFS와 동일)
    - 전위 순회:부모노드 방문 후, 자식 노드 좌,우 순 방문(일반적 DFS와 동일)
    - 중위 순회: 왼쪽 자식, 부모노드, 오른쪽 자식 순으로 방문
    - 후위 순회: 좌,우 자식 방문 후 , 부모 노드  순으로 방문
  - 이진 트리 순회시 모든 부모 노드는 3번 방문한다.
    - 처음 노드에 진입할 때(이 때 방문 표시(혹은 원하는 처리)를 하면 전위 순회), A-B-D-E-H-I-C-F-G
    - 왼쪽 자식에서 돌아올 때(이 때 방문 표시(혹은 원하는 처리)를 하면 중위 순회),D-B-H-E-I-A-F-C-G
    - 오른쪽 자식에서 돌아올 때 (이 때 방문 표시(혹은 원하는 처리)를 하면 후위 순회)D-H-I-E-B-F-G-C-A

  | A    |      |      |      |      |      |
  | ---- | ---- | ---- | ---- | ---- | ---- |
  | B    |      |      | C    |      |      |
  | D    | E    |      | F    | G    |      |
  |      | H    | I    |      |      |      |

- 이진트리의 표현

  - 1차원 배열에 표현이 가능하다

  - 노드 번호가 i인 노드의 왼쪽 자식의 노드 번호는 2*i
  - 노드 번호가 i인 노드의 오른쪽 자식의 노드 번호는 2*i+1
  - 부모는 i//2(왼쪽 자식이던 오른쪽 자식이던 마찬가지다 ∵ //는 나머지를 버리므로 +1이 되던 안되던 상관 없다.)



- 수식트리
  - 수식을 표현하는 이진트리
  - 연산자는 부모, 피연산자는 좌,우의 자식 노드가 된다.
  - 단말 노드는 피연산자, 단말 노드가 아닌 노드(루트 노드와 가지 노드)는 모드 연산자
  - 단말노드(leaf)에 가까울수록 연산의 우선 순위가 높아진다.



- 이진 탐색 트리

  - 탐색 작업을 효율적으로 하기 위한 자료 구조
  - 모든 원소는 서로 다른 유일한 키를 갖는다
  - key는 왼쪽 자식<부모<오른쪽 자식 이다. 즉 왼쪽 서브트리는 루트보다 작은 값이, 오른쪽 서브트리는 루트보다 큰 값이 온다. 각각의 서브트리 역시 이진 탐색 트리가 된다.
  - 중위 순회를 하면 오름차순으로 정렬된 값을 얻을 수 있다.
  - 구체적 탐색 순서
    - 루트에서 시작
    - 탐색할 키 값 x를 루트 노드의 키 값과 비교
    - 루트 노드의 키 값>x 면 왼쪽 서브트리로 로 이동
      - 왼쪽 서브트리에서 다시 처음부터 시작
    - 루트 노드의 키 값<x 면 오른쪽 서브트리로 로 이동
      - 오른쪽 서브트리에서 다시 처음부터 시작
    - 루트 노드의 키 값==x 면 x를 찾음
  - 삽입 연산

- 위의 과정을 거쳐 탐색을 수행 후 탐색이 실패한 위치(삽입 하려는 값이기에 당연히 탐색해도 없을 것이므로 탐색은 실패하게 된다)에 삽입하려는 값을 삽입

- 삭제 연산

  - 삽입과 마찬가지로 탐색을 수행 후 찾으면 삭제

  - 삭제 후 만일 삭제한 노드에 자식이 있었다면 삭제한 노드의 부모 노드와 삭제한 노드의 자식노드를 연결해준다.

  - 만일 삭제한 노드의 자식 노드가 2개 였다면 왼쪽 서브트리의 가장 큰 값이나 오른쪽 서브트리의 가장 작은 값 중 하나가 삭제한 노드의 자리를 대체해 새로운 부모 노드가 된다.

    ∵key는 왼쪽 서브트리<루트 노드<오른쪽 서브트리

      - 왼쪽 서브트리의 가장 큰 값은 왼쪽 서브트리에서 오른쪽으로 갈 수 있을 때 까지 가면 가장 큰 값이 나오며
      - 오른쪽 서브트리의 가장 작은 값은 오른쪽 서브트리에서 왼쪽으로 갈 수 있을 때 까지 가면 가장 작은 값이 나온다.

  - 이진 탐색 트리에서 탐색, 삽입, 삭제 시간은 트리의 높이 만큼 걸린다.

    - 이진 트리가 균형적으로 생성되어 있는 경우(좌,우 서브트리의 높이차가 1이하): 대략 O(log n)
    - 최악의 경우: 한쪽으로 치우친 경사 이진트리의 경우: O(N)



3. 힙(heap)

- 우선순위 큐(큐에 들어간 순서가 아닌, 우선순위에 따라 처리)를 구현하기 위해 사용
- 노드를 완전 이진 트리 형태로 저장하여 구현하여 트리에 있는 노드 중에서 키값이 가장 큰 노드나 키값이 가장 작은 노드를 찾기 위해서 만든 자료구조
- 힙을 정의하는 2가지 요소(둘 중 하나라도 충족하지 못하면 힙이 아니다)
  - 완전 이진 트리이다.
  - 부모 요소와 자식 요소 사이 키 값의 대소에 일관성이 존재한다.
    - 항상 부모 요소의 키 값이 크다(최대힙)
    - 항상 부모 요소의 키 값이 작다(최소힙)
- 즉, 우선순위 큐에서는 가장 작은 값이나 가장 큰 값을 먼저 처리하는데 자료의 추가나 삭제가 빈번히 일어나는 경우에 추가나 삭제가 일어날 때 마다 번번이 추가된 자료나 삭제된 자료를 고려하여 다시 크기 순으로 정렬하고  최대값이나 최솟값을 다시 찾아야 하는 번거로움이 있다. 그러나 힙에서는 항상 루트에 최소값(최소 힙)이나 최대값(최대 힙)을 위치시키기 때문에 다른 값의 정렬 여부와 관계 없이 항상 최대값, 혹은 최소값을 알 수 있다. 따라서 시간이 훨씬 적게 걸린다.
  - 따라서 최대값, 최솟값을 탐색하는 시간 복잡도는 O(1)이다.
- 종류
  - 최대 힙
    - 키 값이 가장 큰 노드를 찾기 위한 완전 이진 트리
    - 부모노드의 키값>자식노드의 키값, 이진 트리와 달리 자식들(좌우) 사이의 키값의 대소는 상관 없다.
    - 루트 노드: 키값이 가장 큰 노드
  - 최소 힙
    - 키 값이 가장 작은 노드를 찾기 위한 완전 이진 트리
    - 부모노드의 키값<자식노드의 키값, 이진 트리와 달리  자식들(좌우) 사이의 키값의 대소는 상관 없다.
    - 루트 노드: 키값이 가장 작은 노드
- 특정 노드의 자식 노드가 있는지 확인하는 방법
  - 일반적으로 트리의 마지막 노드를 알 수 있다.
  - 따라서 만일 노드번호\*2를 했을 때 이 값이 트리의 마지막 노드 번호보다 크다면 자식 노드가 없는 것이다. 만일 같다면 왼쪽 자식 하나만 가지고 있는 것이고 노드번호\*2+1이 마지막 노드 번호보다 작거나 같다면 좌우 자식이 모두 있는 것이다.





# 반복과 재귀

- 반복과 재귀는 유사한 작업을 수행할 수 있다.
- 반복은 수행하는 작업이 완료될 때 까지 계속 반복
- 재귀는 주어진 문제의 해를 구하기 위해 동일하면서 더 작은 문제의 해를 이용하는 방법
  - 하나의 문제를 해결할 수 있는(해결하기 쉬운) 더 작은 문제로 쪼개고 결과들을 결합한다.
  - 재귀함수로 구현



- 반복

  - 초기화: 반복되는 명령문을 실행하기 전에 (한번만)조건 검사에 사용할 변수의 초기값 설정
  - 조건검사
  - 반복할 명령문 실행
  - 엡데이트: 무한루프가 되지 않게 조건이 거짓이 되게 한다.

  ```python
  #e.g 2**k를 구하는 함수
  
  def power_of_2(k):
      #초기화
      i=0
      power=1
      #조건검사
      while i<k:
      #명령문 실행
      	power=power*2
          #업데이트
          i+=1
      
  ```

  



- 재귀적 알고리즘
  - 재귀적 정의는 두 부분으로 나뉜다.
  - 하나 또는 그 이상의 기본 경우(base case or rule): 집합에 포함되어 있는 원소로 induction을 생성하기 위핸 시드(seed) 역할
  - 하나 또는 그 이상의 유도된 경우(inductive case or rule): 새로운 집합의 원소를 생성하기 위해 결합되어 지는 방법



- 재귀함수
  - 함수 내부에서 직접 혹은 간접적으로 자기 자신을 호출하는 함수
  - 일반적으로 재귀적 정의를 이용해 재귀함수를 구현
  - 따라서, 기본 부분과 유도 부분으로 구성된다.
  - 재귀적 프로그램을 작성하는 것은 반복 구조에 비해 간결하고 이해하기 쉽다.
  - 함수 호출은 프로그램 메모리 구조에서 스택을 사용한다. 따라서 재귀 호출은 반복적은 스택의 사용을 의미하며 메모리 및 속도에서 성능저하가 발생

```python
#e.g.팩토리얼 재귀 함수
def fact(n):
    #basic
    if n<=1:
        return 1
    #inductive
    else:
        return n*fact(n-1)
```



- 해결할 문제를 고려하여 반복이나 재귀의 방법을 선택
  - 재구니느 문제 해결을 위한 알고리즘 설계가 간단하고 자연스러움
    - 추상자료형(list, tree 등)의 알고리즘은 재귀가 구현이 간단하고 자연스러운 경우가 많다.
  - 일반적으로 재귀적 알고리즘은 반복 알고리즘보다 더 많은 메모리와 연산을 필요로 한다.
    - 가지치기를 잘 하거나 데이터 양이 적은 경우 재귀가 더 효율적일 수 있다.
  - 입력값 n이 커질수록 재귀 알고리즘은 반복에 비해 비효율적일 수 있다.

|                | 재귀                                    | 반복                |
| -------------- | --------------------------------------- | ------------------- |
| 종료           | 재귀 함수 호출이 종료되는 베이스 케이스 | 반복문의 종료 조건  |
| 수행 시간      | 상대적으로 느림                         | 빠름                |
| 메모리 공간    | 상대적으로 많이 사용                    | 적게 사용           |
| 소스 코드 길이 | 짧고 간결                               | 길다                |
| 소스 코드 형태 | 선택구조(if...else)                     | 반복구조(for,while) |
| 무한 반복시    | 스택 오버플로우                         | CPU를 반복해서 점유 |



- brute-force

  - 문제 해결을 위한 간단하고 쉬운 접근법
  - force의 의미는 사람(지능)보다는 컴퓨터의 force를 의미한다.

  - 대부분의 문제에 적용 가능
  - 상대적으로 빠른 시간에 문제 해결(알고리즘 설계)을 할 수 있다.
  - 문제에 포함된 자료의 크기가 작다면 유용하다
  - 학술적 또는 교육적 목적을 위해 알고리즘의 효율성을 판단하기 위한 척도로 사용된다.

  

- 완전검색

  - 완전검색은 조합적 문제에 대한 brute-force 방법이다.
    - 이들은 전형적으로 순열, 조합, 그리고 부분집합과 같은 조합적 문제들과 연관된다.
    - 많은 종류의 문제들이 특정 조건을 만족하는 경우나 요소를 찾는 것이다.
  - 모든 경우의 수를 생성하고 테스트하기에 수행 속도는 느리지만 해답을 찾지 못할 확률이 작다.
  - 우선 완전검색으로 접근하여 해답을 도출한 후, 성능 개선을 위해 다른 알고리즘을 사용하고 해답을 확인하는 것이 바람직하다.







# 순열과 조합, 부분집합

## 순열



- 순열: 서로 다른 것들 중 몇 개를 뽑아서 한 줄로 나열하는 것

  - 다수의 알고리즘 문제들은 순서화된 요소들의 집합에서 최선의 방법을 찾는 것과 관련 있다.
  - 서로 다른 n개 중 r개를 택하는 순열은 <sub>n</sub>P<sub>r</sub>로 표현한다.
  - <sub>n</sub>P<sub>n</sub>=n! 이다.

- 순열 생성 방법

  - 사전적 순서(Lexicographic-Order)

  - 최소 변경을 통한 방법(Minimum-exchange requirement)

    - 각각의 순열들은 이전의 상태에서 단지 두 개의 요소들을 교환해서 생성
    - [123], [<u>21</u>3], [2<u>31</u>], [<u>32</u>1], [3<u>12</u>], [<u>13</u>2]

  - 순열 생성 알고리즘

    - 반복문을 중첩하여 생성

    - 재귀호출을 통한 순열 생성

    - 재귀호출을 통한 순열 생성-교환을 활용

      - 예제:swea_1244_최대상금




## 부분집합

- 집합에 포함된 원소들을 선택하는 것
- 다수의 중요 알고리즘들이 원소들의 그룹에서 최적의 부분 집합을 찾는 것이다
- N개의 원소를 포함한 집합
  - 자기 자신과 공집합을 포함한 모든 부분집합(power set)의 개수는 2<sup>n</sup>대
  - 원소의 수가 증가하면 부분집합의 개수는 지수적으로 증가
- 부분집합 생성 알고리즘
  - 반복문을 중첩하여 생성
  - 바이너리 카운팅
    - 원소 수에 해당하는 N개의 비트열을 이용한다.
    - n번째 비트값이 1이면 n번째 원소가 포함되었음을 의미한다.



## 조합

- 서로 다른 n개의 원소 중 r개를 순서 없이 골라낸 것을 조합이라고 부란다.

- 조합의 수식
  $$
  _nC_k=\frac{n!}{(n-k)!k!}   (단, n>k)
  $$

  - <sub>n</sub>C<sub>r</sub> = <sub>n-1</sub>C<sub>r-1</sub>+<sub>n-1</sub>C<sub>r</sub>(재귀적 표현, <sub>n</sub>C<sub>r</sub>이라는 동일한 함수를 사용, inductive rule로 쓸 수 있다)
  - <sub>n</sub>C<sub>0</sub> = 1(base rule로 쓸 수 있다)
  - <sub>n</sub>C<sub>n</sub> = 1

- 조합을 재귀로 구하기

  - arr = [0,1,2,3,4]일 때
  - <sub>5</sub>C<sub>3</sub>은 (4가 포함된 경우 + 4가 포함되지 않은 경우)이다. 즉 <sub>5</sub>C<sub>3</sub> = <sub>4</sub>C<sub>2</sub>(4포함)+<sub>4</sub>C<sub>3</sub>(4미포함)
  - <sub>n</sub>C<sub>0</sub> = 1라는 base rule을 사용







# 탐욕 알고리즘

- 탐욕(greedy) 알고리즘
  - 최적해를 구하는 데 사용되는 근시안적인 방법, 반드시 최적해를 구한다는 보장이 없다.
  - 일반적으로, 머리속에 떠오르는 생각을 검증 없이 바로 구현하면 greedy 접근이 된다.
  - 여러 경우 중 하나를 선택 할 때마다 그 순간에 최적이라고 생각되는 것을 선택해 나가는 방식으로 진행하여 최종적인 해답에 도달
  - 각 선택 지점에서 이루어지는 결정은 지역적으로는 최적이지만, 그 선택들을 계속 수집하여 최종적인 해답을 만들었다고 하여, 그것이 최적이라는 보장은 없다. 
  - 일단, 한 번 선택된 것은 번복하지 않는다. 이런 특성 때문에 대부분의 탐욕 알고리즘들은 단순하며, 또한 제한적인 문제들에 적용된다.
  - 매 순간의 선택이 최적이라는 것이 논리적으로 타당해야 한다.



- 최적화(optimization) 문제란 가능한 해들 중에서 가장 좋은(최대 또는 최소) 해를 찾는 문제이다.
  - 대부분의 최적화 문제는 완전검색으로 풀어야 하는 문제들이다.
  - 따라서 시간이 오래 걸리므로 보다 빠르게 찾기 위해 탐욕 알고리즘을 사용한다.
  - 그러나 탐욕으로 풀 수 있는 최적화 문제는 많지 않다.



- 동작 과정
  - 해 선택: 현재 상태에서 부분 문제의 최적 해를 구한 뒤, 이를 부분해 집합(Solution Set)에 추가한다.
  - 실행 가능성 검사: 새로운 부분 해 집합이 실행가능한지를 확인한다. 즉 문제의 제약 조건을 위반하지 않는지 검사한다
  - 해 검사: 새로운 부분 해 집합이 문제의 해가 되는지 확인, 아직 전체 문제의 해가 완성되지 않았다면 1의 해 선택부터 다시 시작한다.
  - 예시: 거스름돈 줄이기
    - 2370원을 거슬러 줘야 하는 경우 최소한의 화폐로 거스름돈을 줘야 한다.
    - 따라서 1000원을 부분해 집합에 추가, 1370이 남음
    - 다시 1000원을 부분해 집합에 추가, 370이 남음
    - 다시 1000원을 부분해 집합에 추가, 실행 가능성 검사에서 문제의 제약조건에 위배되어 다시 1000원을 부분해 집합에서 뺀 후 해 선택으로 돌아감, 100원을 3번 추가, 10원을 7번 추가
    - 해 검사 결과 문제의 해가 되었으므로 종료



- 탐욕 알고리즘의 필수 요소
  - 탐욕적 선택 속성
    - 탐욕적 선택은 최적해로 갈 수 있음을 보여라
    - 즉 탐욕적 선택은 항상 안전하다.
  - 최적 부분 구조
    - 최적화 문제를 정형화하라
    - 하나의 선택을 하면 풀어야 할 하나의 하위 문제가 남는다
  - 원문제의 최적해 = 탐욕적 선택+하위 문제의 최적해 임을 증명하라



- 탐욕 기법과 동적 계획법의 비교
  - 탐욕
    - 완전검색을 하지 않기 위해 사용한다.
    - 매 단계에서 가장 좋게 보이는 것을 선택, 지역 최적 선택(local optimal choice)
    - 하위 문제를 풀기 전에 탐욕적 선택이 먼저 이루어진다.
    - Top-down 방식
    - 일반적으로 빠르고 간결(완전검색을 하지 않는다.)
    - 장점이 많음에도 쓰이지 않는 이유는 탐욕으로 푸는 방법을 찾은 문제가 많지 않기 때문이다. 최적화 문제를 풀기 위한 알고리즘이지만 최적화 문제 중에서도 탐욕으로 푸는 방법을 아직 찾지 못한 문제들이 많이 있다.
  - 동적 계획법
    - 기본적으로 완전검색이다(보다 효율적인 완전 검색).
    - 매 단계의 선택은 해결한 하위 문제의 해를 기반으로 한다.
    - 하위 문제가 우선 해결된다.
    - Bottom-up 방식
    - 좀 더 느리고, 복잡(완전검색을 한다)
    - 탐욕과 달리 대부분의 문제에 적용 가능하다.



- 대표적인 탐욕 기법의 알고리즘들
  - Prim,Kruskal,Dijkstra 등





# 다이나믹 프로그래밍

- 다이나믹 프로그래밍(Dynamic Programming, DP)
  - 응용 수학자 리차드 벨만이 1953년 고안한 패러다임이다.
    - 리차드 벨만은 벨만-포드 알고리즘과 머신러닝 분야의 차원의 저주라는 이론도 만들었다.
  - 문제를 각각의 작은 문제로 나누어 해결한 결과를 저장해 뒀다가 나중에 큰 문제의 결과와 합하여 풀이하는 알고리즘이다.
    - 최적 부분 구조를 가지고 있는 문제(문제의 최적 해결 방법이 부분 문제에 대한 최적 해결 방법으로 구성되는 경우의 문제)를 풀이할 수 있다.
    - DP의 핵심은 중복된 하위 문제들의 결과를 저장해두었다가 활용하는 것이다.
    - 만일 하위 문제들이 중복되지 않는다면 DP로 풀어선 안 된다.
  - 그리디와의 차이
    - 그리디도 마찬가지로 최적 부분 구조를 가진 문제를 푸는데 사용된다.
    - 둘의 차이는 그리디는 항상 그 순간에 최적이라고 생각되는 것을 선택하면서 풀이해 나가는 것이고, DP는 중복된 하위 문제들의 결과를 저장해뒀다가 풀이해 나간다는 차이가 있다.
  - 분할 정복과의 관계
    - 큰 문제를 작은 문제로 분할한다는 점과 둘 다 최적 부분 구조를 가질 때 사용할 수 있다는 점에서 유사하다.
    - 분할 정복은 각각의 sub problem들이 서로 독립적이지만, DP는 한 sub problem의 결과 값을 중복된 sub problem을 푸는데 사용한다.





- 다이나믹 프로그래밍 방법론

  - 상향식(Tabulation)
    - 더 작은 하위 문제부터 살펴본 다음, 작은 문제의 정답을 이용해 큰 문제의 정답을 풀어나가는 방식이다.
    - 데이터를 table 형태로 만들어 tabulation 방식이라 한다.
    - 이 방식만을 DP로 지칭하기도 한다.

  ```python
  # 상향식으로 피보나치 수열을 구하는 풀이
  def fibonacci(n):
      dp[0] = 0
      dp[1] = 1
      
      for i in range(2, n+1):
          dp[i] = dp[i-1] + dp[i-2]
      return dp[n]
  ```

  - 하향식(Memoization)
    - 큰 문제를 더 이상 작은 문제로 분할하여 작은 문제들의 합을 합하여 전체 문제의 합을 구하는 방식
    - 분할 정복과의 차이는 작은 문제의 결과를 재활용하는지 여부이다.

  ```python
  def fibonacci(n):
      if n <= 1:
          return n
      
      if dp[n]:
          return dp[n]
      
      dp[n] = fibonacci(n-1) + fibonacci(n-2)
      return dp[n]
  ```




- DP 문제를 해결하는 단계
  - DP 문제인지 식별하기
    - 전체 단계 중 가장 어려울 수 있는 단계이다.
    - 전체 문제의 해가 더 작은 문제의 해로 표현될 수 있는지를 확인해야한다.
  - 함수에서 사용할 인자를 정의하고, 이들 중 어떤 것이 변해야 하는지를 확인한다.
    - Subproblem들을 나열해보고, 각 subproblem에서 어떤 값들이 변경되는지를 확인해야한다.
    - 변경되는 parameter들의 개수를 확인하는 것은 subproblem들의 개수를 결정하는데 도움이 된다.
  - 점화식(recurrence relation)을 명확하게 표현한다.
    - 문제를 parameter를 사용해 표현하였다면, 자연스럽게 도출할 수 있다.
    - 각 subproblem들이 서로 어떻게 연관되어 있는지를 생각해야한다.
    - Subproblem의 계산 결과로 어떻게 전체 문제의 결과를 도출해낼 수 있는지를 생각해보면 된다.
  - Base condition을 찾는다.
    - 다른 subproblem에 의존하지 않는 subproblem을 base condition이라 부른다.
    - 더 이상 단순해질 수 없을 때 까지 문제를 단순화하면, 그것이 base condition이 된다.
    - 일반적으로 parameter 중 하나가 문제의 제약조건에 의해 불가능한 값이 될 때까지 단순화하다보면 base condition을 찾을 수 있다.
  - 재귀로 구현할지, 반복문으로 구현할지를 선택한다.
    - 문제에 따라 적절한 방식을 선택한다.
  - Sub problem들의 결과를 저장하고, 이를 활용하면서 전체 문제의 결과를 찾는다.



# Divide and Conquer

- 분할정복: 문제를 부분 문제로 나눠(divide)서 부분문제의 해를 구한 후(conquer,) 부분문제의 해를 통해 전체 문제를 해결(combine)하는 방식



- Top-down Approach



 - divide ,conquer, combine의 세 단계를 거쳐 문제를 해결한다.
   - 이 때 부분문제가 더 작은 부분문제로 나뉠 수 있다면 문제가 충분히 작아질 때 까지 conquer 또한 다시 divde,conquer,combine으로 나뉘게 된다.
   - 위의 설명에서 알 수 있듯이 재귀함수와 매우 밀접한 연관을 지니는 패러다임이다.
   - 1~8의 합을 구할 경우 아래 그림과 같이 더 작은 문제들로 분할하여 base case인 1~1의 합 ~ 8~8의 합을 구한 후 이를 통해 상위문제의 해를 구하는 식으로 합을 구한다.
   - 수도 코드

   ```python
   def F(x):
       if F(x)가 간단 then:
           return F(x)를 계산한 값
       
       else:
           x를 x1, x2로 분할
           return F(x1), F(x2)
   ```



- 병합정렬
  - 리스트를 절반으로 나누고(divide), 왼쪽과 오른쪽을 각각 정렬(conquer)한 후, 정렬된 두 리스트를 하나의 정렬된 리스트로 합병(combine)한다.
  - 세 과정 중 합병이 가장 까다롭다.
  - 코드는 알고리즘 폴더 참조



- 퀵정렬

  - 합병정렬과 달리 세 과정 중 나누는과정이 가장 까다롭다.
  - 퀵 정렬에서 리스트를 나누는 과정(divide)을 파티션(partition)이라 부른다.
    - 기준점(pivot)을 정한다(divide). 꼭 리스트의 중간에 있는 값일 필요는 없다.
    - 기준점보다 더 작은 값은 기준점 왼쪽으로, 큰 값은 기준점 오른쪽으로 정렬한다(conquer).
  - 코드는 알고리즘 폴더 참조

  

- 이진 탐색

  - 중간값을 기준으로 계속해서 탐색 범위를 좁혀가며 탐색

  - 과정
    - 자료의 중앙에 있는 원소 선택
    - 중앙 원소의 값고 찾고자 하는 목표값을 비교
    - 목표값이 중앙 원소의 값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색을 수행, 크다면 자료의 오른쪽 반에 대해 새로 검색을 수행
    - 찾고자 하는 값을 찾을 때까지 위 과정을 반복
  - 코드는 알고리즘 폴더 참조





# Backtracking

- 백트레킹 개념
  - 여러가지 선택지들이 존재하는 상황에서 한가지를 선택한다.
  - 선택이 이루어지면 새로운 선택지들의 집합이 생성된다.
  - 이런 선택을 반복하면서 최종 상태에 도달한다.
  - 초기상태에서 목표상태까지 상태 공간 트리를 탐색하면서 진행된다.
  - 올바른 선택을 계속하면 목표 상태(goal state)에 도달한다.



- 절차
  - 상태 공간 트리에 깊이 우선 탐색을 실시
  - 각 노드가 유망한지 점검
  - 유망하지 않으면 그 노드의 부모 노드로 돌아가서 탐색을 계속



- DFS와의 차이
  - 가지치기(Plunning): 깊이 우선 탐색은 모든 경로를 추적하지만 백트래킹은 어떤 노드에서 출발하는 경로가 해결책으로 이어질 것 같지 않으면 그 경로를 따라가지 않음으로서 시도 횟수를 줄인다.
  - 백트래킹 알고리즘을 적용하면 일반적으로 경우의 수가 줄지만 이 역시 최악의 경우에는 여전히 지수함수 시간을 요하므로 처리 불가능



- 가지치기
  - 루트 노드에서 리프 노드까지의 경로는 해답 후보가 되는데 깊이 우선 탐색을 하여 그 해답후보 중에서 답을 찾을 수 있다. 그러나 이 방법을 사용하면 해답이 될 가능성이 전혀 없는 노드의 후손 노드들도 모두 검색해야 하므로 비효율적이다.
  - 모든 후보를 검사하지 않고 어떤 노드의 유망성을 점검한 후에 유망하지 않다고 결정되면 그 노드의 부모 노드로 되돌아가(백트래킹) 다음 자식 노드로 감
  - 유망하다는 것은 노드를 방문했을 때 그 노드를 포함한 경로가 해답이 될 수 있다는 것이다.
  - 가지치기는 유망하지 않은 노드가 포함되는 경로를 더 이상 고려하지 않는 것이다.



- 문제 유형
  - 모든 부분집합 구하기
  - 조합 구하기: 전체 집합에서 몇 개만 선택
    - 모든 부분집합을 구하는 문제 유형에 포함된다고도 볼 수 있다.
    - 예를 들어 <sub>6</sub>C<sub>3</sub>은 요소의 개수가 3인 부분집합을 구하는 것이다.
  - 순열 구하기: 집합의 순서를 변경



- DFS,BFS,백트래킹 문제를 풀 때에는 내가 생각하는 그래프, 혹은 상태공간 트리를 그려보고 최적해를 탐색하는 과정을 생각해 보면 된다.



# 문제 풀면서 알게 된 것들

- b_2667_단지 번호 붙이기

  - 리스트를 기준으로 반복문이 수행될 때, 리스트의 길이를 기준으로 수행될 때와 리스트로 반복문이 수행될 때 차이가 존재한다.

    ```python
    #길이를 기준으로 수행 되는 경우
    arr = [1]
    for i in range(len(arr)):
    	arr.append(i)
    	print("i")
    #위의 경우 반복문에 진입할 때의 arr의 길이를 기준으로 1번만 수행된다.
        
    
    #리스트를 기준으로 수행 되는 경우
    arr = [1]
    for i in arr:
    	arr.append(i)
    	print(i)
    #반면 위의 경우 arr에 계속 append가 되면서 반복문이 무한히 돌게 된다.
    ```




- BFS에서의 return

  - 함수를 정의해서 BFS를 풀 경우 `return`을 주의하라

  ```python
  import sys
  sys.setrecursionlimit(10 ** 6)
  
  dr = [-1, 1, 0, 0]
  dc = [0, 0, -1, 1]
  
  def dfs(r,c,k):
      for i in range(4):
          nr=r+dr[i]
          nc=c+dc[i]
          if nr>=N or nr<0 or nc >=N or nc<0:
              continue
          if maps[nr][nc] == 0:
              maps[r][c] = k
          if maps[nr][nc]==1:
              maps[nr][nc]="L"
              dfs(nr,nc,k)
  
  def bfs(k):
      global Q, Min
      while Q:
          NQ=[]
          for r,c in Q:
              if visited[r][c]>Min:
                  break         #break가 아닌 return을 써서 틀림 return할 경우 Q에 요소가 남아있는 상태로 다음 bfs로 넘어가게 된다.
              for i in range(4):
                  nr=r+dr[i]
                  nc=c+dc[i]
                  if nr>=N or nr<0 or nc>=N or nc<0:
                      continue
                  if maps[nr][nc] !=k and maps[nr][nc] in tk:
                      if Min>visited[r][c]:
                          Min=visited[r][c]
                          break
                  if maps[nr][nc]==0 and visited[nr][nc]==0:
                      NQ.append([nr,nc])
                      visited[nr][nc]=visited[r][c]+1
          Q=NQ
  
  
  N = int(input())
  maps=[list(map(int, input().split())) for _ in range(N)]
  Min= 987654321
  
  k=1
  tk=[]
  for i in range(N):
      for j in range(N):
          if maps[i][j]==1:
              k+=1
              tk.append(k)
              maps[i][j]="L"
              dfs(i,j,k)
  
  Q = []
  for i in range(N):
      for j in range(N):
          if maps[i][j] in tk:
              visited = [[0] * N for _ in range(N)]
              a = maps[i][j]
              Q.append([i,j])
              visited[i][j] = 1
              bfs(a)
  
  print(Min-1)
  ```







# 팁

- 파이썬에서 음수의 나눗셈

  - `//`연산자는 소수점 아래에 대해서는 `floor()`처리된다.
    - 두 정수 사이의 값일 경우 더 작은 값이 결과값이 된다.
  - `%`연산자의 결과값의 부호는 나누는 수(젯수)의 부호를 따른다.
    - a/b의 몫 q, 나머지 r이라고 할 때, `a=b*q+r`, `0<=|r|<b`가 항상 성립하도록 결과값을 리턴하도록 설계되어 있다.

  ```python
  a,b = -3,2
  print(a//b)
  print(int(a/b))
  if a<0:
  	print(-(abs(a)//b))
  
  #a//b의 경우 결과값이 다르게 나온다. 따라서 파이썬에서 음수의 나눗셈을 할 경우 다른 두 경우와 같이 해주는 것이 좋다.
  out
  -2
  -1
  -1
  ```



- 이차배열 형성할 때 주의 점

  ```python
  arr = [[0]*3]*3 #이와 같이 생성하면 안되는데 그 이유는
  arr[0][0] = 1
  arr[0][1] = 2
  arr[0][2] = 3
  print(arr)
  
  out
  [[1,2,3],[1,2,3],[1,2,3]] #이처럼 출력된다.
  #즉 원본 을 그대로 복사해서 적용되기에 이처럼 이차배열을 설정해선 안된다.
  
  따라서 아래와 같이 생성해야 한다.
  arr = [[0]*3 for _ in range(3)]
  ```



- 배열의 인덱스 설정을 위해 범위를 설정할 때(e.g. 미로 문제에서 범위를 벗어날 경우의 처리) 인덱스를 활용한 조건을 함께 써준다면, 반드시 범위 관련 설정을 먼저 써야 한다.

  ```python
  if nr>=N or nr<0 or nc>=N or nc<0 and visited[nr][nc]==0:
  
  #만일 위와 같은 코드를 아래와 같이 쓰면 인덱스 에러가 날 수 있다.
  
  if visited[nr][nc]==0 and nr>=N or nr<0 or nc>=N or nc<0:
      
  and는 앞에서부터 참거짓을 판별하여 앞의 조건이 거짓이면 뒤의 조건은 판별하지 않고 False를 반환한다.
  만일 nr이나 nc가 범위를 벗어난 값일 경우 첫 번째 코드처럼 쓰면 뒤의 visited[nr][nc]==0은 처리되지 않고 넘어간다. 그러나 두 번째 코드처럼 쓰면 우선 앞의 if visited[nr][nc]==0를 먼저 판별하는데 만일 nr이나 nc가 범위를 벗어난 값이었다면 인덱스 에러가 발생하게 된다.
  ```




- list 기반 loop에서 list를 수정하는 방법

  - 아래와 같이 list를 기반으로 loop를 수행할 때가 있다.

  ```python
  lst = [1,2,3,4,5]
  for i in lst:
      print(i)
  
  # 또는
  for i in range(len(lst)):
      print(i)
  ```

  - 이 때 반복 중인 list를 수정하는 것은 위험할 수 있다.
    - 예를 들어 아래와 같은 경우 out of index error가 발생한다.

  ```python
  lst = [1,2,3,4,5]
  
  cnt = 0
  for i in range(len(lst)):
      if i<4:
          lst.remove(lst[i])
      cnt+=1
  ```

  - 이럴 때는 for문 보다는 while문을 사용하는 것이 좋다.
    - 조건에 부합하지 않았을 때만 index를 증가시키고, 조건에 부합할 경우 index를 유지하는 방식을 사용한다.

  ```python
  lst = [1,2,3,4,5]
  
  i = 0
  cnt = 0
  while i != len(lst):
      if cnt<4:
          lst.remove(lst[i])
      else:
          i+=1
      cnt+=1
  ```




- deepcopy

  - Python에서는 `copy` 모듈의 `deepcopy` 함수와 slicing을 통해 깊은 복사가 가능하다.
    - 주의할 점은 slicing의 경우 객체 내부의 객체까지는 복제가 되지 않는다는 점이다.

  - deepcopy 함수는 속도가 느리다.
    - deepcopy를 사용하여 복사하는 것 보다 json의 `dumps`, `loads`를 사용하는 것이 더 빠르다.

  ```python
  from json import dumps, loads
  from copy import deepcopy
  import time
  
  orig_list = [[i for i in range(10)] for i in range(1000000)]
  
  deep_copy_start = time.time()
  copied_list_via_deepcopy = deepcopy(orig_list)
  print(time.time()-deep_copy_start)						# 7.03
  
  slicing_start = time.time()
  copied_list_via_slicing = orig_list[:]
  print(time.time()-slicing_start)						# 0.01
  
  dumps_and_loads_start = time.time()
  copied_list_via_json = dumps(orig_list)
  copied_list_via_json = loads(copied_list_via_json)
  print(time.time()-dumps_and_loads_start)				# 2.78
  
  orig_list[1][0] = 8
  print(copied_list_via_deepcopy[1][0])					# 0
  print(copied_list_via_slicing[1][0])					# 8
  print(copied_list_via_json[1][0])						# 0
  ```




- List를 최대한 균등하게 N분할하기

  - code

  ```python
  def split(a, n):
      k, r = divmod(len(a), n)
      result = []
      st = 0
      print(k, r)
      for i in range(n):
          # 나머지가 다 소진될 때 까지 앞에서부터 1개씩 추가한다.
          # 뒤에 있는 것들은 1칸씩 밀리기에 또 다시 1씩 증가시키면서 더해줘야한다.
          # 나머지가 다 소진되면, 나머지 만큼만 더해준다.
          ed = (i + 1) * k + min(i + 1, r)
          arr = a[st:ed]
          st = ed
          result.append(arr)
  
      return result
  
  
  arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
  for i in split(arr, 4):
      print(i)
  ```

  - 예시
    - `[1,2,3,4,5,6,7,8,9,10,11]`라는 list를 4(`N`)분할 하고자 한다.
    - Element의 개수가 11개이므로 `11 // 4`를 하면 2가 되고, 나머지(`11 % 4`)는 3이 된다.
    - 즉, 4개로 분할하면 분할 된 list 하나 당 2개가 들어가고 3개가 남게 된다.
    - `[1, 2]`, `[3, 4]`, `[5, 6]`, `[7, 8]`이 되고, `[9, 10, 11]`은 남게 된다.
    - 남은 3개의 element를 앞에서부터 하나씩 추가하여 `[1, 2, 9]`, `[3, 4, 10]`, `[5, 6, 11]`, `[7, 8]`이 되도록 해도 되지만, 이러면 list의 순서를 유지해야 하는 경우 문제가 된다.
    - 따라서, 처음에 분할 할 때 부터 앞에서부터 나머지에서 1개의 element씩을 빼서 분배해주는 방식을 사용해야한다.
    - 즉 나머지가 3이므로 처음 반복문을 순회할 때 나머지 중 1개를 더 추가하여 `[1,2,3]`으로 분할한다.
    - 다음 순회 때 나머지 중 1개를 더 추가하여 `[4,5,6]`으로 분할한다.
    - 다음 순회 때 나머지 중 1개를 더 추가하여 `[7,8,9]`로 분할한다.
    - 더 이상 나머지가 남아있지 않으므로 남은 것은 나머지 추가 없이 `[10, 11]`로 분할한다.
    - 즉 나머지를 r이라 할 때, 처음 분할 된 r개의 list에는 몫 + 1개의 element가 들어가게 되고, 더 이상 나머지가 남아있지 않은 r ~ N까지의 list에는 몫 만큼의 element가 들어가게 된다.
  - 구현
    - `+ min(i + 1, r)`는 순전히 나머지 처리를 위한 것으로, 나머지가 0이라면 이 코드는 필요 없다.
    - `min`을 제외하면 code는 `(i + 1) * k + i + 1`가 된다.
    - 여기서 `+1`은 나머지를 1개씩 추가해주기 위함이다.
    - 앞의 순회에서 `+1`을 하여 나머지 1개 만큼을 추가했으므로, 뒤에서는 index가 1씩 밀리게 되어 index를 뒤로 갈 수록 점점 증가시켜줘야한다.
    - 이를 위해서 순회시마다 1씩 증가하는 `i`를 사용하여, `i`를 더해준다. 
    - 따라서 더 이상 추가할 나머지가 남아있지 않으면, 즉 `i+r > r`이면, 더 이상 `+1` 씩 index를 더해주지 않고 앞에서 추가한 index의 개수 만큼만 index를 뒤로 미룬다.
  - 즉 위 code는 더 풀어쓰면 아래와 같다.

  ```python
  def split(a, n):
      k, r = divmod(len(a), n)
  
      result = []
      i = 0
      st = 0
      remaining_r = r
      while i < n:
          # 일단 나머지를 고려하지 않고 끝 index를 선언한다.
          ed = (i + 1) * k
      	# 만약 더 이상 분배할 나머지가 없다면,
          # 앞에서 밀린 index를 만큼을 ed에 추가해준다.
          if remaining_r == 0:
              ed += r
          # 아직 남아 있는 나머지가 있다면,
          else:
              # 나머지 중 1 개를 ed에 추가하고
              ed += 1
              # 나머지에서 1을 뺀다.
              remaining_r -= 1
              # 그 후 나머지로 인해 밀린 index를 반영하기 위해 i를 더한다.
              ed += i
          result.append(a[st:ed])
          st = ed
          i += 1
      return result
  
  
  arr = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
  for i in split(arr, 5):
      print(i)
  ```









# 편집 거리 알고리즘

- 편집 거리 알고리즘(Edit Distance)이란
  - 두 문장의 유사도를 판별하는 알고리즘이다.
    - 표절 여부, 철자 오류 검사 등에 사용된다.
    - 뿐만 아니라 유전 및 의료 공학에서 유전자 유사도 판별에도 사용된다.
  - Hamming Distance,  Levenshtein Distance등의 알고리즘이 있다.



## Levenshtein Distance

> https://madplay.github.io/post/levenshtein-distance-edit-distance 참고

- 편집 거리를 구하기 위해 가장 흔히 사용되는 알고리즘이다.

  - 한 문장이 다른 문장이 되기 위하여 몇 번의 삽입, 수정, 삭제를 거쳐야 하는지 계산하고, 그 최소값을 구한다.
    - 연산 횟수가 적을 수록 두 문장 사이에 유사도가 높다고 판단한다.

  - 간단한 예시
    - word가 world가 되기 위해서는 한 번의 삽입(l을 삽입) 연산이 필요하다.
    - sun이 son이 되기 위해서는 u를 o로 바꾸는 한 번의 수정 연산이 필요하다.
    - world가 word가 되기 위해서는 한 번의 삭제(l을 삭제) 연산이 필요하다.



- 실제 예시

  - delegate가 delete가 되려면 몇 번의 연산을 거쳐야 하는가?
  - 아래와 같이 표를 작성한다.
    - 첫 번째 문자는 null로 채워넣는다.

  |      |      | d    | e    | l    | e    | t    | e    |
  | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
  |      |      |      |      |      |      |      |      |
  | d    |      |      |      |      |      |      |      |
  | e    |      |      |      |      |      |      |      |
  | l    |      |      |      |      |      |      |      |
  | e    |      |      |      |      |      |      |      |
  | g    |      |      |      |      |      |      |      |
  | a    |      |      |      |      |      |      |      |
  | t    |      |      |      |      |      |      |      |
  | e    |      |      |      |      |      |      |      |

  - null 문자에서 delete가 되는 과정
    - null문자에서 null문자가 되기 위해서는 아무 연산도 필요하지 않다(총 0번의 연산)
    - null 문자에서 d가 되기 위해서는 d를 삽입하는 연산이 1번 필요하다(총 1번의 연산).
    - null 문자에서 de가 되기 위해서는 d를 삽입하는 연산 1번과 e를 삽입하는 연산이 1번씩 필요하다(총 2번의 연산).
    - null 문자에서 de가 되기 위해서는 d를 삽입하는 연산 1번과 e를 삽입하는 연산이 1번, l을 삽입하는 연산이 1번씩 필요하다(총 3번의 연산).
    - (...중략...)
    - null문자에서 delete가 되기 위해서는 d,e,l,e,t,e를 한번씩 삽입하는 연산이 필요하다(총 6번의 연산)
    - null이 delegate가 되는 과정도 마찬가지다.

  |      |      | d    | e    | l    | e    | t    | e    |
  | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
  |      | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
  | d    | 1    |      |      |      |      |      |      |
  | e    | 2    |      |      |      |      |      |      |
  | l    | 3    |      |      |      |      |      |      |
  | e    | 4    |      |      |      |      |      |      |
  | g    | 5    |      |      |      |      |      |      |
  | a    | 6    |      |      |      |      |      |      |
  | t    | 7    |      |      |      |      |      |      |
  | e    | 8    |      |      |      |      |      |      |

  - delegate의 d가 delete가 되는 과정
    - d가 d가 되기 위해서는 아무 연산도 필요하지 않다(총 0번의 연산).
    - d가 de가 되기 위해서는 e를 삽입하는 연산이 1번 필요하다(총 1번의 연산).
    - d가 del가 되기 위해서는 e, l을 삽입하는 연산이 1번씩 필요하다(총 2번의 연산).
    - (...중략...)
    - d가 delete가 되기 위해서는 e,l,e,t,e를 삽입하는 연산이 1번씩 필요하다(총 5번의 연산)
  - delegate의 de가 delete가 되는 과정
    - de가 d가 되기 위해서는 삭제 연산이 1번 필요하다(총 1번의 연산).
    - de가 de가 되기 위해서는 아무 연산도 필요하지 않다(총 0번의 연산).
    - (...후략...)
  - (...중략...)
  - delega가 delete가 되는 과정
    - (...전략...)
    - delega가 delete가 되기 위해서는 2번의 수정 연산(g->t, a->e)가 필요하다.
  - 위 과정을 전부 거치면 아래와 같은 표가 완성된다.
    - 표의 가장 우측 최하단에 있는 숫자(2)가 delegate를 delete로 변경하기 위한 최소 연산의 수가 된다.

  |      |      | d    | e    | l    | e    | t    | e    |
  | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
  |      | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
  | d    | 1    | 0    | 1    | 2    | 3    | 4    | 5    |
  | e    | 2    | 1    | 0    | 1    | 2    | 3    | 4    |
  | l    | 3    | 2    | 1    | 0    | 1    | 2    | 3    |
  | e    | 4    | 3    | 2    | 1    | 0    | 1    | 2    |
  | g    | 5    | 4    | 3    | 2    | 1    | 1    | 2    |
  | a    | 6    | 5    | 4    | 3    | 2    | 2    | 2    |
  | t    | 7    | 6    | 5    | 4    | 3    | 2    | 3    |
  | e    | 8    | 7    | 6    | 5    | 4    | 3    | 2    |

  - 위와 같이 일일이 비교하지 않고도 구하는 방법이 존재한다.
    - 비교하는 문자가 같은 경우 11시 방향 대각선의 값을 그대로 가져온다.
    - 변경하려고 할 경우 11시 방향 대각선에서 +1한 값을 가져온다.
    - 삭제하려고 할 경우 위의 값에서 +1한 값을 가져온다.
    - 삽입하려고 할 경우 왼쪽 값에서 +1한 값을 가져온다.
  - Levenshtein Distance 알고리즘은 최소 거리를 구하는 알고리즘이므로 아래와 같이 요약이 가능하다.
    - 비교하는 문자가 같은 경우 11시 방향 대각선의 값을 그대로 가져온다.
    - 비교하는 문자가 다를 경우 11시, 위, 왼쪽 값 중 가장 작은 값에서 +1한 값을 가져온다.
    - 예를 들어 delegate의 마지막 e와 delete의 마지막 e는 같은 문자이므로 11시 방향 대각선 값인 2를 그대로 가져온다.
    - 반면에 delegate의 g와 delete의 l은 서로 다른 문자이므로 11시, 위, 왼쪽 중 가장 작은 값인 위의 값(1)에서 +1한 값을 가져온다.



- 코드로 구현

  > https://towardsdatascience.com/text-similarity-w-levenshtein-distance-in-python-2f7478986e75 참고

  - DP와 memorization 개념이 들어간다.

  ```python
  from functools import lru_cache
  
  def lev_dist(a, b):
      '''
      This function will calculate the levenshtein distance between two input
      strings a and b
      
      params:
          a (String) : The first string you want to compare
          b (String) : The second string you want to compare
          
      returns:
          This function will return the distnace between string a and b.
          
      example:
          a = 'stamp'
          b = 'stomp'
          lev_dist(a,b)
          >> 1.0
      '''
      
      @lru_cache(None)  # for memorization
      def min_dist(s1, s2):
  
          if s1 == len(a) or s2 == len(b):
              return len(a) - s1 + len(b) - s2
  
          # no change required
          if a[s1] == b[s2]:
              return min_dist(s1 + 1, s2 + 1)
  
          return 1 + min(
              min_dist(s1, s2 + 1),      # insert character
              min_dist(s1 + 1, s2),      # delete character
              min_dist(s1 + 1, s2 + 1),  # replace character
          )
  
      return min_dist(0, 0)
  ```



- 원리는 점화식을 이해한 뒤 추후 추가