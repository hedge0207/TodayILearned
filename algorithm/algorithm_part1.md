# 목차

- [선형 탐색과 이진 탐색](#선형-탐색과-이진-탐색)

- [정렬](#정렬)
- [시간복잡도(Time Complexity)](#시간복잡도)
- [재귀함수](#재귀함수)
- [알고리즘 패러다임](#알고리즘-패러다임)



# 선형 탐색과 이진 탐색

1)선형탐색

- 앞에서부터 순차적으로 탐색해 나가는 것을 선형탐색이라고 부른다.

  ```python
  list_a = [1,3,8,9,15,18,22,26,28,30,31,38,44,49,52]
  이 리스트에서 38을 찾는다고 했을 때 1부터 52까지 순서대로 하나씩 확인하는 방식이 선형탐색
  ```



2)이진탐색

- 중간값을 기준으로 계속해서 탐색 범위를 좁혀가며 탐색하는 것을 이진탐색이라 부른다.

  - 자료의 중앙에 있는 원소 선택
  - 중앙 원소의 값고 찾고자 하는 목표값을 비교
  - 목표값이 중앙 원소의 값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색을 수행, 크다면 자료의 오른쪽 반에 대해 새로 검색을 수행
  - 찾고자 하는 값을 찾을 때까지 위 과정을 반복
  
  ```python
  list_a = [1,3,8,9,15,18,22,26,28,30,31,38,44,49,52]
  이 리스트에서 38을 찾는다고 했을 때, 38은 중간값인 26을 기준으로 오른쪽에 있으므로 1~22까지는 탐색 범위에서 제외하고, 다시 중간값인 38을 기준으로 나눈 후 22~38까지는 제외하는 방식으로 탐색 범위를 좁히며 찾는 방식이다.
  ```



3) 선형탐색과 이진탐색의 비교

- 이진탐색이 선형탐색에 비해 훨씬 적은 횟수의 탐색으로 답을 찾을 수 있다. 가장 빨리 답을 찾는 경우는 동일하게 1번의 탐색으로 가능하지만 가장 오래 걸리는 경우에서는 이진탐색이 압도적으로 빠르다. 단, 이진탐색의 경우 정렬되지 않으면 쓸 수 없다는 단점이 존재한다.

  ```python
  list_a = [1,3,8,9,15,18,22,26,28,30,31,38,44,49,52]
  선형탐색
  가장 빨리 답을 찾는 경우: 찾는 값이 1일때 1번의 탐색으로 찾을 수 있다.
  가장 오래 걸리는 경우: 찾는 값이 리스트에 없는 경우에 16번의 탐색으로 찾을 수 있다.
  이진탐색
  가장 빨리 답을 찾는 경우: 찾는 값이 26일때 1번의 탐색으로 찾을 수 있다.
  가장 오래 걸리는 경우: 찾는 값이 리스트에 없는 경우에 4번의 탐색으로 찾을 수 있다.
  ```

  | 리스트 길이 | 선형탐색 | 이진탐색 |
  | ----------- | -------- | -------- |
  | 16          | 16회     | 4회      |
  | 32          | 32회     | 5회      |
  | 64          | 64회     | 6회      |
  | 128         | 128화    | 7회      |
  | 23억        | 23억회   | 31회     |





## 이진탐색

- 이진탐색(이분탐색, binary search)
  - 정렬되어 있는 배열에서 특정 값을 찾기 위해 탐색 범위를 절반으로 줄여가며 찾는 탐색 방법
    - 업다운 게임과 유사한 방식으로 동작한다.
    - 사용하기 위해선 배열이 반드시 정렬되어 있어야 한다.
  - O(N)에 동작하는 선형 탐색과 달리 이진탐색은 O(lg N)에 동작한다.



- 찾고자 하는 값이 배열에 있는 경우

  - 배열(arr)에 14라는 값이 있는지를 확인하고자 한다.

  - 우선 배열 전체를 대상으로 세 개의 인덱스를 변수에 저장한다.

    - `mid`는 탐색 대상 배열의 중간 인덱스로 `(st+ed)/2`로 구한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      | mid  |      |      |      |      | ed   |

  - `arr[mid]`의 값이 찾고자 하는 값인 14보다 작으므로 `st`의 값을 `mid+1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      | mid  | st   |      |      |      | ed   |

  - 줄어든 범위를 대상으로 다시 `mid` 값을 설정한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   |      | mid  |      | ed   |

  - 이번에는 `arr[mid]`의 값이 찾고자 하는 값인 14보다 크므로 `en`의 값을 `mid-1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   | ed   | mid  |      |      |

  - 다시 줄어든 범위를 대상으로 mid 값을 계산하면 아래와 같다.

    | 1    | 3    | 4    | 7    | 12   | 14      | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st, mid | ed   |      |      |      |

  - `arr[mid]`의 값이 찾고자 하는 값인 14와 같으므로 탐색을 종료한다.



- 찾고자 하는 값이 배열에 없는 경우

  - 25라는 값이 배열에 있는지 확인하고자 한다.

  - 우선 배열 전체를 대상으로 세 개의 인덱스를 변수에 저장한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      | mid  |      |      |      |      | ed   |

  - `arr[mid]`의 값이 찾고자 하는 값인 25보다 작으므로 `st`의 값을 `mid+1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      | mid  | st   |      |      |      | ed   |

  - 줄어든 범위를 대상으로 다시 `mid` 값을 설정한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   |      | mid  |      | ed   |

  - 이번에는 `arr[mid]`의 값이 찾고자 하는 값인 25보다 크므로 `en`의 값을 `mid-1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   | ed   | mid  |      |      |

  - 다시 줄어든 범위를 대상으로 mid 값을 계산하면 아래와 같다.

    | 1    | 3    | 4    | 7    | 12   | 14      | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st, mid | ed   |      |      |      |

  - `arr[mid]`의 값이 찾고자 하는 값인 25보다 작으므로 st의 값을 `mid+1`로 변경하고, mid 값을 갱신한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24          | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ----------- | ---- | ---- | ---- |
    |      |      |      |      |      |      | st, ed, mid |      |      |      |

  - `arr[mid]`의 값이 찾고자 하는 값인 25보자 작으므로 `st`의 값을 `mid+1`로 변경한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24      | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- |
    |      |      |      |      |      |      | ed, mid | st   |      |      |

  - st가 ed보다 커졌으므로, 25는 배열에 없다는 것을 확정하고 탐색을 종료한다.
  
  - Python으로 구현
  
  
  ```python
  def binary_search(arr, target):
      st, ed = 0, len(arr)-1
      while st <= ed:
          mid = (st + ed) // 2
  
          if arr[mid] > target:
              ed = mid - 1
          elif arr[mid] < target:
              st = mid + 1
          else:
              return mid
      
      return -1
  ```
  



- Lower bound와 Upper bound

  - 만약 특정 값의 존재 유무가 아니라 특정 값이 몇 개가 포함되어 있는지를 알아야 하는 경우 어떻게 구현해야 하는가?

    - 예를 들어 [1,1,1,1,1,1,1,1,1,1]과 같은 배열 `arr`이 있을 때, 이 배열에 1이 포함되어 있는지 뿐 아니라 1이 몇 개가 포함되어 있는지도 알고 싶다고 해보자.
    - 이진탐색을 수행했을 때, 첫 `mid` 값은 4가 되고, `arr[mid]`의 값은 1이므로 1이 포함된다는 것은 알 수 있다.
    - 문제는 1이 몇 번 등장하는지를 알아야 한다는 것인데, `mid`를 기준으로 인덱스를 `+1`, `-1` 시키면서 1의 개수를 찾는 것은 위와 같은 경우에 배열 전체를 순회해야 하므로 선형탐색과 다를 것이 없어진다.
    - 따라서, 개수를 구해야 하는 경우에도 O(lg N)으로 구할 수 있는 방법이 필요하다.

  - Upper bound와 Lower bound를 사용하여 O(lg N)으로 포함 여부 뿐 아니라 개수까지도 구할 수 있다.

    - Upper bound는 개수를 구하려는 값 k보다 처음으로 큰 값이 나오는 위치를 의미하고, lower bound는 구하려는 값 k보다 크거나 같은 값이 처음으로 나오는 위치를 의미한다.
    - 따라서 upper bound 값에서 lower bound 값을 빼면 배열 내에 k가 몇 개 포함되어 있는지 알 수 있다.
    - 두 값은 이진탐색 방식과 거의 유사한 방식으로 구할 수 있다.
    
  - Lower bound 구하기
  
    - 주의할 점은 이진 탐색의 경우 `배열의 길이 - 1`값 까지를 대상으로 하지만, 개수를 구해야 하는 경우 찾으려는 값이 배열의 맨 마지막에 있을 수 있으므로 배열의 길이까지를 대상으로 한다는 점이다.
    - 예를 들어 [1,2,3,3]과 같은 배열에서 3의 개수를 찾으려고 할 경우, 처음으로 3보다 큰 값이 나오는 위치가 존재하지 않고, 4의 개수를 찾으려 할 경우 처음으로 4보다 크거가 같은 값이 나오는 위치가 존재하지 않으므로, 이 부분을 고려해야한다.
    - 배열 arr에서 12의 개수를 찾는다고 가정한다.
    - 먼저 `(st+ed) // 2`로 `mid`값 5를 구한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid  |      |      |      |      | ed   |
  
    - `arr[5]`는 12보다 크므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14      | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid, ed |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 2인데, `arr[2]`는 12보다 작으므로 st의 값을 `mid+1`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      | mid  | st   |      | ed   |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 4인데, `arr[4]`는 12와 같으므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12      | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      | st   | mid, ed |      |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 3으로, `arr[3]`은 12와 같으므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12          | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      | st, mid, ed |      |      |      |      |      |      |      |
  
    - `st>=ed`가 되었으므로 lower bound를 3으로 확정짓는다.
  
  - Upper bound 구하기
  
    - Lower bound와 마찬가지로 배열의 길이 만큼을 대상으로 한다.
    - Lower bound를 구할 때와 비슷한데 `arr[mid]=target`일 때만 다르게 처리해줘야한다. Lower bound를 구할 때 `arr[mid]=target`이면 `en`의 값을 `mid`로 변경했지만, upper bound를 구할 때는 `arr[mid]=target`인 경우 `st`의 값을 `mid+1`로 변경해야한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid  |      |      |      |      | ed   |
  
    - `arr[5]`는 12보다 크므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14      | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid, ed |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 2인데, `arr[2]`는 12보다 작으므로 st의 값을 `mid+1`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      | mid  | st   |      | ed   |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 4인데, `arr[4]`는 12와 같으므로 `st`의 값을 `mid+1`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14     | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ------ | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      | mid  | st, ed |      |      |      |      |      |
  
    - `st>=ed`가 되었으므로 upper bound를 5로 확정짓는다.
  
  - Python 코드 구현
  
  ```python
  def lower_bound(num):
      st, ed = 0, num_cards
      while st < ed:
          mid = (st+ed) // 2
          if cards[mid] >= num:
              ed = mid
          else:
              st = mid + 1
      return st
  
  def upper_bound(num):
      st, ed = 0, num_cards
      while st < ed:
          mid = (st+ed) // 2
          if cards[mid] > num:
              ed = mid
          else:
              st = mid + 1
      return st
  ```




- 좌표 압축(Coordinate Compression)

  - 정렬된 배열이 있을 때, 배열에 있는 각 요소를 인덱스와 매팽시키는 과정이다.
    - 예를 들어 `[4, 7, 3, 1]`은 `[2, 3, 1, 0]`과 같이 압축될 수 있다.
  - 범위가 크지만 오직 각 값들의 상대적인 위치만 신경쓰면 될 때 유용하게 사용할 수 있다.
    - 예를 들어 가능한 값의 범위가 0~10<sup>10</sup>이지만 실제로 들어오는 숫자의 개수가 10개 뿐인 숫자들의 집합이 있다고 할 때, 전체 범위를 배열의 index로 쓰는 것은 메모리 측면에서 매우 비효율적일 수 있다.
    - 실제 저장해야 하는 값은 10개 뿐인데 10개를 저장하자고 10<sup>10</sup> 크기의 배열을 생성해야 하기 때문이다.
    - 이럴 때 좌표 압축을 적용하면 `0 ~ 10-1`  사이의 숫자만으로 처리가 가능하다.
    - 즉 값의 범위가 어떻든 간에 실제 입력으로 N개의 숫자가 들어온다면 `0 ~ N-1` 내의 숫자로 변환하여 처리 할 수 있게 해준다.
  - 좌표 압축을 적용하지 않은 경우
    - 만약 x, y 좌표를 처리해야 하는 경우가 있다고 가정해보자, 각 좌표의 대소만 알면 되고, 실제 좌표 값은 사용하지 않아도 된다고 할 때, 좌표압축을 적용하면 메모리를 훨씬 절약할 수 있다.
    - 예를 들어 아래와 같은 좌표들을 가지고, 각 좌표들의 대소비교를 해야한다고 가정해보자.
    - 좌표 의 범위는 `0<=x, y <= 1000`이다.
    - 대부분의 좌표 값은 1~7 사이에 있지만 좌표 값의 범위가 최대 1000까지이므로 모든 입력 좌표들을 담기 위해서는 `board`의 크기를 1000*1000으로 선언해야한다.

  ```python
  # coordinates의 각 요소들은 [x좌표, y좌표]
  coordinates = [[1000, 1000], [1, 1], [3, 7], [5, 2]]
  board = [[0]*1000 for _ in range(1000)]
  ```

  - 좌표압축을 적용한 경우
    - 위 예시에서 좌표 압축을 적용하면 다음과 같이 `board`의 크기를 줄일 수 있다.
    - 1000\*1000크기의 좌표가 아닌 4\*4 크기의 배열로 해결이 가능하게 된다.

  ```python
  coordinates = [[1000, 1000], [1, 1], [3, 7], [5, 2]]
  # 좌표 압축
  coordinates = compress_coordinate(coordinates)
  print(coordinates)	# [[3, 3], [0, 0], [1, 2], [2, 1]]
  max_x = max([coordinate[0] for coordinate in arr])	# 3
  max_y = max([coordinate[1] for coordinate in arr])	# 3
  board = [[0]*(max_x+1) for _ in range(max_y+1)]
  ```

  - 구현 과정
    - 좌표 압축을 적용하려는 배열을 오름차순으로 정렬한다.
    - 정렬된 배열에서 중복을 제거한다.
    - 이 배열을 대상으로 특정 값이 몇 번째로 등장하는지를 찾는다.

  - 이진 탐색과의 관계
    - 좌표 압축을 구현할 때 정렬된 배열에서 중복을 제거한 후, 특정 값이 몇 번째로 등장하는지를 찾게 되는 데, 이 때 이진탐색을 사용하여 찾는다.
    - 선형탐색으로 구현해도 되지만, 탐색 시간을 줄이기 위해 주로 이진 탐색으로 구현한다.
  - 구현

  ```python
  def binary_search(arr, target):
      st, ed = 0, len(arr)-1
      while st <= ed:
          mid = (st + ed) // 2
  
          if arr[mid] > target:
              ed = mid - 1
          elif arr[mid] < target:
              st = mid + 1
          else:
              return mid
      
      return -1
      
  
  def compress_coordinate(lst):
      # 중복을 제거한 후 오름차순으로 정렬한다.
      unique_lst = sorted(list(set(lst)))
      compressed_lst = []
      for num in lst:
          # 특정 값이 몇 번째로 등장하는지를 찾는다.
          compressed = binary_search(unique_lst, num)
          compressed_lst.append(compressed)
      
      return compressed_lst
  
  
  
  print(compress_coordinate([3, 13, 2, 13, 7, 65, 42, 2]))	# [1, 3, 0, 3, 2, 5, 4, 0]
  ```

  





- 이진탐색 응용

  - 전체 순회 대상 중 일부를 묶은 후 일부만 이분 탐색 함으로써 시간 복잡도를 낮출 수 있다.
  - 예를 들어 1 이상의 정수로 이루어진 배열 arr의두 요소의 합 중에서 arr에 포함된 것들 중 최대값을 구하려고 한다고 가정해보자.
    - 즉 arr[i] + arr[j] = arr[k]인 arr[k]들 중에서 최대값을 구하려 한다고 가정해보자.
    - 가장 먼저 떠올 릴 수 있는 풀이는 O(N<sup>3</sup>)일 것이다.

  ```python
  arr = [1, 2, 3, 43, 5, 9, 21, 13, 22]
  
  max_num = 0
  for i in arr:
      for j in arr:
          for k in arr:
              if i+j == k and k > max_num:
                  max_num = k
  ```

  - 이는 이진 탐색을 활용하면 O(N<sup>2</sup>lgN)에 풀 수 있다.

  ```py
  def binary_search(num):
      st, ed = 0, len(arr) - 1
      while st <= ed:
          mid = (st + ed) // 2
          if arr[mid] > num:
              ed = mid - 1
          elif arr[mid] < num:
              st = mid + 1
          else:
              return True
  
  arr = [1, 2, 3, 43, 5, 9, 21, 13, 22]
  arr.sort()
  max_num = 0
  for i in arr:
      for j in arr:
          sum_ = i + j
          if binary_search(sum_) and sum_ > max_num:
              max_num = sum_
  
  print(max_num)
  ```



- 이분 탐색 구현시 주의사항

  - 이분 탐색 구현시 아래와 같이 무한 루프에 빠지는 경우가 있다.
    - `binary_search` 함수는 target보다 작은 원소 중 가장 큰 원소를 반환하는 함수이다.
    - 아래 함수를 실행하게 되면 무한 루프에 빠지게 된다.

  ```python
  def binary_search(target):
      st, ed = 0, len(arr)
      while st < ed:
          mid = (st + ed) // 2
  
          if arr[mid] < target:
              st = mid
          else:
              ed = mid - 1
      
      return st
  
  
  arr = [1, 5, 8, 10, 11, 13, 14, 15, 22, 27]
  print(binary_search(11))
  ```

  - 원인
    - 첫 반복이 될 때, `mid` 값이 5이므로 `arr[mid]`가 target보다 크다.
    - 따라서 `ed` 값이 4가 되고, 다음 반복을 돌 때, mid 값은 2가 되고 `arr[mid]`가 target보다 작다.
    - 따라서 `st` 값이 2가 되고, 다음 반복을 돌 때 mid 값은 3이 되고, `arr[mid]`가 target보다 작다.
    - 따라서 `st` 값이 3이 되는데, 여기서부터 문제가 발생한다.
    - `st`가 3이고, `ed`가 4이므로 `mid` 값은 또 다시 3이 되고 무한 루프에 빠지게 된다.
    - 이는 `st+ed`의 값이 항상 정수여야하기 때문에 발생하는 문제로, `st`와 `ed`의 값이 1차이가 난다면 주의해야한다.
  - 해결법
    - `mid` 값을 `(st+ed+1)//2`로 설정한다.

  ```python
  def binary_search(target):
      st, ed = 0, len(arr)
      while st < ed:
          mid = (st + ed + 1) // 2
  
          if arr[mid] < target:
              st = mid
          else:
              ed = mid - 1
      
      return st
  
  
  arr = [1, 5, 8, 10, 11, 13, 14, 15, 22, 27]
  print(binary_search(11))
  ```




- Parametric search(매개 변수 탐색)

  - 최적화 문제를 결정 문제로 변환해 이분탐색을 수행하는 방법
    - 최적화 문제: 조건을 만족하는 최대값 혹은 최소값을 구하는 문제
    - 결정 문제: True 또는 False 둘 중 하나의 답 만을 가지는 문제.
    - 최적화 문제의 답이 결정 문제의 인자로 들어가게 된다.

  - Parametric search 문제를 해결하기 위해 이분 탐색을 사용한다.

  - 예시

    - 가격 순으로 정렬된 제품의 배열이 있을 때, 가격이 5만원 이상인 것들 중 가격이 가장 싼 제품을 찾고자한다.
    - 이 때, 5만원 이상인 것들 중 가장 싼 가격 X를 찾는 것이 최적화 문제이고, X의 값이 5만원 이상인지를 판단하는 것이 결정 문제이다.
    - 즉 가격 X를 받아, X값이 주어진 조건에 부합하는지를 이진탐색을 사용하여 반복적으로 체크하는 방식이다.

    - 먼저 가장 가운데에 위치한 제품의 가격을 확인한다.
    - 만약 해당 제품의 가격이 5만원보다 작으면 그 제품 뒤에 있는 제품들을 살펴보고, 적으면 그 제품 앞에 있는 제품들을 살펴본다.
    - 예컨데 가운데 있는 제품의 가격(X 값)이 4만원이라면, 찾고자 하는 제품은 해당 제품보다 뒤에 있을 것이다.

  - 어떤 문제를 parametric search로 풀려면 아래 조건들이 충족되어야한다.

    - 결정 문제로 풀 수 있어야 한다.
    - 정답이 될 수 있는 값들이 연속적이어야한다.
    - 예를 들어 최대값을 구하는 최적화 문제에서 결정 문제를 푸는 함수 `f(x)`가 True라면, x 이상인 모든 값들에 대해서 `f(x)`는 True여야 하고, 마찬가지로 최소값을 구하는 최적화 문제에서 `f(x)`가 True라면 x 이하인 모든 값들에 대해서 `f(x)`는 True여야한다.

    - Parametric search의 개념이나 기본적인 구현 난이도 자체는 높지 않지만 문제를 보고 parametric search로 풀 수 있다는 것을 알아내기가 쉽지 않은 만큼, 위 조건들을 항상 생각해야한다.






***





# 정렬

1)선택 정렬

- 리스트 내의 모든 요소를 탐색하면서 정렬하는 방식, 각 위치에 어떤 값이 들어갈지를 찾는 방식

  ```python
  list_a = [4,2,7,1,9,3]
  여기서 첫 번째 요소인 4를 최솟값으로 지정하고 2~3까지를 비교한다.
  2는 4보다 작으므로 최솟값은 4에서 2가 된다.
  7은 2보다 크므로 최솟값은 변화가 없다.
  1은 2보다 작으므로 최솟값은 2에서 1이 된다.
  9는 1보다 크므로 최솟값은 변화가 없다.
  3은 1보다 크므로 최솟값은 변화가 없다.
  결국 리스트를 전부 탐색했을 때 1이 최솟값이므로 0번 인덱스와 1의 인덱스를 바꾼다.
  list_a = [1,2,7,4,9,3]
  이제 1은 제외하고 2부터 다시 위와 같은 과정을 반복한다.
  ```



2)삽입정렬

- 리스트에 값을 하나씩 삽입하듯 정렬하는 방식, 각 값이 어떤 위치에 들어갈지를 찾는 방식

  ```python
  list_a = [4,2,7,1,9,3]
  우선 0~1번 인덱스까지만 비교하여 4가 2보다 크므로 둘의 자리를 바꾼다.
  다음으로 0~2번 인덱스까지만 비교하여 7은 2,4보다 크므로 그대로 둔다.
  다음으로 0~3번 인덱스까지만 비교하여 1은 7보다 크므로 7을 1과 바꾼다. 4도 1보다크므로 4와 1을 바꾼다. 2도 1보다 크므로 1과 2도 바꾼다. 
  다음으로 0~4번 인덱스까지만 비교하여 9는 1,2,4,7보다 크므로 그대로 둔다.
  마지마긍로 0~5번 인덱스를 비교하요 3은 4,7,9보다 작으므로 3과 9, 3과 7, 3과 4의 자리를 바꾼다. 
  ```



3)합병정렬

- 분할정복을 사용한 정렬이므로 아래 분할정복을 읽고 올 것

- 리스트를 절반으로 나누고(divide), 왼쪽과 오른쪽을 각각 정렬(conquer)한 후, 정렬된 두 리스트를 하나의 정렬된 리스트로 합병(combine)한다.

- 세 과정 중 합병이 가장 까다롭다.

  ```python
  a = [1,3,8,9]
  b = [2,4,5,6]
  c = []
  절반으로 나눠 각기 정렬 된 리스트가 있을 때 이 둘을 정렬하는 방법은 다음과 같다.
  1. 각 리스트는 정렬되어 있으므로 첫번째 값이 가장 작을 것이다. 따라서 각 리스트의 첫 번째 값을 비교한 후 더 작은 값을 c에 넣는다.
  a = [3,8,9]
  b = [2,4,5,6]
  c = [1]
  2. 그럼 위와 같은 상태가 되는데 이 과정을 반복하면 정렬된 전체 리스트를 얻을 수 있다.
  3. 만일 정렬되지 않았을 경우 더 이상 나눌 수 없을 때 까지 더 작은 부분으로 나누어 정렬한 뒤 점점 더 큰 부분으로 정렬해 나간다.
  a = [8,3,9,1]
  b = [5,2,6,4]
  우선 a를 절반으로 나눈다.
  [8,3],[9,1]
  그 후 다시 절반으로 나눈다.
  [8],[3]/[9],[1]
  이제 [8],[3]을 정렬하여 하나의 리스트로 합하고 [9],[1]을 정렬하여 하나의 리스트로 합한다.
  [3,8]/[1,9]
  이제 위의 둘도 1~2의 과정을 통해 정렬하여 하나의 리스트로 합한다.
  [1,3,8,9]
  b도 마찬가지 과정을 거친다.
  [2,4,5,6]
  이제 1~2를 반복하면 정렬이 완료된다.
  ```
  
  

4)퀵 정렬

- 분할정복을 사용한 정렬이므로 아래 분할정복을 읽고 올 것

- 합병정렬과 달리 세 과정 중 나누는과정이 가장 까다롭다.

- 퀵 정렬에서 리스트를 나누는 과정(divide)을 파티션(partition)이라 부른다.

  - 기준점(pivot)을 정한다(divide). 꼭 리스트의 중간에 있는 값일 필요는 없다.
  - 기준점보다 더 작은 값은 기준점 왼쪽으로, 큰 값은 기준점 오른쪽으로 정렬한다(conquer).

  ```python
  1.a = [16,11,6,13,1,4,10,7]일때 7을 기준점으로 잡으면 아래와 같이 담기게 된다(divide)
  	al = [6,1,4]
  	ar = [16,11,13,10]
  2.이제 각 리스트를 정렬해야 하는데(conquer) 다시 기준점을 잡아준다(부분문제의 divide).
  2-1.al의 기준점을 4로 잡으면 아래와 같이 담기게 된다.두 리스트 모두 값이 하나뿐이므로 base case라고 	볼 수 있다.
  	all = [1] ; alr = [6]
  2-2.ar의 기준점을 13으로 잡으면 아래와 같이 담기게 된다.
  	arl = [10,11]
  	arr = [16]
  	arr은 리스트에 값이 하나뿐이므로 base case가 되지만 arl은 아니므로 또 partition을 해준다.
  	10을 기준점으로 잡으면(arll은 아무것도 담기지 않는다.)
      arlr = [11]
      base case가 나왔으므로 return하면 된다.
  3-3.모든 리스트가 정렬되었으므로 아래와 같은 리스트가 얻어진다.
      [1,4,6,7,10,11,13,16]
  ```

  ```python
  원리는 위와 같지만 이를 코드로 구현하기 위해서는 조금 다르게 생각을 해야 한다.
  a = [16,11,6,13,1,4,10,7]
  0. start지점, end지점을 설정한다(정렬할 리스트의 시작과 끝).
     -이 경우 0번 인덱스와 7번 인덱스
  1. 기준점을 잡는다.
     -이 경우 7을 기준점으로 잡는다.
  2. 탐색할 인덱스 i와 기준점보다 큰 값이 시작되는 인덱스 b를 설정한다.
     i = 0; b = 0
  3-1. list를 i를 가지고 탐색하면서 list[i]가 기준점보다 크다면 b는 그대로 두고 i에만 +1을 해준다.
  3-2. list[i]가 기준점보다 작다면 list[b]와  list[i]의 자리를 바꾸고 b와 i 둘 다 +1을 해준다.
  3-3. i가 end와 같아지면 list[b]와 list[end]를 바꿔준다.
  
  b = 0
  i = 0
  start = 0
  end = 0
  [16,11,6,13,1,4,10,7]
  list[0]인 16은 7보다 크므로 i만 +1
  list[1]인 11은 7보다 크므로 i만 +1
  list[2]인 6은 7보다 작으므로 list[b],즉 list[0]과 list[i], 즉list[2]의 위치를 바꾸고 b와 i 둘 다 +1을 해준다.
  b = 1
  i = 3
  [6,11,16,13,1,4,10,7]
  이런식으로 쭉 반복하다 i가 end와 같아지면 list[b]와 list[i], 즉 list[end]를 바꿔준다.
  [1,4,6,7,10,11,13,16]
  ```

  

5)어떤 정렬을 사용해야 하는가

- https://www.toptal.com/developers/sorting-algorithms 정렬 알고리즘별 속도를 비교해주는 사이트
- 위 사이트에 들어가보면 상황에 따른 알고리즘별 정렬 속도를 알 수 있다. 즉 상황에 따라 더 빠른 알고리즘을 사용해야 하고 어떤 상황에서 어떤 정렬알고리즘이 가장 빠른지를 판단할 수 있어야 한다.





---



# 시간복잡도

- 알고리즘의 시간을 평가하는 방식은 다양하다. 간단한 예로 알고리즘별 실행 시간을 측정하는 방법도 있다. 그러나 이는 컴퓨터의 사양, 프로그램의 요구사양, 프로그래밍 언어에 따라 달라질 수 있으므로 신뢰할 만한 결과를 얻기는 어렵다.



- 따라서 시간복잡도를 측정하는 방식을 사용한다.



1)시간복잡도(Time Complexity)

- 인풋의 크기에 따라 실행 시간이 얼마나 증가하는지를 뜻하는 개념이다. 아래의 표에서 B가 A에 비해 시간복잡도가 크다고 할 수 있고 더 느린 알고리즘이라고 할 수 있다.

  | 인풋 크기 | 알고리즘A | 알고리즘B |
  | --------- | --------- | --------- |
  | 10개      | 10초      | 10초      |
  | 20개      | 20초      | 40초      |
  | 100개     | 100초     | 1000초    |



2)시간복잡도의 배경지식

- 로그 : 거듭제곱의 반대 개념

- a를 x번 제곱해야 b가 나온다는 것은 다음과 같이 표시한다 :  log<sub>a</sub>b = x, 로그 a의 b라고 읽는다.

- 혹은 b를 a로 x번 나누어야 1이 된다고도 할 수 있다.

  ex. log<sub>2</sub>8은 3이다.

- 컴퓨터의 특성상 a값이 2인 경우가 많은데 이 경우 다음과 같이 표시하기도 한다 : lg b=x

  ex.lg 16 = 4



3)시간복잡도의 표기법

- 알고리즘 소요시간은 일반적으로 인풋의 크기에 따라 달라지게 되는데 그 식은 알고리즘에 따라 다양하게 나올 수 있다. n을 인풋의 수라고 할 때,
  - 20n + 40,    2n<sup>2</sup> + 8n + 157,   20lgn + 60
  - 위와 같이 다양하게 나올 수 있는데 n을 제외한 20,40,2,8,157,20,60 등은 컴퓨터의 사양에 따라 달라질 수 있는 수 들이다. 따라서 위와 같은 식으로는 신뢰할 만한 시간을 구할 수 없다.



4) 점근표기법(Big-O)

- 위와 같은 문제를 해결 하고자 연구자들은 점근표기법(Big-O)라는 방식으로 통일하여 표기하기로 했다.

- 점근 표기법은 소요시간에 가장 큰 영향을 미치는 요소만 남기고 나머지는 다 제거한 후 남은 요소, 즉 소요시간에 가장 큰 영향을 미치는 요소로만 표기하는 방식이다.

    | 소요시간                           | 삭제되는 것들        | 점근 표기법(Big-O) |
    | ---------------------------------- | -------------------- | ------------------ |
    | 20n+40                             | 20, 40               | O(n)               |
    | 2n<sup>2</sup> + 8n + 157          | 2, 8n, 157           | O(n<sup>2</sup>)   |
    | 20lgn + 60                         | 20, 60               | O(lg n)            |
    | 5n<sup>3</sup>+100n<sup>2</sup>+75 | 100n<sup>2</sup>, 75 | O(n<sup>3</sup>)   |
    
    - 순서대로 big of n, big of n<sup>2</sup>등으로 읽는다.



- 점근표기법의 핵심은 n이 매우 크다고 가정하는 것이다. n이 작을 수록 좋은 알고리즘과 좋지 않은 알고리즘의 소요시간이 크게 차이가 나지 않는다. 그러나 n이 커질 수록 소요시간에 가장 큰 영향을 미치는 요소의 영향력이 커지게 된다.

  | input의 크기(n) | n<sup>2</sup> | 8n + 157 |
  | --------------- | ------------- | -------- |
  | 5               | 25            | 197      |
  | 10              | 100           | 237      |
  | 100             | 10000         | 957      |
  | 1000            | 1000000       | 8157     |
  | 100000          | 10000000000   | 800157   |

  - 위와 같이 인풋의 크기가 커질수록 가장 큰 영향을 미치는 요소(위의 경우 n<sup>2</sup>)의 영향이 커지게 된다.
  - 위의 예에서 n이 십만인 경우 n<sup>2</sup>은 100억이 되지만 8n + 157은 8십만이 조금 넘는다. 따라서 인풋이 커질수록, 영향을 덜 미치는 요소들(위의 경우 8n + 157)은 고려할 가치가 없어지게 된다.



- 점근표기법의 의미
  - O(1): 인풋의 크기가 소요시간에 영향을 미치지 않는다. 반복문이 없으면 대체로 O(1)이다.

    - 2n<sup>2</sup>에서 2를 무시하고 O(n<sup>2</sup> )로 표기하는 것 처럼 O(x)도 마찬가지로 x가 몇이든 1로 표기한다. 왜냐하면 인풋의 크기와 무관하게 소요시간이 같으므로 x가 무엇이 되든 시간복잡도에는 영향을 미치지 않는다.

      ex.O(1) = O(4) = O(10000) 모두 O(1)과 같다고 간주한다. 
      
      

  - O(n): 리스트의 크기에 정비례하여 소요시간이 증가한다. 반복문이 있고 반복되는 횟수가 인풋의 크기에 비례하면 일반적으로 O(n)이다.

    cf. 2n번 반복하든 0.5n번 반복하든 앞의 수(이 경우 2, 0.5)는 버리므로 모두  O(n)이다. 즉 인풋만큼 반복하는 가와 무관하게 인풋의 크기에 비례해서 반복한다면  대체로 O(n)이다. 

    cf. 반복문 안에 반복문이 있는 형태가 아닌 여러 반복문이 독립적으로 있을 경우에도 O(n)이다.

    ```python
    N = int(input())
    
    cnt=0	#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
    for i in range(N):		#O(1)*반복횟수(N)
        cnt+=1
        
    for i in range(N):		#O(1)*반복횟수(N)
        cnt-=1
        
    이 경우 O(n)+O(n)+O(1)이 되어 O(2n+1)이지만 2와 1은 버리므로 반복문 2개가 들어간 이 코드의 복잡도는 O(n)이다. 반복문이 중첩되지 않는다면 반복문 몇 개가 들어가도 마찬가지다.
    ```

  

  - O(n<sup>2</sup>): 리스트의 크기가 증가하면 그 제곱만큼 초가 증가한다.
    - 반복문이 중첩된 경우(이중 반복문) 대체로 O(n<sup>2</sup>)이다.

  

  - O(n<sup>3</sup>): 리스트의 크기가 증가하면 그 세제곱만큼 초가 증가한다.	
    - 반복문이 3중으로 중첩된 경우 대체로 O(n<sup>2</sup>)이다.

| 인풋의 크기(n) | O(1) | O(n)  | O(n<sup>2</sup>) | O(n<sup>3</sup>) |
| -------------- | ---- | ----- | ---------------- | ---------------- |
| 100            | 1초  | 1초   | 1초              | 1초              |
| 200            | 1초  | 2초   | 4초              | 8초              |
| 1000           | 1초  | 10초  | 100초            | 1000초           |
| 10000          | 1초  | 100초 | 10000초          | 1000000초        |





5)알고리즘 평가

- 알고리즘을 점근표기법으로 평가하는 방법을 선형탐색을 예로 들어서 살펴보면 다음과 같다.

  ```python
  def linear_search(element, some_list):
      i = 0			#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      n = len(some_list)   #인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      
      while i < n:					#O(1)*반복횟수(n), 이 경우 리스트의 길이가 인풋의 크기다.
          if some_list[i] == element:
              return i
          i += 1
          
  return None				#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
  
  가장 빠른 경우는 찾는 값(element)가 0번 인덱스에 있는 경우로
  1번 반복하므로 O(1)*반복횟수(n)=O(1)이 되고 모든 O를 더하면
  O(1)+O(1)+O(1)+O(1) = O(4)가된다.
  또한 O(4) = O(1)이므로 시간복잡도는 O(1)가 된다.
  
  가장 느린 경우는 찾는 값이 없는 경우로
  n번 반복하므로  O(1)*반복횟수(n)=O(n)이 되고 모든 O를 더하면
  O(1)+O(1)+O(n)+O(1) = O(n+3)이 된다.
  이때 3은 무시해도 되므로 시간복잡도는 O(n)이 된다.
  
  따라서 선형 탐색 알고리즘은 일반적으로 O(n)라 부른다.
  ```



- 이번에는 이진탐색을 예로 들어서 살펴보면

  ```python
  def binary_search(element, some_list):
      st = 0				#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      ed = len(some_list)-1	#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      
          while st <= ed:			#O(1)*반복횟수(n), 이 경우 리스트의 길이가 인풋의 크기다.
          	mid = (st+ed)//2
          	if some_list[mid] == element:
              	return mid
          	elif some_list[mid] > element:
              	ed = mid-1
          	else:
              	st = mid+1
                  
  		return None			#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
  
  가장 빠른 경우는 찾는 값(element)가 mid 인덱스에 있는 경우로
  1번 반복하므로 O(1)*반복횟수(n)=O(1)이 되고 모든 O를 더하면
  O(1)+O(1)+O(1)+O(1) = O(4)가된다.
  또한 O(4) = O(1)이므로 시간복잡도는 O(1)가 된다.
  
  가장 느린 경우는 찾는 값이 없는 경우로
  한 번의 반복마다 절만씩 줄어들기에 총 lg n번 반복된다. 따라서 O(lg n)이 되고 모든 O를 더하면
  O(1)+O(1)+O(lg n)+O(1) = O(lg n)+3이 된다.
  이때 3은 무시해도 되므로 시간복잡도는 O(lg n)이 된다.
  
  따라서 이진 탐색 알고리즘은 일반적으로 O(lg n)라 부른다.
  ```



- 코드 없이 시간복잡도를 평가하는 방법
  - 최악의 경우를 상정하고 그 경우 몇 번의 반복이 일어나는지 생각하면 된다.
  - 위의 두 예에서 최악의 경우를 상정한 것도 그런 이유 때문이다.



6)공간 복잡도

- 인풋의 크기에 비례해서 알고리즘이 사용하는 메모리 공간을 나타내는 개념이다. 
- 역시 마찬가지로 점근표기법으로 표현한다.  
- 시간복잡도 평가와 유사한 방식으로 평가하지만 지금은 디테일하게 다루지 않는다.





---







# 재귀함수

- 함수 안에 함수가 들어있는 형태로 영화 [인셉션]이나 마트료시카를 생각하면 된다.

- 재귀적으로 문제를 푼다는 것은 결국 같은 형태의 더 작은 문제(부분문제)를 풀고 이를 이용하여 전체 문제를 푸는 것이다.

  ex.5! = 5\*4\*3\*2\*1인데 4!=4\*3\*2\*1 이므로 4!는 5!의 부분문제라고 할 수 있다. 
  마찬가지로 3! =3\*2\*1이므로 3!는 4!의 부분문제라고 할 수 있다.

- 재귀적으로 풀 때 또 하나 생각해야 할 것은 base case와 recursive case이다. base케이스는 문제가 충분히 작아서 바로 풀 수 있는 경우이고 recursive case는 재귀적(더 작은 부분문제로 나눠)으로 문제를 풀어야 하는 것이다.

  ex. n! 에서 n=0일때 0 != 1이다. 이는 바로 풀수 있고 더 작은 부분문제로 나눠지지도 않으므로 base case라고 할 수 있다. 반면 n > 0일때 n!=n(n-1)!*n이다. 이는 더 작은 문제로 나뉠 수 있으므로 recursive case이다.

- 반복문으로 풀 수 있는 문제는 재귀함수로도 풀 수 있고 그 역도 마찬가지다.
  
  - 단 재귀함수의 경우 지나치게 많이 재귀호출을 할 경우 call stack이 과부화되어 StackOverflowError가 발생(python의 경우 call stack이 1,000으로 제한되어 있다)한다. 따라서 재귀호출을 지나치게 많이 할 것 같을 경우 반복문으로 푸는 것이 나을 수 있다.







---





# 알고리즘 패러다임

- 알고리즘 문제에는 다양한 접근법이 존재하는데 이중 유사한 접근법들을 묶어서 알고리즘 패러다임이라 한다.

1)Brute Force(완전 탐색이라고도 부른다)

- 가능한 모든 방법을 시도하는 방식
- 모든 알고리즘의 시작점이라고도 할 수 있으며 Brute Force 방식으로 생각한 후 더 효율적인 방법을 찾는 것이바람직하다
-  코드가 직관적이고 확실한 답을 얻을 수 있다는 장점이 있다.
-  비효율적이고 인풋이 커질수록 시간이 점점 더 오래 걸린다는 단점이 있다.

​	ex. 비밀번호가 0000~9999일 때 모두 하나씩 입력해 보는 방식

- 동적 계획법이나 백트래킹도 완전탐색의 일종이다. 다만 시간을 더 줄일 수 있는 방식이다.



2)Divide and Conquer(분할정복)

- 문제를 부분 문제로 나눠(divide)서 부분문제의 해를 구한 후(conquer), 부분문제의 해를 통해 전체 문제를 해결(combine)하는 방식
- Top-down Approach
 - divide ,conquer, combine의 세 단계를 거쳐 문제를 해결한다.
   	- 이 때 부분문제가 더 작은 부분문제로 나뉠 수 있다면 문제가 충분히 작아질 때 까지 conquer 또한 다시 divde,conquer,combine으로 나뉘게 된다.
	- 위의 설명에서 알 수 있듯이 재귀함수와 매우 밀접한 연관을 지니는 패러다임이다.
	- 1~8의 합을 구할 경우 아래 그림과 같이 더 작은 문제들로 분할하여 base case인 1~1의 합 ~ 8~8의 합을 구한 후 이를 통해 상위문제의 해를 구하는 식으로 합을 구한다.

| 1~8의 합 |          |          |          |          |          |          |          |
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |
| 1~4의 합 |          |          |          | 5~8의 합 |          |          |          |
| 1~2의합  |          | 3~4의 합 |          | 5~6의 합 |          | 7~8의 합 |          |
| 1~1의 합 | 2~2의 합 | 3~3의 합 | 4~4의 합 | 5~5의 합 | 6~6의 합 | 7~7의 합 | 8~8의 합 |



3)Dynamic Programming(동적 계획법)

- 중복되는 문제들을 계속 풀어야 하는 비효율을 해결하는 프로그래밍, 한번 계산한 결과를 재활용하는 방식이라고 할 수 있다.



- 동적계획법을 사용하기 위해서는 아래의 두 조건이 충족되어야 한다.

  - 최적 부분 구조(Optimal Substructure)
    - 부분문제들의 최적을 답을 이용해서 기존문제(전체문제)의 최적의 답을 구할 수 있는 구조
    - 예를들어 fibo(5)는 fibo(4)와 fibo(3)의 답으로 답을 얻을 수 있으므로 이에 해당한다.
  - 중복되는 부분 문제(Overlapping Subproblems)
    
  - 예를들어 fibo(5)는 fibo(4)를 1번, fibo(3)을 2번, fibo(2)를 3번, fibo(1)을 2번 계산해야 하는데 fibo(3), fibo(2), fibo(1)은 중복되는 부분문제들이다.
    
    - 합병정렬의 경우 절반으로 나뉜 리스트에 중복된 값이 없을 것이므로 중복되는 부분 문제가 없다.
    
      

- 중복되는 부분 문제가 있다(조건2)면 중복되는 문제들을 계속 풀어야 해서 비효율적이다. 이를 해결하기 위해 만일 최적 부문구조가 있을 경우(조건1) 동적계획법으로 이 비효율을 해결할 수 있다. 즉 중복되는 부분 문제가 있다는 것은 동적 계획법을 쓸 필요가 있다는 것이고 최적 부분 구조를 지닌다는 것은 동적 계획법을 쓸 수 있다는 것이다.



- 다이나믹 프로그래밍을 구현하는 두 가지 방법

  (1)Memoization

  - 동일한 계산을 해야 할 때마다 다시 계산하는 대신 한 번 계산한 값을 기록해두고 이후에 동일한 계산을 해야하면 기록한 값을 읽어오는 것. 따라서 중복되는 부분문제를 딱 1번씩만 풀면 된다.
    - ex. 아메리카노(100원), 에스프레소(200)원, 쥬스(300)원일 때 모든 계산 결과들(7가지 경우)을 모두 기록해 놓는 것이다. 이렇게 하면 만일 누군가 아메리카노와 쥬스를 시킨다면 100+300을 계산하는 것이 아니라 이미 기록해둔 400이라는 값을 읽어오면 된다.

  (2)Tabulation

  - 표에 기록하는 방식이라 하여 Tab(le)ulation이라 부른다.

  - 재귀를 기반으로 하는 메모이제이션과 달리 타뷸레이션은 반복문을 사용한다.
  - 또한 fibo(5)를 구하기 위해 fibo(4)를 구해야 하고, fibo(4)를 구하기 위해 fibo(3)를 구해야 하는 것 처럼 하향식 접근을 취하는 메모이제이션에 비해 타뷸레이션은 fibo(5)를 구하기 위해 fibo(1)부터 fibo(5)까지 구해나가는 상향식 접근을 취한다.

  (3)메모이제이션의 경우 재귀를 기반으로 하므로 재귀호출이 지나치게 깊어지면 실행이 안될 수 있다는 단점이 있고 타뷸레이션은 처음부터 끝까지 모든 값을 계산하며 올라가므로 필요없는 값도 계산하는 경우가 생긴다. 반면에 메모이제이션은 위에서 부터 필요한 값만 계산하며 내려오므로 이런 경우가 없다.

  ​	ex. 임의의 함수 f(8)은 f(6)+f(2)로 구할 수 있고 f(6)은 f(4)+f(2)로 구할 수 있고 f(4)는 f(2)+f(2)로 구할 수 있을 	때 메모이제이션은 f(8)을 구하기 위해 f(6),f(4),f(2) 만 구하면 되지만 타뷸레이션은 f(1)~f(8)까지 모두 계산	해야 한다.

  

- 공간 사용의 최적화

  - 메모이제이션은 메모에, 타뷸레이션은 테이블에(둘 다 리스트나 딕셔너리에 저장하긴 하지만) 지금까지 계산한 값들을 저장하는데 이는 비효율적일 수 있다.

    - 예를 들어 메모이제이션으로 fibo(5)를 계산하는데에는 fibo(4)와 fibo(3)이 필요하고 fibo(4)를 계산하는 데에는 fibo(3)과 fibo(2)가 필요하다. fibo(3)을 계산하는 데에는 다시 fibo(2)와 fibo(1)이 필요한데 정작 우리가 원하는 값인 fibo(5)는  fibo(4)와 fibo(3)만 알면 구할 수 있다. 따라서 fibo(4)와 fibo(3)을 구한 순간 fibo(2)와 fibo(1)은 더 이상 필요 없음에도 리스트(메모)에서 공간만 잡아먹게 된다.

    - 타퓰레이션도 마찬가지로 fibo(5)를 계산하는데에는 fibo(4)와 fibo(3)만 알면 되는데, fibo(3)을 계산해서 테이블에 적은 순간 fibo(1)은 필요 없는 값이 되고(fibo3+n을 계산하는데 쓰이지 않으므로) fibo(4)를 계산한 순간 fibo(2)는 필요없는 값이 된다. 그럼에도 여전히 리스트(테이블)에 남아 있다.

    - 따라서 다음 단계의 계산에 필요한 두 값, fibo(n)을 구할 경우 fibo(n-1)과 fibo(n-2)를 각각 a, b에 넣고 계산이 끝날 때 마다. b에 a값을 넣고, a에  fibo(n)값을 넣으면 변수 2개로 해결 할 수 있다.

      ```python
      fibo(5)= fibo(4)+fibo(3)
      fibo(4)= fibo(3)+fibo(2)
      fibo(3)= fibo(2)+fibo(1)
      이므로 fibo(n-1)과 fibo(n-2)를 각기 a,b에 넣으면 다음과 같이 표현 할 수 있다.
      a = fibo(2)
      b = fibo(1)
      fibo(3) = a+b
      b = a
      a = fibo(3)
      fibo(4) = a+b
      b = a
      a = fibo(4)
      fibo(5) = a+b
      ```

      

4)Greedt Algorithm(탐욕 알고리즘)

- 미래를 내다보지 않고, 당장 눈 앞에 보이는 최적의 선택을 하는 방식

- 장단점은 다음과 같다.

  - 장점: 빠르고 간단하게 구현 가능하다.
  - 단점: 최적의 답이 보장되지 않는다.

- 다른 알고리즘으로는 고려해야 할 사항이 너무 많아서 시간 내에 할 수 없을 때, 혹은 최적의 답이 없을 때 마지막 대안으로 사용.

- 탐욕 알고리즘이 최적의 답을 보장해 주는 문제도 간혹 있는데 다음의 두 조건을 모두 충족하는 경우이다.

  - 최적 부분 구조일 경우 부분 문제의 최적의 답으로 기존 문제의 최적의 답을 찾을 수 있으므로 탐욕 알고리즘으로 최적의 답을 구할 수 있다.
  -  탐욕적 선택 속성(Greedy Choice Property)이 있는 경우이다. 이는 각 단계에서 탐욕스런 선택이 최종 답을 구하기 위한 최적의 선택임을 의미한다.

  ```python
  #최대한 적은 동전으로 거슬러주는 문제는 위의 두 조건을 모두 지니고 있는 문제이다.
   예를 들어 1700을 거슬러줘야 한다고 할 때 첫 동전으로 500원을 거슬러 준다면 1200원을 최대한 적은 동전으로 거슬러주는 부분 문제를 풀어야 하고 첫 동전으로 100원을 거슬러 준다면 1600원을 최대한 적은 동전으로 거슬러주는 부분 문제를 풀어야 한다. 따라서 최적 부분 구조가 있다. 
   또한 매 순간마다 최대한 큰 동전을 고를 수도 있다.예를 들어 660원을 거슬러 줄 경우 가장 큰 동전인 500원을 선택하고 남은 160원에서 가장 큰 동전인 100원을 선택하고 남은 60원에서 가장 큰 50원을 선택하고 마지막으로 가장 큰 동전인 10원을 선택하면 가장 큰 동전을 고른다는 탐욕스런 선택만으로 최적의 답을 구하게 된다. 따라서 이 문제에는 탐욕적 선택 속성이 존재한다.
  ```

  

















