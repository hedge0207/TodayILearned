# 선형 탐색과 이진 탐색

- 선형 탐색과 이진 탐색

  - 선형 탐색
    - 앞에서부터 순차적으로 탐색해 나가는 것을 선형탐색이라고 부른다.
    - 예를 들어 아래 배열에서 38을 찾는다고 했을 때 1부터 52까지 순서대로 하나씩 확인하는 방식이 선형탐색
    

  ```python
  arr = [1,3,8,9,15,18,22,26,28,30,31,38,44,49,52]
  ```

  - 이진 탐색
    - 중간값을 기준으로 계속해서 탐색 범위를 좁혀가며 탐색하는 것을 이진탐색이라 부르며, 아래 순서로 진행한다.

    - 자료의 중앙에 있는 원소 선택한다.
    - 중앙 원소의 값고 찾고자 하는 목표값을 비교한다.
    - 목표값이 중앙 원소의 값보다 작으면 자료의 왼쪽 반에 대해서 새로 검색을 수행, 크다면 자료의 오른쪽 반에 대해 새로 검색을 수행한다.
    - 찾고자 하는 값을 찾을 때까지 위 과정을 반복한다.
    - 예를 들어 아래 배열에서 38을 찾는다고 했을 때, 38은 중간값인 26을 기준으로 오른쪽에 있으므로 1~22까지는 탐색 범위에서 제외하고, 다시 중간값인 38을 기준으로 나눈 후 22~38까지는 제외하는 방식으로 탐색 범위를 좁히며 찾는 방식이다.
    - 배열이 정렬되어 있어야 사용이 가능하다.


  ```python
  arr = [1,3,8,9,15,18,22,26,28,30,31,38,44,49,52]
  ```

  - 선형탐색과 이진탐색의 비교
    - 이진탐색이 선형탐색에 비해 훨씬 적은 횟수의 탐색으로 답을 찾을 수 있다. 
    - 가장 빨리 답을 찾는 경우는 동일하게 1번의 탐색으로 가능하지만 가장 오래 걸리는 경우에서는 이진탐색이 압도적으로 빠르다. 
    - 단, 이진탐색의 경우 정렬되지 않으면 쓸 수 없다는 단점이 존재한다.
    - 예를 들어 아래 배열에서 선형 탐색은 찾는 값이 1일 때 1번의 탐색으로 찾을 수 있지만, 찾는 값이 배열에 없는 경우 모든 요소를 탐색해야 한다.
    - 반면 이진 탐색은 찾는 값이 중앙값인 26일 때 1번의 탐색으로 찾을 수 있고, 찾는 값이 배열에 없는 경우 4번의 탐색만 하면 된다.


  ```python
  arr = [1,3,8,9,15,18,22,26,28,30,31,38,44,49,52]
  ```

  - 최악의 경우(배열에 찾고자 하는 값이 없는 경우)일 경우 배열 길이별 각 방식의 탐색 횟수를 표로 나타내면 아래와 같다.
    - 이진 탐색이 선형 탐색에 비해 월등히 빠른 것을 확인할 수 있다.
    - O(N)에 동작하는 선형 탐색과 달리 이진탐색은 O(lg N)에 동작한다.

  | 배열 길이 | 선형탐색 | 이진탐색 |
  | --------- | -------- | -------- |
  | 16        | 16회     | 4회      |
  | 32        | 32회     | 5회      |
  | 64        | 64회     | 6회      |
  | 128       | 128화    | 7회      |
  | 23억      | 23억회   | 31회     |





## 이진 탐색

- 이진탐색에서 찾고자 하는 값이 배열에 있는 경우

  - 배열(arr)에 14라는 값이 있는지를 확인하고자 한다.

  - 우선 배열 전체를 대상으로 세 개의 인덱스를 변수에 저장한다.

    - `mid`는 탐색 대상 배열의 중간 인덱스로 `(st+ed)/2`로 구한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      | mid  |      |      |      |      | ed   |

  - `arr[mid]`의 값이 찾고자 하는 값인 14보다 작으므로 `st`의 값을 `mid+1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      | mid  | st   |      |      |      | ed   |

  - 줄어든 범위를 대상으로 다시 `mid` 값을 설정한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   |      | mid  |      | ed   |

  - 이번에는 `arr[mid]`의 값이 찾고자 하는 값인 14보다 크므로 `en`의 값을 `mid-1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   | ed   | mid  |      |      |

  - 다시 줄어든 범위를 대상으로 mid 값을 계산하면 아래와 같다.

    | 1    | 3    | 4    | 7    | 12   | 14      | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st, mid | ed   |      |      |      |

  - `arr[mid]`의 값이 찾고자 하는 값인 14와 같으므로 탐색을 종료한다.



- 이진 탐색에서 찾고자 하는 값이 배열에 없는 경우

  - 25라는 값이 배열에 있는지 확인하고자 한다.

  - 우선 배열 전체를 대상으로 세 개의 인덱스를 변수에 저장한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      | mid  |      |      |      |      | ed   |

  - `arr[mid]`의 값이 찾고자 하는 값인 25보다 작으므로 `st`의 값을 `mid+1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      | mid  | st   |      |      |      | ed   |

  - 줄어든 범위를 대상으로 다시 `mid` 값을 설정한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   |      | mid  |      | ed   |

  - 이번에는 `arr[mid]`의 값이 찾고자 하는 값인 25보다 크므로 `en`의 값을 `mid-1`로 변경해 탐색 범위를 절반으로 줄인다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st   | ed   | mid  |      |      |

  - 다시 줄어든 범위를 대상으로 mid 값을 계산하면 아래와 같다.

    | 1    | 3    | 4    | 7    | 12   | 14      | 24   | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | st, mid | ed   |      |      |      |

  - `arr[mid]`의 값이 찾고자 하는 값인 25보다 작으므로 st의 값을 `mid+1`로 변경하고, mid 값을 갱신한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24          | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ----------- | ---- | ---- | ---- |
    |      |      |      |      |      |      | st, ed, mid |      |      |      |

  - `arr[mid]`의 값이 찾고자 하는 값인 25보자 작으므로 `st`의 값을 `mid+1`로 변경한다.

    | 1    | 3    | 4    | 7    | 12   | 14   | 24      | 27   | 28   | 31   |
    | ---- | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- |
    |      |      |      |      |      |      | ed, mid | st   |      |      |

  - st가 ed보다 커졌으므로, 25는 배열에 없다는 것을 확정하고 탐색을 종료한다.
  
  - Python으로 구현하면 아래와 같다.
  
  
  ```python
  def binary_search(arr, target):
      st, ed = 0, len(arr)-1
      while st <= ed:
          mid = (st + ed) // 2
  
          if arr[mid] > target:
              ed = mid - 1
          elif arr[mid] < target:
              st = mid + 1
          else:
              return mid
      
      return -1
  ```
  



- Lower bound와 Upper bound

  - 만약 특정 값의 존재 유무가 아니라 특정 값이 몇 개가 포함되어 있는지를 알아야 하는 경우 어떻게 구현해야 하는가?

    - 예를 들어 [1,1,1,1,1,1,1,1,1,1]과 같은 배열 `arr`이 있을 때, 이 배열에 1이 포함되어 있는지 뿐 아니라 1이 몇 개가 포함되어 있는지도 알고 싶다고 해보자.
    - 이진탐색을 수행했을 때, 첫 `mid` 값은 4가 되고, `arr[mid]`의 값은 1이므로 1이 포함된다는 것은 알 수 있다.
    - 문제는 1이 몇 번 등장하는지를 알아야 한다는 것인데, `mid`를 기준으로 인덱스를 `+1`, `-1` 시키면서 1의 개수를 찾는 것은 위와 같은 경우에 배열 전체를 순회해야 하므로 선형탐색과 다를 것이 없어진다.
    - 따라서, 개수를 구해야 하는 경우에도 O(lg N)으로 구할 수 있는 방법이 필요하다.

  - Upper bound와 Lower bound를 사용하여 O(lg N)으로 포함 여부 뿐 아니라 개수까지도 구할 수 있다.

    - Upper bound는 개수를 구하려는 값 k보다 처음으로 큰 값이 나오는 위치를 의미하고, lower bound는 구하려는 값 k보다 크거나 같은 값이 처음으로 나오는 위치를 의미한다.
    - 따라서 upper bound 값에서 lower bound 값을 빼면 배열 내에 k가 몇 개 포함되어 있는지 알 수 있다.
    - 두 값은 이진탐색 방식과 거의 유사한 방식으로 구할 수 있다.
    
  - Lower bound 구하기
  
    - 주의할 점은 이진 탐색의 경우 `배열의 길이 - 1`값 까지를 대상으로 하지만, 개수를 구해야 하는 경우 찾으려는 값이 배열의 맨 마지막에 있을 수 있으므로 배열의 길이까지를 대상으로 한다는 점이다.
    - 예를 들어 [1,2,3,3]과 같은 배열에서 3의 개수를 찾으려고 할 경우, 처음으로 3보다 큰 값이 나오는 위치가 존재하지 않고, 4의 개수를 찾으려 할 경우 처음으로 4보다 크거가 같은 값이 나오는 위치가 존재하지 않으므로, 이 부분을 고려해야한다.
    - 배열 arr에서 12의 개수를 찾는다고 가정한다.
    - 먼저 `(st+ed) // 2`로 `mid`값 5를 구한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid  |      |      |      |      | ed   |
  
    - `arr[5]`는 12보다 크므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14      | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid, ed |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 2인데, `arr[2]`는 12보다 작으므로 st의 값을 `mid+1`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      | mid  | st   |      | ed   |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 4인데, `arr[4]`는 12와 같으므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12      | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      | st   | mid, ed |      |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 3으로, `arr[3]`은 12와 같으므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12          | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      | st, mid, ed |      |      |      |      |      |      |      |
  
    - `st>=ed`가 되었으므로 lower bound를 3으로 확정짓는다.
  
  - Upper bound 구하기
  
    - Lower bound와 마찬가지로 배열의 길이 만큼을 대상으로 한다.
    - Lower bound를 구할 때와 비슷한데 `arr[mid]=target`일 때만 다르게 처리해줘야한다. Lower bound를 구할 때 `arr[mid]=target`이면 `en`의 값을 `mid`로 변경했지만, upper bound를 구할 때는 `arr[mid]=target`인 경우 `st`의 값을 `mid+1`로 변경해야한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid  |      |      |      |      | ed   |
  
    - `arr[5]`는 12보다 크므로 `ed`의 값을 `mid`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14      | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ------- | ---- | ---- | ---- | ---- | ---- |
    | st   |      |      |      |      | mid, ed |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 2인데, `arr[2]`는 12보다 작으므로 st의 값을 `mid+1`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14   | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      | mid  | st   |      | ed   |      |      |      |      |      |
  
    - 다시 `mid`의 값을 계산하면 4인데, `arr[4]`는 12와 같으므로 `st`의 값을 `mid+1`로 변경한다.
  
    | 1    | 3    | 4    | 12   | 12   | 14     | 24   | 27   | 28   | 32   |      |
    | ---- | ---- | ---- | ---- | ---- | ------ | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      | mid  | st, ed |      |      |      |      |      |
  
    - `st>=ed`가 되었으므로 upper bound를 5로 확정짓는다.
  
  - Python 코드 구현
  
  ```python
  def lower_bound(num):
      st, ed = 0, num_cards
      while st < ed:
          mid = (st+ed) // 2
          if cards[mid] >= num:
              ed = mid
          else:
              st = mid + 1
      return st
  
  def upper_bound(num):
      st, ed = 0, num_cards
      while st < ed:
          mid = (st+ed) // 2
          if cards[mid] > num:
              ed = mid
          else:
              st = mid + 1
      return st
  ```




- 좌표 압축(Coordinate Compression)

  - 정렬된 배열이 있을 때, 배열에 있는 각 요소를 인덱스와 매팽시키는 과정이다.
    - 예를 들어 `[4, 7, 3, 1]`은 `[2, 3, 1, 0]`과 같이 압축될 수 있다.
  - 범위가 크지만 오직 각 값들의 상대적인 위치만 신경쓰면 될 때 유용하게 사용할 수 있다.
    - 예를 들어 가능한 값의 범위가 0~10<sup>10</sup>이지만 실제로 들어오는 숫자의 개수가 10개 뿐인 숫자들의 집합이 있다고 할 때, 전체 범위를 배열의 index로 쓰는 것은 메모리 측면에서 매우 비효율적일 수 있다.
    - 실제 저장해야 하는 값은 10개 뿐인데 10개를 저장하자고 10<sup>10</sup> 크기의 배열을 생성해야 하기 때문이다.
    - 이럴 때 좌표 압축을 적용하면 `0 ~ 10-1`  사이의 숫자만으로 처리가 가능하다.
    - 즉 값의 범위가 어떻든 간에 실제 입력으로 N개의 숫자가 들어온다면 `0 ~ N-1` 내의 숫자로 변환하여 처리 할 수 있게 해준다.
  - 좌표 압축을 적용하지 않은 경우
    - 만약 x, y 좌표를 처리해야 하는 경우가 있다고 가정해보자, 각 좌표의 대소만 알면 되고, 실제 좌표 값은 사용하지 않아도 된다고 할 때, 좌표압축을 적용하면 메모리를 훨씬 절약할 수 있다.
    - 예를 들어 아래와 같은 좌표들을 가지고, 각 좌표들의 대소비교를 해야한다고 가정해보자.
    - 좌표 의 범위는 `0<=x, y <= 1000`이다.
    - 대부분의 좌표 값은 1~7 사이에 있지만 좌표 값의 범위가 최대 1000까지이므로 모든 입력 좌표들을 담기 위해서는 `board`의 크기를 1000*1000으로 선언해야한다.

  ```python
  # coordinates의 각 요소들은 [x좌표, y좌표]
  coordinates = [[1000, 1000], [1, 1], [3, 7], [5, 2]]
  board = [[0]*1000 for _ in range(1000)]
  ```

  - 좌표압축을 적용한 경우
    - 위 예시에서 좌표 압축을 적용하면 다음과 같이 `board`의 크기를 줄일 수 있다.
    - 1000\*1000크기의 좌표가 아닌 4\*4 크기의 배열로 해결이 가능하게 된다.

  ```python
  coordinates = [[1000, 1000], [1, 1], [3, 7], [5, 2]]
  # 좌표 압축
  coordinates = compress_coordinate(coordinates)
  print(coordinates)	# [[3, 3], [0, 0], [1, 2], [2, 1]]
  max_x = max([coordinate[0] for coordinate in arr])	# 3
  max_y = max([coordinate[1] for coordinate in arr])	# 3
  board = [[0]*(max_x+1) for _ in range(max_y+1)]
  ```

  - 구현 과정
    - 좌표 압축을 적용하려는 배열을 오름차순으로 정렬한다.
    - 정렬된 배열에서 중복을 제거한다.
    - 이 배열을 대상으로 특정 값이 몇 번째로 등장하는지를 찾는다.

  - 이진 탐색과의 관계
    - 좌표 압축을 구현할 때 정렬된 배열에서 중복을 제거한 후, 특정 값이 몇 번째로 등장하는지를 찾게 되는 데, 이 때 이진탐색을 사용하여 찾는다.
    - 선형탐색으로 구현해도 되지만, 탐색 시간을 줄이기 위해 주로 이진 탐색으로 구현한다.
  - 구현

  ```python
  def binary_search(arr, target):
      st, ed = 0, len(arr)-1
      while st <= ed:
          mid = (st + ed) // 2
  
          if arr[mid] > target:
              ed = mid - 1
          elif arr[mid] < target:
              st = mid + 1
          else:
              return mid
      
      return -1
      
  
  def compress_coordinate(lst):
      # 중복을 제거한 후 오름차순으로 정렬한다.
      unique_lst = sorted(list(set(lst)))
      compressed_lst = []
      for num in lst:
          # 특정 값이 몇 번째로 등장하는지를 찾는다.
          compressed = binary_search(unique_lst, num)
          compressed_lst.append(compressed)
      
      return compressed_lst
  
  
  
  print(compress_coordinate([3, 13, 2, 13, 7, 65, 42, 2]))	# [1, 3, 0, 3, 2, 5, 4, 0]
  ```




- 이진탐색 응용

  - 전체 순회 대상 중 일부를 묶은 후 일부만 이분 탐색 함으로써 시간 복잡도를 낮출 수 있다.
  - 예를 들어 1 이상의 정수로 이루어진 배열 arr의두 요소의 합 중에서 arr에 포함된 것들 중 최대값을 구하려고 한다고 가정해보자.
    - 즉 arr[i] + arr[j] = arr[k]인 arr[k]들 중에서 최대값을 구하려 한다고 가정해보자.
    - 가장 먼저 떠올 릴 수 있는 풀이는 O(N<sup>3</sup>)일 것이다.

  ```python
  arr = [1, 2, 3, 43, 5, 9, 21, 13, 22]
  
  max_num = 0
  for i in arr:
      for j in arr:
          for k in arr:
              if i+j == k and k > max_num:
                  max_num = k
  ```

  - 이는 이진 탐색을 활용하면 O(N<sup>2</sup>lgN)에 풀 수 있다.

  ```py
  def binary_search(num):
      st, ed = 0, len(arr) - 1
      while st <= ed:
          mid = (st + ed) // 2
          if arr[mid] > num:
              ed = mid - 1
          elif arr[mid] < num:
              st = mid + 1
          else:
              return True
  
  arr = [1, 2, 3, 43, 5, 9, 21, 13, 22]
  arr.sort()
  max_num = 0
  for i in arr:
      for j in arr:
          sum_ = i + j
          if binary_search(sum_) and sum_ > max_num:
              max_num = sum_
  
  print(max_num)
  ```



- 이분 탐색 구현시 주의사항

  - 이분 탐색 구현시 아래와 같이 무한 루프에 빠지는 경우가 있다.
    - `binary_search` 함수는 target보다 작은 원소 중 가장 큰 원소를 반환하는 함수이다.
    - 아래 함수를 실행하게 되면 무한 루프에 빠지게 된다.

  ```python
  def binary_search(target):
      st, ed = 0, len(arr)
      while st < ed:
          mid = (st + ed) // 2
  
          if arr[mid] < target:
              st = mid
          else:
              ed = mid - 1
      
      return st
  
  
  arr = [1, 5, 8, 10, 11, 13, 14, 15, 22, 27]
  print(binary_search(11))
  ```

  - 원인
    - 첫 반복이 될 때, `mid` 값이 5이므로 `arr[mid]`가 target보다 크다.
    - 따라서 `ed` 값이 4가 되고, 다음 반복을 돌 때, mid 값은 2가 되고 `arr[mid]`가 target보다 작다.
    - 따라서 `st` 값이 2가 되고, 다음 반복을 돌 때 mid 값은 3이 되고, `arr[mid]`가 target보다 작다.
    - 따라서 `st` 값이 3이 되는데, 여기서부터 문제가 발생한다.
    - `st`가 3이고, `ed`가 4이므로 `mid` 값은 또 다시 3이 되고 무한 루프에 빠지게 된다.
    - 이는 `st+ed`의 값이 항상 정수여야하기 때문에 발생하는 문제로, `st`와 `ed`의 값이 1차이가 난다면 주의해야한다.
  - 해결법
    - `mid` 값을 `(st+ed+1)//2`로 설정한다.

  ```python
  def binary_search(target):
      st, ed = 0, len(arr)
      while st < ed:
          mid = (st + ed + 1) // 2
  
          if arr[mid] < target:
              st = mid
          else:
              ed = mid - 1
      
      return st
  
  
  arr = [1, 5, 8, 10, 11, 13, 14, 15, 22, 27]
  print(binary_search(11))
  ```




- Parametric search(매개 변수 탐색)

  - 최적화 문제를 결정 문제로 변환해 이분탐색을 수행하는 방법
    - 최적화 문제: 조건을 만족하는 최대값 혹은 최소값을 구하는 문제
    - 결정 문제: True 또는 False 둘 중 하나의 답 만을 가지는 문제.
    - 최적화 문제의 답이 결정 문제의 인자로 들어가게 된다.

  - Parametric search 문제를 해결하기 위해 이분 탐색을 사용한다.

  - 예시

    - 가격 순으로 정렬된 제품의 배열이 있을 때, 가격이 5만원 이상인 것들 중 가격이 가장 싼 제품을 찾고자한다.
    - 이 때, 5만원 이상인 것들 중 가장 싼 가격 X를 찾는 것이 최적화 문제이고, X의 값이 5만원 이상인지를 판단하는 것이 결정 문제이다.
    - 즉 가격 X를 받아, X값이 주어진 조건에 부합하는지를 이진탐색을 사용하여 반복적으로 체크하는 방식이다.

    - 먼저 가장 가운데에 위치한 제품의 가격을 확인한다.
    - 만약 해당 제품의 가격이 5만원보다 작으면 그 제품 뒤에 있는 제품들을 살펴보고, 적으면 그 제품 앞에 있는 제품들을 살펴본다.
    - 예컨데 가운데 있는 제품의 가격(X 값)이 4만원이라면, 찾고자 하는 제품은 해당 제품보다 뒤에 있을 것이다.

  - 어떤 문제를 parametric search로 풀려면 아래 조건들이 충족되어야한다.

    - 결정 문제로 풀 수 있어야 한다.
    - 정답이 될 수 있는 값들이 연속적이어야한다.
    - 예를 들어 최대값을 구하는 최적화 문제에서 결정 문제를 푸는 함수 `f(x)`가 True라면, x 이상인 모든 값들에 대해서 `f(x)`는 True여야 하고, 마찬가지로 최소값을 구하는 최적화 문제에서 `f(x)`가 True라면 x 이하인 모든 값들에 대해서 `f(x)`는 True여야한다.

    - Parametric search의 개념이나 기본적인 구현 난이도 자체는 높지 않지만 문제를 보고 parametric search로 풀 수 있다는 것을 알아내기가 쉽지 않은 만큼, 위 조건들을 항상 생각해야한다.





# 정렬

>  [정렬 알고리즘별 속도를 비교해주는 사이트](https://www.toptal.com/developers/sorting-algorithms)

- 선택 정렬
  - 리스트 내의 모든 요소를 탐색하면서 정렬하는 방식, 각 위치에 어떤 값이 들어갈지를 찾는 방식
  - 동장 과정
    - `[4,2,7,1,9,3]`를 정렬하려고 한다.
    - 여기서 첫 번째 요소인 4를 최솟값으로 지정하고 2~3까지를 비교한다.
    - 2는 4보다 작으므로 최솟값은 4에서 2가 된다.
    - 7은 2보다 크므로 최솟값은 변화가 없다.
    - 1은 2보다 작으므로 최솟값은 2에서 1이 된다.
    - 9는 1보다 크므로 최솟값은 변화가 없다.
    - 3은 1보다 크므로 최솟값은 변화가 없다.
    - 결국 리스트를 전부 탐색했을 때 1이 최솟값이므로 0번 인덱스와 1의 인덱스를 바꾼다.
    - 이제 배열은 `[1,2,7,4,9,3]`가 된다.
    - 배열의 두 번째 요소부터 위 과정을 반복한다.
  



- 삽입정렬
  - 리스트에 값을 하나씩 삽입하듯 정렬하는 방식, 각 값이 어떤 위치에 들어갈지를 찾는 방식
  - 동작 과정
    - `[4,2,7,1,9,3]`
    - 우선 0~1번 인덱스까지만 비교하여 4가 2보다 크므로 둘의 자리를 바꾼다.
    - 다음으로 0~2번 인덱스까지만 비교하여 7은 2,4보다 크므로 그대로 둔다.
    - 다음으로 0~3번 인덱스까지만 비교하여 1은 7보다 크므로 7을 1과 바꾼다. 4도 1보다크므로 4와 1을 바꾼다. 2도 1보다 크므로 1과 2도 바꾼다. 
    - 다음으로 0~4번 인덱스까지만 비교하여 9는 1,2,4,7보다 크므로 그대로 둔다.
    - 마지막으로 0~5번 인덱스를 비교하여 3은 4,7,9보다 작으므로 3과 9, 3과 7, 3과 4의 자리를 바꾼다. 
    




- 합병정렬

  - 분할정복을 사용한 정렬방법이다.

    - 리스트를 절반으로 나누고(divide), 왼쪽과 오른쪽을 각각 정렬(conquer)한 후, 정렬된 두 리스트를 하나의 정렬된 리스트로 합병(combine)한다.


    - 세 과정 중 합병이 가장 까다롭다.

  - 정렬된 두 개의 배열을 정렬된 채로 병합하는 방법은 아래와 같다.

    - `[1,3,8,9]`, `[2,4,5,6]` 두 개의 배열을 정렬을 유지하면서 하나의 배열로 병합하려고 한다.
    - 각 리스트는 정렬되어 있으므로 첫번째 값이 가장 작을 것이다. 따라서 각 리스트의 첫 번째 값을 비교한 후 더 작은 값을 새로운 배열에 넣는다.
    - 이 때 세 배열의 상태는 `[3, 8, 9]`, `[2, 4, 5, 6]`, `[1]`이 된다.
    - 이 과정을 반복하면 정렬된 정렬을 유지한 채로 병합된 배열을 얻을 수 있다.

  - 병합 정렬은 위 아이디어를 가지고 정렬을 진행한다.

    - 전체 배열을 더 이상 나눠지지 않을 때 까지 절반으로 나눈다.
    - `[8,3,9,1,5,2,6,4]`과 같은 배열이 있을 때, 이를 절반으로 나누면 `[8,3,9,1]`, `[5,2,6,4]`가 된다.
    - 절반으로 나눠진 각 배열 각각을 다시 절반으로 나누는 것을 반복하면 `[8],[3],[9],[1],[5],[2],[6],[4]`가 된다.
    - [8],[3]을 정렬하여 하나의 리스트로 합하고 [9],[1]을 정렬하여 하나의 리스트로 합한다.
    - 다른 배열들도 마찬가지 방식으로 병합한다.
    - 위 과정을 계속 반복하면 정렬이 완료된다.




- 퀵 정렬

  - 분할정복을 사용한 정렬방법이다.


  - 합병정렬과 달리 세 과정 중 나누는과정이 가장 까다롭다.


  - 퀵 정렬에서 리스트를 나누는 과정(divide)을 파티션(partition)이라 부른다.

    - 기준점(pivot)을 정한다(divide). 꼭 리스트의 중간에 있는 값일 필요는 없다.
    - 기준점보다 더 작은 값은 기준점 왼쪽으로, 큰 값은 기준점 오른쪽으로 정렬한다(conquer).

  - 과정은 아래와 같다.

  ```
  1.a = [16,11,6,13,1,4,10,7]일때 7을 기준점으로 잡으면 아래와 같이 담기게 된다(divide)
  	al = [6,1,4]
  	ar = [16,11,13,10]
  2.이제 각 리스트를 정렬해야 하는데(conquer) 다시 기준점을 잡아준다(부분문제의 divide).
  2-1.al의 기준점을 4로 잡으면 아래와 같이 담기게 된다.두 리스트 모두 값이 하나뿐이므로 base case라고 	볼 수 있다.
  	all = [1] ; alr = [6]
  2-2.ar의 기준점을 13으로 잡으면 아래와 같이 담기게 된다.
  	arl = [10,11]
  	arr = [16]
  	arr은 리스트에 값이 하나뿐이므로 base case가 되지만 arl은 아니므로 또 partition을 해준다.
  	10을 기준점으로 잡으면(arll은 아무것도 담기지 않는다.)
      arlr = [11]
      base case가 나왔으므로 return하면 된다.
  3-3.모든 리스트가 정렬되었으므로 아래와 같은 리스트가 얻어진다.
      [1,4,6,7,10,11,13,16]
  ```

  - 원리는 위와 같지만 이를 코드로 구현하기 위해서는 조금 다르게 생각을 해야 한다.

  ```python
  a = [16,11,6,13,1,4,10,7]
  0. start지점, end지점을 설정한다(정렬할 리스트의 시작과 끝).
     -이 경우 0번 인덱스와 7번 인덱스
  1. 기준점을 잡는다.
     -이 경우 7을 기준점으로 잡는다.
  2. 탐색할 인덱스 i와 기준점보다 큰 값이 시작되는 인덱스 b를 설정한다.
     i = 0; b = 0
  3-1. list를 i를 가지고 탐색하면서 list[i]가 기준점보다 크다면 b는 그대로 두고 i에만 +1을 해준다.
  3-2. list[i]가 기준점보다 작다면 list[b]와  list[i]의 자리를 바꾸고 b와 i 둘 다 +1을 해준다.
  3-3. i가 end와 같아지면 list[b]와 list[end]를 바꿔준다.
  
  b = 0
  i = 0
  start = 0
  end = 0
  [16,11,6,13,1,4,10,7]
  list[0]인 16은 7보다 크므로 i만 +1
  list[1]인 11은 7보다 크므로 i만 +1
  list[2]인 6은 7보다 작으므로 list[b],즉 list[0]과 list[i], 즉list[2]의 위치를 바꾸고 b와 i 둘 다 +1을 해준다.
  b = 1
  i = 3
  [6,11,16,13,1,4,10,7]
  이런식으로 쭉 반복하다 i가 end와 같아지면 list[b]와 list[i], 즉 list[end]를 바꿔준다.
  [1,4,6,7,10,11,13,16]
  ```






# 시간복잡도

- 시간복잡도(Time Complexity)

  - 알고리즘의 시간을 평가하는 방식은 다양하다. 
    - 간단한 예로 알고리즘별 실행 시간을 측정하는 방법도 있다. 
    - 그러나 이는 컴퓨터의 사양, 프로그램의 요구사양, 프로그래밍 언어에 따라 달라질 수 있으므로 신뢰할 만한 결과를 얻기는 어렵다.
    - 따라서 시간복잡도를 측정하는 방식을 사용한다.
  - 인풋의 크기에 따라 실행 시간이 얼마나 증가하는지를 뜻하는 개념이다.
    -  아래의 표에서 B가 A에 비해 시간복잡도가 크다고 할 수 있고 더 느린 알고리즘이라고 할 수 있다.


  | 인풋 크기 | 알고리즘A | 알고리즘B |
  | --------- | --------- | --------- |
  | 10개      | 10초      | 10초      |
  | 20개      | 20초      | 40초      |
  | 100개     | 100초     | 1000초    |



- 시간복잡도의 표기법

  - 알고리즘 소요시간은 일반적으로 인풋의 크기에 따라 달라지게 되는데 그 식은 알고리즘에 따라 다양하게 나올 수 있다. n을 인풋의 수라고 할 때,
    - `20n + 40`, `2n<sup>2</sup> + 8n + 157`, `20lgn + 60`와 같이 다양하게 나올 수 있는다. 
    - 이 때 n을 제외한 20,40,2,8,157,20,60 등은 컴퓨터의 사양에 따라 달라질 수 있는 수 들이다. 
    - 따라서 위와 같은 식으로는 신뢰할 만한 시간을 구할 수 없다.

  - 점근표기법(Big-O)

    - 위와 같은 문제를 해결 하고자 연구자들은 점근표기법(Big-O)라는 방식으로 통일하여 표기하기로 했다.


    - 점근 표기법은 소요시간에 가장 큰 영향을 미치는 요소만 남기고 나머지는 다 제거한 후 남은 요소, 즉 소요시간에 가장 큰 영향을 미치는 요소로만 표기하는 방식이다.

    | 소요시간                           | 삭제되는 것들        | 점근 표기법(Big-O) |
    | ---------------------------------- | -------------------- | ------------------ |
    | 20n+40                             | 20, 40               | O(n)               |
    | 2n<sup>2</sup> + 8n + 157          | 2, 8n, 157           | O(n<sup>2</sup>)   |
    | 20lgn + 60                         | 20, 60               | O(lg n)            |
    | 5n<sup>3</sup>+100n<sup>2</sup>+75 | 100n<sup>2</sup>, 75 | O(n<sup>3</sup>)   |

  - 점근표기법의 핵심은 n이 매우 크다고 가정하는 것이다.

    - n이 작을 수록 좋은 알고리즘과 좋지 않은 알고리즘의 소요시간이 크게 차이가 나지 않는다. 
    - 그러나 n이 커질 수록 소요시간에 가장 큰 영향을 미치는 요소의 영향력이 커지게 된다.

    | input의 크기(n) | n<sup>2</sup> | 8n + 157 |
    | --------------- | ------------- | -------- |
    | 5               | 25            | 197      |
    | 10              | 100           | 237      |
    | 100             | 10000         | 957      |
    | 1000            | 1000000       | 8157     |
    | 100000          | 10000000000   | 800157   |

  - 위와 같이 인풋의 크기가 커질수록 가장 큰 영향을 미치는 요소(위의 경우 n<sup>2</sup>)의 영향이 커지게 된다.

    - 위의 예에서 n이 십만인 경우 n<sup>2</sup>은 100억이 되지만 8n + 157은 8십만이 조금 넘는다. 
    - 따라서 인풋이 커질수록, 영향을 덜 미치는 요소들(위의 경우 8n + 157)은 고려할 가치가 없어지게 된다.




- 점근표기법의 의미
  - O(1)
    - 인풋의 크기가 소요시간에 영향을 미치지 않는다. 반복문이 없으면 대체로 O(1)이다.
    - 2n<sup>2</sup>에서 2를 무시하고 O(n<sup>2</sup> )로 표기하는 것 처럼 O(x)도 마찬가지로 x가 몇이든 1로 표기한다. 
    - 왜냐하면 인풋의 크기와 무관하게 소요시간이 같으므로 x가 무엇이 되든 시간복잡도에는 영향을 미치지 않기 때문이다.
    - 예를 들어 O(1) = O(4) = O(10000) 모두 O(1)과 같다고 간주한다. 
  
  - O(n)
    - 리스트의 크기에 정비례하여 소요시간이 증가한다. 반복문이 있고 반복되는 횟수가 인풋의 크기에 비례하면 일반적으로 O(n)이다.
    - 2n번 반복하든 0.5n번 반복하든 앞의 수(이 경우 2, 0.5)는 버리므로 모두  O(n)이다. 즉 인풋만큼 반복하는 가와 무관하게 인풋의 크기에 비례해서 반복한다면  대체로 O(n)이다. 
    - 반복문 안에 반복문이 있는 형태가 아닌 여러 반복문이 독립적으로 있을 경우에도 O(n)이다.
  

  ```python
  N = int(input())
  
  cnt=0	#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
  for i in range(N):		#O(1)*반복횟수(N)
      cnt+=1
      
  for i in range(N):		#O(1)*반복횟수(N)
      cnt-=1
      
  이 경우 O(n)+O(n)+O(1)이 되어 O(2n+1)이지만 2와 1은 버리므로 반복문 2개가 들어간 이 코드의 복잡도는 O(n)이다. 반복문이 중첩되지 않는다면 반복문 몇 개가 들어가도 마찬가지다.
  ```
  
  - O(n<sup>2</sup>): 리스트의 크기가 증가하면 그 제곱만큼 초가 증가한다.
    - 반복문이 중첩된 경우(이중 반복문) 대체로 O(n<sup>2</sup>)이다.
  
  - O(n<sup>3</sup>): 리스트의 크기가 증가하면 그 세제곱만큼 초가 증가한다.	
    - 반복문이 3중으로 중첩된 경우 대체로 O(n<sup>2</sup>)이다.
  
  | 인풋의 크기(n) | O(1) | O(n)  | O(n<sup>2</sup>) | O(n<sup>3</sup>) |
  | -------------- | ---- | ----- | ---------------- | ---------------- |
  | 100            | 1초  | 1초   | 1초              | 1초              |
  | 200            | 1초  | 2초   | 4초              | 8초              |
  | 1000           | 1초  | 10초  | 100초            | 1000초           |
  | 10000          | 1초  | 100초 | 10000초          | 1000000초        |
  



- 알고리즘 평가

  - 알고리즘을 점근표기법으로 평가하는 방법을 선형탐색을 예로 들어서 살펴보면 다음과 같다.
    - 가장 빠른 경우는 찾는 값(element)가 0번 인덱스에 있는 경우로 1번 반복하므로 O(1)*반복횟수(n)=O(1)이 되고 모든 O를 더하면 O(1)+O(1)+O(1)+O(1) = O(4)가된다.
    - O(4) = O(1)이므로 시간복잡도는 O(1)가 된다.


  ```python
  def linear_search(element, some_list):
      i = 0			#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      n = len(some_list)   #인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      
      while i < n:					#O(1)*반복횟수(n), 이 경우 리스트의 길이가 인풋의 크기다.
          if some_list[i] == element:
              return i
          i += 1
          
  return None				#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
  
  
  
  가장 느린 경우는 찾는 값이 없는 경우로
  n번 반복하므로  O(1)*반복횟수(n)=O(n)이 되고 모든 O를 더하면
  O(1)+O(1)+O(n)+O(1) = O(n+3)이 된다.
  이때 3은 무시해도 되므로 시간복잡도는 O(n)이 된다.
  
  따라서 선형 탐색 알고리즘은 일반적으로 O(n)라 부른다.
  ```

  - 이번에는 이진탐색을 예로 들어서 살펴보면
    - 가장 빠른 경우는 찾는 값(element)가 mid 인덱스에 있는 경우로 1번 반복하므로 O(1)*반복횟수(n)=O(1)이 되고 모든 O를 더하면 O(1)+O(1)+O(1)+O(1) = O(4)가된다.
    - O(4) = O(1)이므로 시간복잡도는 O(1)가 된다.
    - 가장 느린 경우는 찾는 값이 없는 경우로 한 번의 반복마다 절만씩 줄어들기에 총 lg n번 반복된다. 
    - 따라서 O(lg n)이 되고 모든 O를 더하면 O(1)+O(1)+O(lg n)+O(1) = O(lg n)+3이 된다.
    - 이때 3은 무시해도 되므로 시간복잡도는 O(lg n)이 된다.
    - 따라서 이진 탐색 알고리즘은 일반적으로 O(lg n)라 부른다.


  ```python
  def binary_search(element, some_list):
      st = 0				#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      ed = len(some_list)-1	#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
      
          while st <= ed:			#O(1)*반복횟수(n), 이 경우 리스트의 길이가 인풋의 크기다.
          	mid = (st+ed)//2
          	if some_list[mid] == element:
              	return mid
          	elif some_list[mid] > element:
              	ed = mid-1
          	else:
              	st = mid+1
                  
  		return None			#인풋의 크기와 무관하게 항상 같은 시간이 걸리므로 O(1)
  ```



- 코드 없이 시간복잡도를 평가하는 방법
  - 최악의 경우를 상정하고 그 경우 몇 번의 반복이 일어나는지 생각하면 된다.
  - 위의 두 예에서 최악의 경우를 상정한 것도 그런 이유 때문이다.



- 공간복잡도

  - 인풋의 크기에 비례해서 알고리즘이 사용하는 메모리 공간을 나타내는 개념이다. 

  - 역시 마찬가지로 점근표기법으로 표현한다.  

  - 시간복잡도 평가와 유사한 방식으로 평가하지만 지금은 디테일하게 다루지 않는다.






# 재귀함수

- 함수 안에 함수가 들어있는 형태로 영화 [인셉션]이나 마트료시카를 생각하면 된다.

- 재귀적으로 문제를 푼다는 것은 결국 같은 형태의 더 작은 문제(부분문제)를 풀고 이를 이용하여 전체 문제를 푸는 것이다.

  ex.5! = 5\*4\*3\*2\*1인데 4!=4\*3\*2\*1 이므로 4!는 5!의 부분문제라고 할 수 있다. 
  마찬가지로 3! =3\*2\*1이므로 3!는 4!의 부분문제라고 할 수 있다.

- 재귀적으로 풀 때 또 하나 생각해야 할 것은 base case와 recursive case이다. base케이스는 문제가 충분히 작아서 바로 풀 수 있는 경우이고 recursive case는 재귀적(더 작은 부분문제로 나눠)으로 문제를 풀어야 하는 것이다.

  ex. n! 에서 n=0일때 0 != 1이다. 이는 바로 풀수 있고 더 작은 부분문제로 나눠지지도 않으므로 base case라고 할 수 있다. 반면 n > 0일때 n!=n(n-1)!*n이다. 이는 더 작은 문제로 나뉠 수 있으므로 recursive case이다.

- 반복문으로 풀 수 있는 문제는 재귀함수로도 풀 수 있고 그 역도 마찬가지다.
  
  - 단 재귀함수의 경우 지나치게 많이 재귀호출을 할 경우 call stack이 과부화되어 StackOverflowError가 발생(python의 경우 call stack이 1,000으로 제한되어 있다)한다. 따라서 재귀호출을 지나치게 많이 할 것 같을 경우 반복문으로 푸는 것이 나을 수 있다.







---





# 알고리즘 패러다임

- 알고리즘 문제에는 다양한 접근법이 존재하는데 이중 유사한 접근법들을 묶어서 알고리즘 패러다임이라 한다.

1)Brute Force(완전 탐색이라고도 부른다)

- 가능한 모든 방법을 시도하는 방식
- 모든 알고리즘의 시작점이라고도 할 수 있으며 Brute Force 방식으로 생각한 후 더 효율적인 방법을 찾는 것이바람직하다
-  코드가 직관적이고 확실한 답을 얻을 수 있다는 장점이 있다.
-  비효율적이고 인풋이 커질수록 시간이 점점 더 오래 걸린다는 단점이 있다.

​	ex. 비밀번호가 0000~9999일 때 모두 하나씩 입력해 보는 방식

- 동적 계획법이나 백트래킹도 완전탐색의 일종이다. 다만 시간을 더 줄일 수 있는 방식이다.



2)Divide and Conquer(분할정복)

- 문제를 부분 문제로 나눠(divide)서 부분문제의 해를 구한 후(conquer), 부분문제의 해를 통해 전체 문제를 해결(combine)하는 방식
- Top-down Approach
 - divide ,conquer, combine의 세 단계를 거쳐 문제를 해결한다.
   	- 이 때 부분문제가 더 작은 부분문제로 나뉠 수 있다면 문제가 충분히 작아질 때 까지 conquer 또한 다시 divde,conquer,combine으로 나뉘게 된다.
	- 위의 설명에서 알 수 있듯이 재귀함수와 매우 밀접한 연관을 지니는 패러다임이다.
	- 1~8의 합을 구할 경우 아래 그림과 같이 더 작은 문제들로 분할하여 base case인 1~1의 합 ~ 8~8의 합을 구한 후 이를 통해 상위문제의 해를 구하는 식으로 합을 구한다.

| 1~8의 합 |          |          |          |          |          |          |          |
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |
| 1~4의 합 |          |          |          | 5~8의 합 |          |          |          |
| 1~2의합  |          | 3~4의 합 |          | 5~6의 합 |          | 7~8의 합 |          |
| 1~1의 합 | 2~2의 합 | 3~3의 합 | 4~4의 합 | 5~5의 합 | 6~6의 합 | 7~7의 합 | 8~8의 합 |



3)Dynamic Programming(동적 계획법)

- 중복되는 문제들을 계속 풀어야 하는 비효율을 해결하는 프로그래밍, 한번 계산한 결과를 재활용하는 방식이라고 할 수 있다.



- 동적계획법을 사용하기 위해서는 아래의 두 조건이 충족되어야 한다.

  - 최적 부분 구조(Optimal Substructure)
    - 부분문제들의 최적을 답을 이용해서 기존문제(전체문제)의 최적의 답을 구할 수 있는 구조
    - 예를들어 fibo(5)는 fibo(4)와 fibo(3)의 답으로 답을 얻을 수 있으므로 이에 해당한다.
  - 중복되는 부분 문제(Overlapping Subproblems)
    
  - 예를들어 fibo(5)는 fibo(4)를 1번, fibo(3)을 2번, fibo(2)를 3번, fibo(1)을 2번 계산해야 하는데 fibo(3), fibo(2), fibo(1)은 중복되는 부분문제들이다.
    
    - 합병정렬의 경우 절반으로 나뉜 리스트에 중복된 값이 없을 것이므로 중복되는 부분 문제가 없다.
    
      

- 중복되는 부분 문제가 있다(조건2)면 중복되는 문제들을 계속 풀어야 해서 비효율적이다. 이를 해결하기 위해 만일 최적 부문구조가 있을 경우(조건1) 동적계획법으로 이 비효율을 해결할 수 있다. 즉 중복되는 부분 문제가 있다는 것은 동적 계획법을 쓸 필요가 있다는 것이고 최적 부분 구조를 지닌다는 것은 동적 계획법을 쓸 수 있다는 것이다.



- 다이나믹 프로그래밍을 구현하는 두 가지 방법

  (1)Memoization

  - 동일한 계산을 해야 할 때마다 다시 계산하는 대신 한 번 계산한 값을 기록해두고 이후에 동일한 계산을 해야하면 기록한 값을 읽어오는 것. 따라서 중복되는 부분문제를 딱 1번씩만 풀면 된다.
    - ex. 아메리카노(100원), 에스프레소(200)원, 쥬스(300)원일 때 모든 계산 결과들(7가지 경우)을 모두 기록해 놓는 것이다. 이렇게 하면 만일 누군가 아메리카노와 쥬스를 시킨다면 100+300을 계산하는 것이 아니라 이미 기록해둔 400이라는 값을 읽어오면 된다.

  (2)Tabulation

  - 표에 기록하는 방식이라 하여 Tab(le)ulation이라 부른다.

  - 재귀를 기반으로 하는 메모이제이션과 달리 타뷸레이션은 반복문을 사용한다.
  - 또한 fibo(5)를 구하기 위해 fibo(4)를 구해야 하고, fibo(4)를 구하기 위해 fibo(3)를 구해야 하는 것 처럼 하향식 접근을 취하는 메모이제이션에 비해 타뷸레이션은 fibo(5)를 구하기 위해 fibo(1)부터 fibo(5)까지 구해나가는 상향식 접근을 취한다.

  (3)메모이제이션의 경우 재귀를 기반으로 하므로 재귀호출이 지나치게 깊어지면 실행이 안될 수 있다는 단점이 있고 타뷸레이션은 처음부터 끝까지 모든 값을 계산하며 올라가므로 필요없는 값도 계산하는 경우가 생긴다. 반면에 메모이제이션은 위에서 부터 필요한 값만 계산하며 내려오므로 이런 경우가 없다.

  ​	ex. 임의의 함수 f(8)은 f(6)+f(2)로 구할 수 있고 f(6)은 f(4)+f(2)로 구할 수 있고 f(4)는 f(2)+f(2)로 구할 수 있을 	때 메모이제이션은 f(8)을 구하기 위해 f(6),f(4),f(2) 만 구하면 되지만 타뷸레이션은 f(1)~f(8)까지 모두 계산	해야 한다.

  

- 공간 사용의 최적화

  - 메모이제이션은 메모에, 타뷸레이션은 테이블에(둘 다 리스트나 딕셔너리에 저장하긴 하지만) 지금까지 계산한 값들을 저장하는데 이는 비효율적일 수 있다.

    - 예를 들어 메모이제이션으로 fibo(5)를 계산하는데에는 fibo(4)와 fibo(3)이 필요하고 fibo(4)를 계산하는 데에는 fibo(3)과 fibo(2)가 필요하다. fibo(3)을 계산하는 데에는 다시 fibo(2)와 fibo(1)이 필요한데 정작 우리가 원하는 값인 fibo(5)는  fibo(4)와 fibo(3)만 알면 구할 수 있다. 따라서 fibo(4)와 fibo(3)을 구한 순간 fibo(2)와 fibo(1)은 더 이상 필요 없음에도 리스트(메모)에서 공간만 잡아먹게 된다.

    - 타퓰레이션도 마찬가지로 fibo(5)를 계산하는데에는 fibo(4)와 fibo(3)만 알면 되는데, fibo(3)을 계산해서 테이블에 적은 순간 fibo(1)은 필요 없는 값이 되고(fibo3+n을 계산하는데 쓰이지 않으므로) fibo(4)를 계산한 순간 fibo(2)는 필요없는 값이 된다. 그럼에도 여전히 리스트(테이블)에 남아 있다.

    - 따라서 다음 단계의 계산에 필요한 두 값, fibo(n)을 구할 경우 fibo(n-1)과 fibo(n-2)를 각각 a, b에 넣고 계산이 끝날 때 마다. b에 a값을 넣고, a에  fibo(n)값을 넣으면 변수 2개로 해결 할 수 있다.

      ```python
      fibo(5)= fibo(4)+fibo(3)
      fibo(4)= fibo(3)+fibo(2)
      fibo(3)= fibo(2)+fibo(1)
      이므로 fibo(n-1)과 fibo(n-2)를 각기 a,b에 넣으면 다음과 같이 표현 할 수 있다.
      a = fibo(2)
      b = fibo(1)
      fibo(3) = a+b
      b = a
      a = fibo(3)
      fibo(4) = a+b
      b = a
      a = fibo(4)
      fibo(5) = a+b
      ```

      

4)Greedt Algorithm(탐욕 알고리즘)

- 미래를 내다보지 않고, 당장 눈 앞에 보이는 최적의 선택을 하는 방식

- 장단점은 다음과 같다.

  - 장점: 빠르고 간단하게 구현 가능하다.
  - 단점: 최적의 답이 보장되지 않는다.

- 다른 알고리즘으로는 고려해야 할 사항이 너무 많아서 시간 내에 할 수 없을 때, 혹은 최적의 답이 없을 때 마지막 대안으로 사용.

- 탐욕 알고리즘이 최적의 답을 보장해 주는 문제도 간혹 있는데 다음의 두 조건을 모두 충족하는 경우이다.

  - 최적 부분 구조일 경우 부분 문제의 최적의 답으로 기존 문제의 최적의 답을 찾을 수 있으므로 탐욕 알고리즘으로 최적의 답을 구할 수 있다.
  -  탐욕적 선택 속성(Greedy Choice Property)이 있는 경우이다. 이는 각 단계에서 탐욕스런 선택이 최종 답을 구하기 위한 최적의 선택임을 의미한다.

  ```python
  #최대한 적은 동전으로 거슬러주는 문제는 위의 두 조건을 모두 지니고 있는 문제이다.
   예를 들어 1700을 거슬러줘야 한다고 할 때 첫 동전으로 500원을 거슬러 준다면 1200원을 최대한 적은 동전으로 거슬러주는 부분 문제를 풀어야 하고 첫 동전으로 100원을 거슬러 준다면 1600원을 최대한 적은 동전으로 거슬러주는 부분 문제를 풀어야 한다. 따라서 최적 부분 구조가 있다. 
   또한 매 순간마다 최대한 큰 동전을 고를 수도 있다.예를 들어 660원을 거슬러 줄 경우 가장 큰 동전인 500원을 선택하고 남은 160원에서 가장 큰 동전인 100원을 선택하고 남은 60원에서 가장 큰 50원을 선택하고 마지막으로 가장 큰 동전인 10원을 선택하면 가장 큰 동전을 고른다는 탐욕스런 선택만으로 최적의 답을 구하게 된다. 따라서 이 문제에는 탐욕적 선택 속성이 존재한다.
  ```

  

















