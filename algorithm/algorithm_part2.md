# 알고리즘

- 알고리즘

  - 유한한 단계를 통해 문제를 해결하기 위한 절차나 방법

  - 알고리즘의 조건
    - 입력: 알고리즘 수행에 필요한 자료가 외부에서 입력으로 제공된다.
    - 출력: 알고리즘 수행 후 하나 이상의 결과를 출력한다.
    - 명확성: 수행할 작업의 내용과 순서를 나타내는 알고리즘 명령어들은 명확하게 정의되어야 한다.
    - 유한성: 알고리즘은 수행 뒤에 반드시 종료된다.
    - 효과성: 알고리즘의 모든 명령어들은 기본적이며 실행 가능해야 함.

  - 알고리즘 문제 해결 전략
    - 비슷한 문제를 풀어본 적 있는지 고민
    - 단순한 방법에서 시작할 수 있을지 고민
    - 문제를 단순화 할 수 있을지 고민
    - 그림, 수식 등으로 표현 할 수 있을지 고민
    - 문제를 분해할 수 있을지 고민
    - 뒤에서부터 생각해서 문제를 풀 수 있을지 고민

  - 좋은 알고리즘
    - 정확성: 얼마나 정확하게 동작하는가
    - 작업량: 얼마나 적은 연산으로 원하는 결과를 얻어내는가
    - 메모리 사용량: 얼마나 적은 메모리를 사용하는가
    - 단순성: 얼마나 단순한가
    - 최적성: 더 이상 개선할 여지없이 최적화되었는가




- 자료구조, 자료형, 추상 자료형
  - 자료구조
    - 데이터에 효율적으로 접근하고 조작하기 위한 데이터의 조직, 관리, 저장 구조를 의미한다.
    - 학문적인 성격이 강하다.
  - 자료형
    - 자료구조를 특정 언어에서 구현한 것이다.
    - 컴파일러 또는 인터프리터에게 프로그래머가 어떻게 데이터를 사용하는지 알료주는 일종의 데이터 속성이다.
  - 추상 자료형(ADT)
    - 자료형에 대한 수학적 모델을 지칭한다.
    - 해당 유형의 자료에 대한 연산들을 명기한 것이다.
    - 행동만을 정의할 뿐 실제 구현 방법은 명시하지 않는다.





# 복잡도

- 알고리즘의 효율성은 공간적 효율성과 시간적 효율성으로 나눈다.
  - 공간적 효율성: 얼마나 많은 메모리 공간을 요하는가
  - 시간적 효율성: 얼마나 많은 시간을 요하는가
  - 복잡도는 효율성을 뒤집어 표현한 것이다.



- 공간 복잡도
  - 알고리즘을 프로그램으로 실행하여 완료하기까지 필요한 총 저장 공간의 양



- 시간적 복잡도 분석

  - 하드웨어 환경에 따라 처리 시간이 달라진다.
  - 소프트웨어 환경에 따라 처리 시간이 달라진다(프로그래밍 언어의 종류, 운영체제 등).

  - 이러한 환경적 차이로 인해 분석이 어렵다.



- 복잡도의 점근적 표기
  - 시간, 공간 복잡도는 입력 크기에 대한 함수로 표기하는데, 이 함수는 주로 여러 개의 항을 가지는 다항식.
  - 이를 단순한 함수로 표현하기 위해 점근적 표기(Asymptotic Notation)을 사용
  - 입력 크기 n이 무한대로 커질 때의 복잡도를 간단히 표현하기 위해 사용하는 표기법이다.
  - 종류
    - O(Big-Oh)표기
    - Ω(Big-Omega)표기
    - θ(Big-Theta)표기



- Ω(Big-Omega)표기
  - 복잡도의 점근적 하한을 나타낸다(최소한 이만한 시간은 걸린다).
  - T(n) >= c*f(n)이 되는 상수 c,n<sub>0</sub>가 존재할 때(c, n<sub>0</sub>는 n의 값에 독립적)만 Ω(Big-Omega)표기 사용 가능
  - T(n) = Ω(f(n))이라고 한다.



- θ(Big-Theta)표기
  - T(n) = O(f(n)) 이고 T(n) = Ω(f(n)) 일때 T(n) = θ(f(n))이 성립한다.
  - n<sub>0</sub>보다 크거나 같은 모든 n에 대해서 c<sub>1</sub>*f(n)<=T(n)<=c<sub>2</sub>*f(n)이 되는 상수 c<sub>1</sub>, c<sub>2</sub>, n<sub>0</sub>가 존재할 때만 표기 가능
  - T(n) = θ(f(n))이라고 한다.



## big-O

- big-O(혹은 O) notation

  - 입력값이 무한대로 향할 때 함수의 상한을 설명하는 수학적 표기법이다.
  - 입력값이 커질 때 알고리즘의 실행 시간(시간 복잡도)과 함께 공간 요구사항(공간 복잡도)이 어떻게 증가하는지를 분류하는 데 사용된다.

  - 점근적 실행 시간(Asymptotic Running Time)을 표기할 때 가장 널리 쓰이는 수학적 표기법 중 하나이다.
    - 점근적 실행 시간: 입력값 n이 무한대로 향할 때 함수의 실행 시간의 추이를 의미한다.
    - 컴퓨터의 빠른 처리 능력으로 인해 복잡한 알고리즘이라도 입력의 크기가 작으면 금방 종료된다.
    - 따라서 입력의 크기가 충분히 클 때 알고리즘의 효율성을 정확히 측정할 수 있다.
    - 점근적 실행 시간은 달리 말하면 시간 복잡도라 할 수 있다.
  - 시간 복잡도(Time Complexity)
    - 어떤 알고리즘을 수행하는 데 걸리는 시간을 설명하는 계산 복잡도최고(Computational Complexity)를 의미한다.
    - 계산 복잡도를 표기하는 대표적인 방법이 big-O다.
    - big-O로 시간복잡도를 계산할 때는 최고차항만을 표기하며 계수는 무시한다.



- big-O 표기법의 종류
  - O(1)
    - 입력값이 아무리 커도 실행 시간은 일정하다.
    - 상수 시간을 갖는 알고리즘은 최고의 알고리즘이라 할 수 있다.
    - 그러나 상수 시간에 실행된다고 해도 상수값이 매우 크다면 사실상 일정한 시간이 의미가 없다.
  - O(log n)
    - 매우 큰 입력값에도 영향을 받지 않는 편이다. 
    - 웬만한 n의 크기에 대해서도 매우 견고하다.
  - O(n)
    - 입력값만큼 실행 시간에 영향을 받으며, 알고리즘을 수행하는 데 걸리는 시간은 입력값에 비례한다.
    - 이 시간 복잡도를 가지는 알고리즘을 선형 시간(Linear-Time) 알고리즘이라 한다.
  - O(n log n)
    - 대부분의 효율 좋은 정렬 알고리즘이 이에 속한다.
  - O(n<sup>2</sup>)
    - 버블 정렬 같은 비효율적인 정렬 알고리즘이 이에 해당한다.
  - O(2<sup>n</sup>)
    - 피보나치 수를 재귀로 계산하는 알고리즘이 이에 해당한다.
  - O(n!)
    - 외판원 문제를 브루트 포스로 풀이할 때가 이에 해당한다.
    - 가장 느린 알고리즘으로, 입력값이 조금만 커져도 웬만한 다항 시간 내에는 계산이 어렵다.



- 상한과 최악
  - 빅오는 상한을 의미한다.
  - 하한을 의미하는 빅오메가, 평균을 의미하는 빅세타가 있는데, 업계에서는 빅세타와 빅오를 하나로 합쳐 단순화해서 표현하려는 경향이 있다.



- 분할 상환 분석(Amortized Analysis)
  - 빅오와 함께 함수의 동작을 설명할 때 중요한 분석 방법 중 하나.
    - 시간 또는 메모리를 분석하는 알고리즘의 복잡도를 계산할 때, 알고리즘 전체를 보지 않고 최악의 경우만을 살펴보는 것은 지나치게 비관적이라는 이유로 등장했다.
    - 로버트 타잔이 [상각된 계산 복잡도(Amortized Computational Complexity)]라는 논문에서 처음으로 소개했다.
  - 분할 상환 혹은 상각이라고 표현하는, 최악의 경우를 여러 번에 걸쳐 골고루 나눠주는 형태로 알고리즘의 시간 복잡도를 계산할 수 있다.



- 알고리즘과 병렬화
  - 딥러닝의 인기와 함께 병렬화가 큰 주목을 받고 있다.
  - 근래에 들어서는 알고리즘의 우수성을 평가할 때, 병렬화가 가능한지도 평가한다.





# 진수

- 추천문제: swea_1240, swea_1242
- 파이썬에서 10진수 이외의 진수는 모두 아래와 같이 수 앞에 문자를 붙여서 표현한다.
  - 2진수: `0b`
  - 8진수: `0o`
  - 16진수:`0x`



- 10진수를 타 진수로 변환하는 방법
  - 원하는 타 진법의 수로 나눈 뒤 나머지를 거꾸로 읽는다.



- 2진수, 8진수, 16진수간 변환
  - 2진법을 8진법으로 바꿀 때는 3자리씩 묶으면 되고, 역으로 수행할 때는 3자리씩 나열하면 된다.
  - 2진법을 16진법으로 바꿀 때는 4자리씩 묶으면 되고, 역으로 수행할 때는 4자리씩 나열하면 된다.



- 16진 표기법

  - 16진수는 2진수로 저장된다.

  - 10진수를 16진수로 변환하는 과정, 16진수를 10진수로 변환하는 과정은 2진수와 동일하다.

  - 16진수 한 자리는 2진수 4자리로 표현한다.

    - 7DF는 2진수로 다음과 같이 표현한다.

    - 7은 2진수로 0111, D(13)는 2진수로 1101, F(15)는 2진수로 1111
    - 011111011111 

  - 16진수는 0~9, A~F를 사용해 표현한다.

    - 0~9는 10진수의 0~9와 동일, A~F는 10진수의 10~15와 동일
    - 즉 0~F를 사용해 0~15를 표현한다.
    - 16진수임에도 15까지만 표현하는 이유는 16으로 나눈 가장 큰 나머지가 15이기 때문이다.

  - 16진수로 변환 예시

    - 2015를 16진수로 표현하면
    - 2015/16=125...15
    - 125/16=7...13
    - 7, 13, 15을 16진수로 표현하면 7,D,F가 된다.
    - 결국 10진수 2015의 16진수 표기는 0x7DF이다.

  - 10진수로 변환 예시
    - 16진수 0x7DF를 다시 10진수로 변환하면 16\*\*2\*7+16\*\*1\*13+16\*\*0\*15=2015

    

- 엔디안(Endianness)

  - 16진수의 1비트는 2진수 4비트로 표현된다.

  - 그렇다면 0x01020304는 00000001/00000010/00000011/00000100이 되야 하겠지만 결과는 00000100/00000011/00000010/00000001로 거꾸로 나온다.

  - 이런 결과가 나오는 이유는 엔디안 때문이다.

  - 엔디안: 컴퓨터 메모리와 같은 1차원 공간에 여러 개의 연속된 대상을 배열하는 방법을 의미

  - 주의: 속도 향상을 위해 바이트 단위와 워드 단위를 변환하여 연산 할 때 올바로 이해하지 않으면 오류를 발생시킬 수 있다.

    - 위에서 말하는 워드란 컴퓨터가 한번에 처리하는 단위이다.
    - ex. 64bit 운영체제에서 64bit가 워드를 의미하는 것이다.
    - 1byte=8bit

  - 종류

    - 단위: 0x1234라는 데이터가 있을 때 1은 16의 3승, 2는 16의 2승, 3은 16의 1승, 4는 16의 0승을 곱해서 10진수로 변환한다. 이때 지수가 더 큰 1,2가 큰 단위, 3,4가 작은 단위가 된다.
    - 빅엔디안: 보통 큰 단위가 앞에 나온다. 네트워크의 처리 방식
      - 빅 엔디안에서는 0x1234를 12 34로 저장한다.
    - 리틀 엔디안: 보통 작은 단위가 앞에 나온다. 대다수 데스크탑 컴퓨터의 처리 방식
      - 리틀 엔디안에서는 0x1234를 34 12로 저장한다.

  - 즉 위에서 결과거 거꾸로 출력된 이유는 리틀엔디안으로 처리가 되었기 때문이다.

  - 엔디안 확인 코드

    ```python
    #1.비트연산을 통한 확인
    n=0x00111111
    #n을 2진수로 표현하면 00000000/00010001/00010001/00010001
    
    if n&0xff:    #f는 15, ff는 2진수로 11111111
        print('little endian')
    else:
        print('big endian')
        
    #만일 리틀 엔디안으로 처리가 되었다면 00010001/00010001/00010001/00000000가 되어 
    #00010001 & 11111111의 값은 0이 아닐 것이므로 'little endian'이 출력,
    #만일 빅 엔디안으로 처리가 되었다면 00000000/00010001/00010001/00010001가 되어
    #00000000 & 11111111의 값은 0일 것이므로 'big endian'이 출력
    
    
    #2.파이썬 시스템 라이브러리를 통해 확인 
    import sys
    if sys.byteorder == 'little':
        print('little endian platform')
    else:
        print('big endian platform')
        
    #확인 필요
    print(0b00000000000100010001000100010001&0b11111111) #big
    print(0x00111111&0b11111111)
    print(0b00010001000100010001000100000000&0b11111111) #little
    print(0x00111111==0b00000000000100010001000100010001) #big
    print(0x00111111==0b00010001000100010001000100000000) #little
    
    out
    17
    17
    0
    True
    False
    ```

  - 엔디안 변환 코드

    ```python
    def change_endian(n):
        p = []
        for i in range(0,4):
            p.append((n>>(24-i*8))&0xff)  
            #24인 이유는 0x01020304가 2진수로 총 32비트 이기 때문이다. 
        return p
    
    def change_endian2(n):
        return (n<<24 & 0xff000000) | (n<<8 & 0xff0000) | (n>>8 & 0xff00) | (n>>24 & 0xff)
    ```



- 컴퓨터에서 음의 정수 표현 방법
  - 컴퓨터의 정수 표현은 `부호비트|값비트`로 표현하고 부호비트는 양수일 경우 0, 음수일 경우 1이 된다.

  - 보수: 보충을 해주는 수를 의미한다. 이를테면 1에 대한 10의 보수는 9, 4에 대한 15의 보수는 11의 개념

  - 1의 보수: 부호와 절대값으로 표현된 값을 부호 비트를 제외 한 나머지 비트들을 0은 1로, 1은 0으로 변환
    - 0에 대한 1의 보수는 1, 1에 대한 1의 보수는 0
    - 따라서 0은 1로, 1은 0으로 변환(사실상 비트의 반전)
    - 예를 들어 6은 2진수로 표현 하면 110(값비트, 정확히는 양수이므로 0110)이다. 
    - 여기에 부호비트인 1(음수)를 표시하면 1110이 된다.
    - 1의 보수 방법을 사용하여 음수로 표시하면 1001(부호비트는 변환에서 제외)이 된다.
    
  - 2의 보수: 1의 보수  방법으로 표현된 값의 최하위 비트에 1을 더한다.
    
    -  1의 보수 방법으로 표현된 100<u>1</u>의 최하위 비트(밑줄)에 1을 더하면 1002가 된다.
    -  2진수이므로 다음 자리로 넘기면 1010이 된다.
    
  - 즉, 크게 `부호비트|값비트`표현, 1의 보수 표현, 2의 보수표현의 3가지 방법이 있지만 대부분 2의 보수 방법을 사용

  - 0의 표현

    | 2진수 | 부호비트\|값비트 | 1의 보수  | 2의 보수 |
    | ----- | ---------------- | --------- | -------- |
    | 000   | 0000,1000        | 0000,1111 | 0000     |

    

  - 정수표현을 그냥 `부호비트|값비트`로 해도 되는데 굳이 보수로 표현하는 이유

    - 예를 들어 3-3을 한다고 하면, 3-3은 3+(-3)과 같으므로, 3은 0011, -3은  보수로 표현하지 않고 `부호비트|값비트`로 표현해서 계산 할 경우  1011이 된다. 둘을 더하면 1110이 되어 0이 아닌 -6이 되게 된다.
    - 1의 보수로 동일한 계산을 할 경우 3은 그대로 0011, -3은 1100이 되어 둘을 더하면 1111이 된다. 이는 0을 1의 보수로 표현한 것과 동일하다. 그러나 1의 보수로 표현한 0은 +0과 -0이 생길 수 밖에 없어서 계산이 정확하지 않고 후술할 문제(캐리의 처리)도 있어서 잘 사용하지 않는다.
    - 2의 보수로 동일한 계산을 할 경우 3은 그대로 0011, -3은 1101이 되어 둘을 계산하면 10000이 되는데 2의 보수는 계산 결과 나온 맨 앞의 1(캐리, 자리 올림)은 버린다. 따라서 0000이 되고 0을 2의 보수로 표현한 것과 동일한 값을 얻게 된다.
    - 만일 1의 보수로 계산했을 때 위의 경우와 동일하게 계산 결과 맨 앞에 1이 나오는 경우가 생긴다면 그 1을 떼고 마지막 비트에 1을 더해줘야 계산이 맞게 된다.
      - 4-3을 할 경우 4는 4비트로 0100, -3은 1100인데 둘을 더하면 10000이 된다. 이 때 2의 보수는 동일한 상황에서 1을 떼면 끝이었으나 1의 보수는 1(캐리)을 뗀 후 마지막 비트에 1을 더해서 0001이 되야 계산이 맞게 된다.
      - 동일한 계산을 2의 보수로 해보면 4는 0100, -3은 2의 보수로 1101으로 둘을 더하면 10001이 되고 캐리를 떼면 0001로 추가적인 처리 없이도 맞는 값이 나오게 된다.



# 실수의 표현

- 소수점 이하 자리를 표현하는 방법

  - 123.456이라는 10진수로 표현한 실수가 있다고 할 때 이는 아래와 같이 풀어쓸 수 있다.

    - 10<sup>2</sup>*1+10\*2+3+10<sup>-1</sup>\*4+10<sup>-2</sup>\*5+10<sup>-3</sup>\*6

  - 마찬가지로 101.101이라는 2진수로 표현한 실수가 있다고 할 때 아래와 같이 풀어쓸 수 있다.

    - 2<sup>2</sup>\*1+2<sup>1</sup>\*0+2<sup>0</sup>\*1+2<sup>-1</sup>*1+2<sup>-2</sup>\*0+2<sup>-3</sup>\*1

      

- 컴퓨터의 실수 표현

  - 부동소수점(floating-point) 표기법을 사용
    - 움직이지 않는 소수점이라는 의미가 아닌 떠다니듯이 움직이는 소수점이라는 의미이다.
  - 부동소수점과 대비되는 개념으로 고정소수점(fixed-point)이 존재
  - 고정소수점과 부동소수점의 차이
    - 고정소수점은 일반적인 표시방법대로 정수부와 실수부를 나눠서 표시
      - 1001.0011에서 1001은 정수부, 0011은 실수부
    - 부동소수점은 소수점의 위치를 왼쪽의 가장 유효한 숫자 다음으로 옮기고 밑수의 지수승으로 표현
      - 1001.0011에서 왼쪽의 가장 유효한 숫자 다음으로 소수점을 옮기면 1.0010011이 된다. 여기서 밑수의 지수숭을 곱하면 1.0010011*2<sup>3</sup>이 된다.
      - 만일 0.0010110을 부동소수점으로 표시한다면, 왼쪽의 가장 유효한 숫자 다음으로 소수점을 옮기면 1.0110이 되고 밑수의 지수승을 곱하면 1.0110*2<sup>-3</sup>이 된다.
    - 즉, 부동소수점은 지수승으로 원래 소수점의 위치를 나타내준다.

  



- 단정도 실수(32비트로 표현, 일반적으로 float 타입이라고 불림)

  - 부호1비트|지수8비트|가수23비트

  - 지수부: 실제 소수점의 위치를 지수 승으로 표현한 것

  - 가수부: 실수의 유효 자릿수들을 부호화된 고정 소수점으로 표현한 것

    - 가수부에 표현할 수 있는 수가 많아질 수록 수를 더욱 정밀하게 표현 가능

  - 지수부에 0~2<sup>8</sup>-1(256개)만큼 표현 가능

  - 가수 부분 만드는 방법(1001.0011을 예로)

    - 정수부의 첫 번째 자리가 1이 되도록 오른쪽으로 시프트(1.0010011)
    - 소수점 이하를 (0을 추가해서)23비트로 만든다(1.00100110000000000000000)
    - 소수점 이하만을 가수 부분에 저장(00100110000000000000000)
    - 지수 부분은 시프트 한 자릿수 만큼 증가 또는 감소(1.0010011*2<sup>3</sup>)

  - 지수부에는 0~255까지 나타낼 수 있지만 음수도 나타내야 하므로 익세스(excess)표현법을 사용

    - 지수부의 값을 반으로 나누어 그 값을 0으로 간주하고 음수지수와 양수지수를 표현
    - 0~255의 중간을 0으로 간주 -127~128의 값을 가진다.
    - -127은 2진수로 00000000, 10진수로 0을 나타내고, 128은 2진수로 11111111, 10진수로 255를 나타낸다. 0은 2진수로 01111111, 10진수로 127을 나타낸다.

  - 결국 1001.0011은 단정도 실수로 표현하면 다음과 같다.

    > 0|10000010|00100110000000000000000

    - 맨 앞의 0은 부호비트, 뒤의 10000010은 익세스 표현법으로 나타낸 3의 2진수(10진수로는 130)로 지수부, 00100110000000000000000는 허수부

    

- 배정도 실수(64비트로 표현, 일반적으로 double타입이라고 불림)

  - 부호1비트|지수11비트|가수52비트
  - 지수부에 2<sup>11</sup>-1만큼 표현 가능
  - 파이썬은 64비트로 처리 함에도 float이라고 표현함



- 컴퓨터는 실수를 근사적으로 표현한다.
  - 이진법으로 표현할 수 없는 형태의 실수는 근사값으로 저장되는데 이 때 작은 오차가 생긴다.
  - 실수 자료형의 유효 자릿수
    - 32비트 실수형(십진수 기준):6, 즉 소수점 6자리까지는 유효하나 그 아래는 근사값
    - 64비트 실수형(십진수 기준):15, 즉 소수점 15자리까지는 유효하나 그 아래는 근사값



# 비트

- 부분집합 관련 배경지식

  - 집합의 원소가 n개일 때, 공집합을 포함하는 부분집합의 수는 2<sup>n</sup>개이다.
  - 이는 각 원소를 부분집합에 포함시키거나 포함시키지 않는 2가지 경우를 모두 원소에 적용한 경우의 수와 같다.




- 작은 값의 10진수를 2진수로 빠르게 변환하는 방법은 해당 값이 어떤 2의 n승들을 더해서 구성되는지 알면 된다. 예를 들어 10은 2의 3승인 8과 2의 1승인 1로 구성되므로 1010과 같이 쓸 수 있고 6은 2의 2승인 4와 2의 1승인 1로 구성되므로 110과 같이 쓸 수 있다. 



- 비트 연산자

  - 종류

    | 연산자 | 의미               | 예시                                     |
    | ------ | ------------------ | ---------------------------------------- |
    | \|     | or연산             | 두 비트 값이 하나라도 1이면 1, 아니면0   |
    | &      | and연산            | 두 비트값이 하나라도 0이면 0, 아니면1    |
    | ^      | xor연산            | 두 비트값이 같으면 0, 다르면 1           |
    | !      | not연산            | 1은 0으로 0은 1로                        |
    | <<     | 왼쪽 쉬프트 연산   | 모든 비트 값을 왼쪽으로 한 자리씩 이동   |
    | >>     | 오른쪽 쉬프트 연산 | 모든 비트 값을 오른쪽으로 한 자리씩 이동 |

  - 예시

    ```python
    print(13&9)
    
    out
    9
    
    #13,9의 &연산 결과가 9가 나오는 이유는 다음과 같다.
    #13은 2진수로 1101, 9는 2진수로 1001이다. 따라서 두 2진수를 비교해보면
    # 1101
    # 1001
    # ----
    # 1001
    # 위와 같은 결과가 나오게 된다.
    ```

  

  - 비트연산자 `^`를 2번 하면 처음 값을 반환한다.

    ```python
  #비트연산자 ^의 결과값은 두 비트의 값이 다를 때만 1이 된다.
    a = 0b1100
    b = 0b1001
    a^=b    # 1번
    #1100
    #1001
    #0101
    print(bin(a))
    a^=b    # 2번
    #0101
    #1001
    #1100
    print(bin(a)) 
    
    
    
    out
    0b101
    0b1100  #처음 값으로
    ```

    

  - 바이너리 카운팅

    - a<<n은 a*2<sup>n</sup>과 같다.
  - 1<<n은 2<sup>n</sup>과 같다.  a<<1은 a에 2를 곱하는 것과 같다. a>>1은 a에 2를 나눈는 것과 같다.
    - 따라서 부분집합을 구할 때도 많이 사용한다.
  
    ```python
    arr = [3,6,7,1,5,4]
    n = len(arr)          #n : 원소의 개수
    for i in range(1<<n):  #1<<n: 부분 집합의 개수(64)
        #i는 0~63까지의 값을 가진다. 2진수로는 000000~111111(10진수로 63)까지의 값을 가진다.
        for j in range(n): #원소의 수만큼 비트를 비교함
            if i & (1<<j):  #i의 j번째 비트가 0이 아니면 j번째 원소 출력
                print(arr[j],end=", ")
        print()
     
    #원리
    #n=6이므로 000000부터 111111까지 6자리 2진수를 가지게 된다.
    #즉, 2**5,2**4,2**3,2**2,2**1,2**0의 2진수가 만들어지게 된다.
    #n=6이므로 arr의 인덱스도 0~5까지 존재하게 된다.
    #그러므로 2의 제곱과 arr의 인데스가 0~5로 일치하므로 제곱에 인덱스를 대응시킬 수 있게 된다.
    #만일 0,2,4번 인덱스에 해당하는 값으로 이루어진 부분집합 [3,7,5]가 있다면
    #2**0, 2**2, 2**4의 비트값이 1이 되는 것이므로 2진수로는 010101이된다.
    
    #즉 정리하자면 000000~111111까지의 모든 2진수를 전부 탐색하면서 각 2진수의 비트를 리스트의 인덱스에 대응시키는 방식이다.
    #좀 더 작은 리스트로 예를 들어 보면
    brr = [1,2,3]
    n = len(brr)
    result = []
    for i in range(1<<n):
        temp = []
        for j in range(n):
            if i & (1<<j):
                temp.append(brr[j])
        result.append(temp)
    print(result)
    
    out
    [[], [1], [2], [1, 2], [3], [1, 3], [2, 3], [1, 2, 3]]
    
    
    #000~111까지의 2진수를 모두 나열하면 다음과 같다
    #000,001,010,100,011,110,101,111
    #이를 각 인덱스에 대응시키면 
    #[],[1],[2],[3],[1,2],[2,3],[1,3],[1,2,3]이와 같이 된다.
    #위 코드에서 i 가 6인 경우를 예로 들면 6은 2진수로 110이므로
    #j = 0일때 110의 첫 번째 비트값은 0이므로 brr[0]은 temp에 담기지 않는다.
    #j = 1일때 110의 두 번째 비트값은 1이므로 brr[1]은 temp에 담긴다.
    #j = 2일때 110의 세 번째 비트값은 1이므로 brr[2]는 temp에 담긴다.
    #결국 [2,3]이라는 부분집합이 나오게 된다.
    ```

    

    - 2를 곱하거나 나누는 코드를 작성해야 할때 *연산자나 /연산자를 사용하는 것 보다,  >>나 <<연산자를 사용하는 것이 훨씬 실행 속도가 빠르다.
  
    ```python
    a = 10
    print(a<<1)
    print(a>>1)
    
    out 
    20
    5
    #위와 같은 결과가 나오는 이유
    #10을 2진수로 변환하면 1010이다. 이 때 <<1을 해주면
    #10100이 되고 이를 10진수로 변환하면 20이 된다.
    #결국 x<<n은 x에 2**n을 곱한 것과 같은 결과가 나오게 된다(x*2**n).
    #반대로 10을 2진수로 변환한 1010에 >>1을 해주면
    #101이 되고 이를 10진수로 변환하면 5가 된다.
    #결국 x>>n은 x에 2**n을 나눈 것과 같은 결과가 나오게 된다(x/2**n).
    ```

  - 비트마스크 

    - &는 합집합 연산자로 i&(1<<j)와 같이 쓰면 i의  j번째 비트가 1인이 아닌지를 알 수 있다.
  
    ```python
    #10은 10진수로 1010이다. 0이 나오면 비트가0, 다른 숫자가 나오면 비트가1인 것이다.
    print(10&(1<<3))
    print(10&(1<<2))
    print(10&(1<<1))
    print(10&(1<<0))
      
    out
    8
    0
    2
  0
    ```

    

  - 또한 2진수 표현을 통해 홀짝 판단이 가능하다.
  
  - 2\*\*0은 1인데 2\*\*0의 비트값이 1이면 홀수, 0이면 짝수가 된다.
    - 홀짝 판단을 할때 보통 2로 나눠서 나머지가 있는지를 보는 방식을 쓰는데 그 방식보다 아래 방식이 훨씬 빠르게 수행된다.
  
    ```python
    if 6&1:    
        print('홀수')
    else:
        print('짝수')
    
    if 5&1:    
        print('홀수')
    else:
        print('짝수')
    
    out
    짝수
    홀수
    #6은 2진수로 110이고 1은 2진수로 1이다.
    #이를 다르게 표현하면 6은 110이고 1은 001이라고 할수 있다 110과 001은 겹치는 것이 하나도 없다.
    #110
    #001
    #따라서 6은 짝수이다.
    #반면에 5는 2진수로 101인데 101과 001은 마지막 1이 겹친다.
    #따라서 5는 홀수이다.
    ```






# 문자표현

- 해싱: 키를 통해 그 키값에 해당하는 밸류를 찾는 것을 해싱이라 부른다. 딕셔너리도 이에 해당한다.



- 컴퓨터의 문자 표현

  - 영어가 대소문자 합쳐서 모두 52자이므로 6비트(2**6=64)면 모두 표현할 수 있다.

  - 초기에는 지역마다 표현 방식이 모두 달랐으나 1967년 미국에서 ASCII(American Standard Code for Information Interchange)라는 문자 인코딩 표준이 제정됨.

  - ASCII

    - 7비트 인코딩으로 128문자를 표현한다. 128문자는 33개의 출력 불가능한 제어 문자들과 공백을 포함한 95개의 출력 가능한 문자들로 이루어져 있다.

    - 일일이 대응하는 값을 외울 필요는 없지만 몇 가지 규칙을 알고 있으면 편하다

      -숫자가 대문자보다 작은 코드에 배정되어 있으며 대문자는 소문자보다 작은 코드에 배정되어 있다.

      -또한 0~9, A~Z, a~z는 각각 코드 값이 1씩 증가해 나간다.

    - 확장 아스키는 표준 문자 이외의 악센트 문자, 도형문자, 특수문자, 특수기호 등 부가적인 문자 128가지를 추가할 수 있게 하는 부호이다.

      - 기존의 아스키 코드에 1비트를 추거하여 8비트를 사용(256개)

      - 표준화된 것은 아니고 개발자가 할당하고 싶은 문자를 할당할 수 있는 것이다. 따라서 다른 사람과의 공유가 어렵다.

  - 유니코드

    - 인터넷이 전 세계로 발전하면서 국가 간에 코드 체계가 다른 문제가 발생하였고 다국어 처리를 위해 또 다시 표준을 만들었는데 이를 유니코드라 한다.

    - 여러 체계가 존재한다.

      -utf-8(웹에서 주로 사용), uff-16(윈도우와 자바에서 사용), utf32(리눅스에서 사용) 등이 있다.



- 파이썬의 문자열 처리
  - 다른 언어와 달리 char 타입이 없다, char는 다른 언어에서 한 문자를 표현하기 위한 것이나 파이썬은 한 문자도 문자열에 넣으면 된다. 예를 들어 a라는 하나의 문자를 처리하기 위해서 다른 언어에서는 char 타입을 사용해야 하지만 파이썬은 그냥 'a'와 같이 해주면 된다.
  - 문자열은 요소값을 변경 할 수 없다(immutable).



## 패턴 매칭

- 패턴 매칭

  - 주어진 패턴과 동일한 패턴을 찾는 문제
    - 일반적으로 주어진 패턴을 P 또는 p로 정의하고 그 길이를 M또는 m으로 정의하며 패턴의 인덱스를 j로 정의한다
    - 또한 패턴을 찾을 텍스트를 T또는t로 정의하고 그 길이를 N또는 n으로 정의하며 텍스트의 인덱스를 i로 정의한다. 

  - Pythond의 경우 `str.find()` 메서드를 제공한다.


  ```python
  P = "ababd"
  M = len(P)
  T = "ababcababd"
  N = len(T)
  
  idx=T.find(P)  #해당 패턴이 시작하는 위치를 리턴해준다. 없을 경우 -1리턴
  print(idx, T[idx:idx+M]) # 12 asd
  ```

  - 브루트 포스로 찾기
    - 주어진 패턴과 본문을 일일이 비교하여 찾는 다. 
    - 시간복잡도는 O(MN)

  ```python
  P = "ababd"
  M = len(P)
  T = "ababcababd"
  N = len(T)
  
  i = 0
  j = 0
  while i < N:
      if T[i] == P[j]:
          i += 1
          j += 1
          if j == M:		# 패턴을 찾을 경우
              j = 0 		# 일치하는 패턴이 또 있을 수 있으므로 j를 0으로 초기화
      else:
          i = i-j+1		# 불일치가 발생하면 패턴의 인덱스와 텍스트의 인덱스를 모두 초기화한다.
          j = 0
  ```



- KMP알고리즘

  - 불일치가 발생한 텍스트 스트링의 앞 부분에 어떤 문자가 있는지를 알고 있으므로, 불일치가 발생한 앞 부분에 대하여 다시 비교하지 않고 매칭을 수행하는 방식이다. 
    - 실패 함수(failure function)를 만들고, 실패 함수를 사용해서 탐색하는 두 과정으로 나뉜다.
    - 실패 함수를 만드는데 O(N), 탐색에 O(M)이 걸려 시간복잡도는O(N+M)이다.
    - 알고리즘을 고안한 Knuth, Morris, Pratt 세 명의 이름 첫 글자를 따서 지었다.
  - 브루트 포스 방식의 문제점
    - 탐색 중에 일치하지 않는 character를 발견할 경우 패턴의 인덱스와 텍스트의 인덱스를 모두 초기화한다.
    - 이로 인해 불필요한 탐색이 발생하게 된다.

  - KMP 알고리즘 방식
    - 시작은 브루트 포스 방식과 동일하게 처음부터 비교한다.
    - 그러다 불일치가 발생하면 일정 부분을 건너 뛰고 탐색을 다시 시작한다.
    - 이때 건너뛰기 위해서 텍스트의 접미어와 패턴의 접두어가 같은 곳을 찾는다.

  ```
  a b a b | c a b a b d
  a b a b | d			# 불일치 발생
  	a b | a b d		# 텍스트의 접미어와 패턴의 접두어가 같은 곳으로 바로 이동
  ```

  - 실패 함수 만들기
    - LPS(Longest Prefix which is also Suffix) 배열을 만들기 위한 실패 함수를 작성한다.
    - LPS[i]는 패턴에서 i까지의 부분 문자열이 가진 prefix와 suffix들 중 일치하는 것의 길이이다.
    - 이 정보를 활용하여 불일치가 발생했을 때 어디서부터 다시 비교해야 하는지를 알아내는 데 사용한다.
    - 패턴 ababd를 예시로 보면 아래와 같다.

  | i    | sub string | prefix           | suffix           | prefix==sufix | LPS[i]     |
  | ---- | ---------- | ---------------- | ---------------- | ------------- | ---------- |
  | 0    | a          | -                | -                | -             | 0          |
  | 1    | ab         | a                | b                | -             | 0          |
  | 2    | aba        | a, ab            | a, ba            | a             | 1(len(a))  |
  | 3    | abab       | a, ab, aba       | b, ab, bab       | ab            | 2(len(ab)) |
  | 4    | ababd      | a, ab, aba, abad | d, bd, abd, babd | -             | 0          |

  - LPS를 활용하여 탐색하기
    - 텍스트 ababcababd에서 패턴 ababd를 찾을 것이다.
    - 부르트 포스 방식과는 달리 텍스트의 인덱스는 초기화하지 않고, 패턴의 인덱스만 변경하며, 패턴의 인덱스 역시 0으로 초기화하지 않고, 적절한 위치로 건너 뛰도록 변경한다.

  | i    | text[i] | j    | pattern[j] | text[i]==pattern[j] | action            |
  | ---- | ------- | ---- | ---------- | ------------------- | ----------------- |
  | 0    | a       | 0    | a          | T                   | i++, j+           |
  | 1    | b       | 1    | b          | T                   | i++, j+           |
  | 2    | a       | 2    | a          | T                   | i++, j++          |
  | 3    | b       | 3    | b          | T                   | i++, j++          |
  | 4    | c       | 4    | d          | F                   | j = lps[j-1] == 2 |
  | 4    | c       | 2    | a          | F                   | j = lps[j-1] == 0 |
  | 5    | a       | 0    | a          | T                   | i++, j++          |
  | 6    | b       | 1    | b          | T                   | i++, j++          |
  | 7    | a       | 2    | a          | T                   | i++, j++          |
  | 8    | b       | 3    | b          | T                   | i++, j++          |
  | 9    | d       | 4    | d          | T                   | i++, j++          |

  - 구현

  ```python
  def kmp_search(text, pattern):
      # 1. 실패 함수 만들기
      lps = [0] * len(pattern)
      length = 0  # 현재까지 접두사와 접미사가 일치하는 접두사(접미사)의 길이
  
      for i in range(1, len(pattern)):
          while length > 0 and pattern[i] != pattern[length]:
              length = lps[length - 1]    # 앞으로 돌아가서 더 짧은 접두사/접미사와 비교
          if pattern[i] == pattern[length]:
              length += 1
              lps[i] = length
  
      # 2. 패턴 검색하기
      result = []
      j = 0  # 패턴 인덱스
  
      for i in range(len(text)):  # 텍스트 인덱스
          while j > 0 and text[i] != pattern[j]:
              j = lps[j - 1]
          if text[i] == pattern[j]:
              j += 1
              if j == len(pattern):
                  result.append(i - j + 1)  # 패턴 발견된 시작 위치
                  j = lps[j - 1]
  
      return result
  ```



- 보이어-무어 알고리즘

  - 패턴의 인덱스만 오른쪽에서 왼쪽으로 비교, 텍스트와 패턴의 비교는 기존처럼 왼쪽에서 오른쪽으로.
  - 대부분의 상용 소프트웨어에서 채택하고 있는 알고리즘
  - 패턴에 오른쪽 끝에 있는 문자가 불일치 하고 이 문자가 패턴 내에 존재하지 않는 경우, 이동 거리는 패턴의 길이만큼 된다.
  - 보이어 무어 알고리즘은 KMP에서 살펴본 접미어 와 맨 마지막 단어 모두를 고려하는데 그 중 맨 마지막 단어만 고려하여 구현하는 심플한 버전을 보이어-무어-horspool 알고리즘 혹은 그냥 horspool알고리즘이라 부른다.

  ```
  T = "qwerqwerqwerasd"
  p = "asd"
  q w e r q w e r q w e r a s d
  a s d  #패턴의 오른쪽(d부터)부터 비교 시작e != d이고 패턴에 e가 없으므로 패턴의 길이 만큼 이동
        a s d  d!=w이고 패턴에 w가 없으므로 패턴의 길이만큼 이동
              a s d  똑같은 과정을 반복
        
   
  T = "qweqwewater"
  P = "water"
  q w e q w e w a t e r
        w a t e r #패턴의 오른쪽(r부터)부터 비교 시작, r과 a는 불일치하지만 패턴에 a가 존재는 함
              w a t e r  #a부터 비교 시작
  ```







# 그래프 

- 그래프는 아이템(사물 또는 추상적 개념)들과 이들 사이의 연결 관계를 표현한다.
  - 선형 자료구조(배열)나 트리로 표현하기 어려운 N:N 관계를 표현하기 용이하다.
  - 트리도 그래프의 일종이다(사이클이 없는 그래프).



- 점과 선으로 이루어진 자료 구조
  - 점을 정점(Node 또는 Vortex)이라고 부르고 선을 간선(Edge)라고 부른다.
  - 각 정점에 연결된 간선의 수를 차수(degree)라고 부른다.
  - 일반적으로 정점을 V로, 그 개수를 |V|로 표시하고, 간선을 M으로 간선의 개수를 |M|으로 표시함.
  - |V|개의 정점을 가지고 있는 그래프는 최대 `|V|(|V|-1)/2` 개의 간선이 존재.
  - degree(차수): 해당 노드에 연결된 엣지의 수(혹은 엣지 가중치의 합)



- sparse/dense graph
  - sparse graph: 노드의 수보다 엣지 수가 적은 그래프
  - dense graph: 노드 수보다 엣지 수가 큰 그래프



- 인접과 부속
  - 인접(adjacent): 두 노드가 하나의 엣지로 연결돼 있을 경우
  - 부속(incident): 두 노드가 인접할 경우 두 노드 사이의 엣지는 두 노드에 부속한다.



- 종류

  - 무향 그래프: 화살표가 없는 그래프, 동등한 관계, 양방통행이 가능한 관계
  - 유향 그래프: 화살표가 있는 그래프, 동등하지 않은 관계, 일방통행만 가능한 관계
  - 가중치 그래프: 그래프 사이의 관계에 가중치를 부여하는 그래프, 이동 시간, 비용 등
  - 사이클 없는 방향 그래프(DAG, Directed Acyclic Graph)
  - 완전 그래프: 정점들에 대해 가능한 모든 간선들을 가진 그래프
  - 부분 그래프: 원래 그래프에서 일부 정점이나 간선을 제외한 그래프



- 인접: 두 개의 정점 사이에 간선이 존재하면 서로 인접해 있다고 한다.
  - 완전 그래프에 속한 임의의 두 정점들은 모두 인접해 있다.
  - 만일 유향그래프이고 1->2라면 1번은 2번 정점에 인접해있다고 하지만 2번은 1번 정점에 인접해 있지 않다.



- 경로: 간선들을 순서대로 나열한 것
  - 단순 경로: 경로 중 한 정점을 최대 한 번만 지나는 경로(사이클이 X).

  - 사이클: 임의의 한 정점에서 출발해 자기 자신으로 돌아올 수 있는 경로, 시작한 정점에서 끝나는 경로

    - 임의의 세 노드가 서로 연결되어 있다고 해도 반드시 사이클이 있다고 할 수 는 없다. 무향 그래프일 때는 사이클이 존재하겠지만 유향그래프이면 사이클이 존재 할 수도 있고 하지 않을 수도 있다.



- 그래프의 표현

  - 간선의 정보를 저장하는 방식, 메모리나 성능을 고려해서 결정

  - 인접행렬: |V|*|V|크기의 2차원 배열을 이용해서 간선 정보를 저장

    - 두 정점을 연결하는 간선의 유무를 |V|x|V| 정방(정사각형) 행렬
    - 행 번호와 열 번호는 그래프의 정점에 대응
    - 두 정점이 인접되어 있으면 1, 그렇지 않으면 0으로 표현
    - 만일 |V|가 5,000이면 총 25,000,000의 값을 저장할 2차 배열이 만들어지는데 |E|가 100,000이면 간선의 수에 비해 불필요하게 큰 2차배열을 만든 셈이 된다. 이럴 경우 공간도 낭비되고 최악의 경우25,000,000개의 값을 모두 뒤져야 하기에 굉장히 비효율적이다. 즉 간선이 적은 그래프(희소 그래프)일수록 비효율적일 수 있다.
    - 진입차수와 진출차수를 모두 쉽게 구할 수 있다는 장점이 있다.
    - 무향 그래프일 때 i번째 행의 합 = i번째 열의 합 = V<sub>i</sub>의 차수( V<sub>i</sub>에 연결된 간선의 수)
    - 유향 그래프일 때 행 i의 합=V<sub>i</sub>의 진출 차수, 열 i의 합=V<sub>i</sub>의 진입 차수
  
    ```python
  간선이 있으면 1, 없으면 0
    v = [1,2,3]이고
  1-2
    1-3이면
    [[0,1,1] #1일 경우, 2,3과 간선이 있음
    [1,0,0]  #2일 경우  1과 간선이 있음
    [1,0,0]] #3일 경우  1과 간선이 있음
    
    
    #인접 행렬 구현
    '''
    input
    7 8
    1 2 1 3 2 4 2 5 4 6 5 6 6 7 3 7
    '''
    V, E = map(int,input().split())
    edges = list(map(int,input().split()))
    
    #인접행렬을 생성
    adj = [[0]*(V+1) for _ in range(V+1)]
    
    for i in range(E):
        s,e = edges[2*i], edges[2*i+1]
        #무향그래프일 경우
        adj[s][e]=1
        adj[e][s]=1
    ```
  
  - 인접 리스트: 각 정점에 대한 인접 정점들을 순차적으로 표현
  
    - 하나의 정점에 대한 인접 정점들을 각각 노드로 하는 연결 리스트로 저장 
    - 무방향 그래프일때  `노드 수 = 간선의 수 * 2`, `각 정점의 노드 수 = 정점의 차수`
    - 방향 그래프일 때 `노드 수=간선의 수`, `각 정점의 노드 수=정점의 진출 차수`
    - 진입 차수를 구하기 까다롭다.
  
    ```python
    #input값, 첫 번째 줄에는 순서대로 V와 E의 개수가 주어지고 그 아래로 E개의 간선이 주어진다.
    7 8
    1 2   #무향 그래프
    1 3
    2 4
    2 5
    4 6
    5 6
    6 7
    3 7
    
    V, E = map(int,input().split())
    G = [[] for _ in range(V+1)] #정점은 7까지 있으므로 0번 인덱스는 비워 놓고 7번가지 표현							  하려면 +1을 해줘야 한다.
    for _ in range(E):
        u,v = map(int, input().split())
        G[u].append(v) #유향그래프이고 만일 u에서 v로만 갈 수 있다면 u에다 만 추가 하면 된다.
        G[v].append(u) #무향그래프이기에 u,v를 모두 추가해야한다.
    
    print(G)
    for i in range(1,V+1):
        print(i,G[i])
    
        
    out
    [[], [2, 3], [1, 4, 5], [1, 7], [2, 6], [2, 6], [4, 5, 7], [6, 3]]
    1 [2, 3]  #1번 노드는 2,3번과 연결
    2 [1, 4, 5]
    3 [1, 7]
    4 [2, 6]
    5 [2, 6]
    6 [4, 5, 7]
    7 [6, 3]
    
    
    
    #딕셔너리로 구현
    '''
    input
    7 8
    1 2 1 3 2 4 2 5 4 6 5 6 6 7 3 7
    '''
    
    V, E = map(int,input().split())
    edges = list(map(int,input().split()))
    adj = {i:[] for i in range(1,V+1)}
    for i in range(E):
        s,e = edges[2*i], edges[2*i+1]
        #무향그래프일 경우
        adj[s].append(e)
        adj[e].append(s)
    print(adj)
    ```
  
  - 간선의 배열: 간선(시작 정점, 끝 정점)을 배열에 연속적으로 저장 



- 부분집합과 같이 가상의 상태공간트리를 탐색하며 모든 경우의 수를 고려해보는 완전검색 문제를 풀 때,   매 단계를 선택의 과정으로 생각하는 것이 좋다.
  - 예를 들어 [1,2,3]의 부분집합을 구할 경우 n번째 원소가 들어가는 경우와 들어가지 않는 경우의 2가지 경우의 수가 있다. 따라서 최종적으로 부분집합의 개수는 2<sup>n</sup>개가 있게 된다.
  - 가위바위보를 하는 경우를 생각해 보면 가위바위보는 경우의 수가 3개 이므로 n번 했을 때 나올 수 있는 경우의 수는 3<sup>n</sup>이 된다.
  - 즉 가상의 상태공간 트리는 가위를 선택한 경우, 바위를 선택한 경우, 보를 선택한 경우로 매 선택마다 나뉘게 된다.
  - 이렇게 어떤 선택들을 해야 모든 경우를 탐색할 수 있을지를 생각하면서 문제를 푸는 것이 좋다.



- 그래프 순회는 비선형 구조인 그래프로 표현된 모든 자료(정점)를 빠짐 없이 탐색하는 것을 의미한다.
  - 선형 구조의 경우 인덱스 순으로 순차적으로 탐색하면 되기에 탐색하는 것이 문제 되지 않는다. 그러나 비선형 구조는 어떻게 탐색해야 할지가 문제가 된다.
  - DFS, BFS의 두 가지 방법이 존재한다.
  - DFS(깊이 우선 탐색)
    - 시작 정점의 한 방향으로 갈 수 있는 경로가 있는 곳까지 깊이 탐색해 가다가 더 이상 갈 곳이 없게 되면 가장 마지막에 만났던 갈림길 간선이 있는 정점으로 되돌아와서 다른 방향의 정점으로 탐색을 계속 반복하여 결국 모든 정점을 방문하는 순회 방법
    - 스택을 사용
  - BFS(너비 우선 탐색)
    - 시작 정점의 인접한 정점들을 먼머 모두 차례로 방문한 후에, 방문했던 정점을 시작점으로 하여 다시 인접한 정점들을 차례로 방문하는 방식
    - 큐를 사용



## 서로소 집합

- 서로소 집합(Disjoint-set)

  - 서로소 또는 상호 배타 집합들은 서로 중복 포함된 원소가 없는 집합들이다.  다시 말해 교집합이 없다.

  - 집합에 속한 하나의 특정 멤버를 통해 각 집합들을 구분한다. 이를 대표자라 한다.

- 상호 배타 집합을 표현하는 방법

  - 연결리스트
  - 트리

- 상호배타 집합 연산

  > alogrithm 폴더에 구현 파일이 있다.

  - Make-Set(x): 원소 x를 유일한 원소로 하는 집합을 생성
  - Find-Set(x): x가 포함된 집합의 대표자를 리턴
  - Union(x,y): x가 포함된 집합과 y가 포함된 집합을 합친다. 대표자를 찾고 대표자들 끼리 연결한다.

- 연결리스트 구현.

  - 같은 집합의 원소들은 하나의 연결 리스트로 관리한다.
  - 연결 리스트의 맨 앞의 원소를 집합의 대표 원소로 삼는다.
  - 각 원소는 집합의 대표원소를 가리키는 링크를 갖는다(대표자 자신도 자신을 가리킨다.).

- 트리로 구현

  - 하나의 집합을 하나의 트리로 표현
  - 자식 노드가 부모 노드를 가리키며 루트 노드가 대표자가 된다(루트 노드도 자기 자신을 가리킨다).

  | 첨자(index) | 0    | 1    | 2    | 3    | 4    | 5    |
  | ----------- | ---- | ---- | ---- | ---- | ---- | ---- |
  | 정점        | a    | b    | c    | d    | e    | f    |
  | 부모        | 0    | 1    | 2    | 2    | 2    | 4    |

  - 위 표는 `a, b, d→c, e→c, f→e`를 표로 나타낸 것이다.
  - 위 표에서 첨자와 정점의 부모가 같으면 해당 정점이 대표자라는 것이다.

  ```python
  #disjoint_set
  def make_set(x):
      p[x]=x
  
  def find_set(x):
      if p[x]==x:
          return x
      else:
          return find_set(p[x])
  
  def union(x,y):
      p[find_set(y)]=find_set(x)
  
  
  N = 8
  p = [0]*(N+1)
  for i in range(1,N+1):
      make_set(i)
  
  union(7,8)
  union(6,7)
  union(5,6)
  union(4,5)
  union(3,4)
  union(2,3)
  union(1,2)
  print(p)
  
  
  out
  #최악의 경우
  [0,1,1,2,3,4,5,6,7]
  
  #이 경우 tree로 구현했음에도
  #1←2←3←4←5←6←7←8의 형태를 띄게 되어 tree로 구현한 의미가 없어진다. 
  ```

  - 문제점: 대표자를 찾기 위해서 루트노드까지 부모 노드를 계속 타고 이동하기에 재귀호출을 여러번 실행해야 한다. 중요한 것은 대표자(루트)가 어느 정점인가 하는 것이지 부모가 어느 정점인지가 아니다. 따라서 이를 빨리 하기 위해 `path compresion`을 사용한다.

    - 트리가 `a→b→c→d→e`로 연결이 되어 있다고 할 때 b에서 루트인 e까지 가기 위해서는 재귀를 3번 실행해야 하고 리턴도 3번 이루어 져야 한다. 
    - 이를 `path compresion`으로 바꿔서 표현하면 다음과 같다. `a→b, b→e, c→e, d→e `

  - 트리로 구현할 때 연산의 효율을 높이는 방법

    - Rank를 이용한 Union: 각 노드는 자신을 루트로 하는 subtree의 높이를 랭크라는 이름으로 저장한다. 두 집합을 합칠 때 rank가 낮은 집합을 rank가 높은 집합에 붙인다. 트리의 높이가 같을 경우 아무렇게나 붙여도 상관 없고 대표자가 된 정점의 랭크를 +1 해준다.

    - path compression: Find-Set을 행하는 과정에서 만나는 모든 조상 노드들이 직접 root(대표자)를 카리키도록 갱신한다(루트까지 가는 경로에 없는 노드들은 갱신되지 않는다.).

      | 노드 | a    | b    | c    | d    | e    | f    | g    | h    |
      | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모 | a    | a    | b    | a    | d    | e    | e    | e    |

      - 위와 같은 트리가 있고 h에서 a까지 가는 과정에서 path compression을 하면 아래와 같이 갱신된다.

      | 노드 | a    | b    | c    | d    | e    | f    | g    | h    |
      | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모 | a    | a    | b    | a    | a    | e    | e    | a    |

      - c, f, g는 h에서 a까지 가는 경로 상에 존재하지 않으므로 갱신되지 않는다. 
      - e, h는 부모 노드가 root로 갱신된다.

  ```python
  #disjoint_set_rank
  def make_set(x):
      p[x]=x
  
  def find_set(x):
      if p[x]==x:
          return x
      else:
          p[x]=find_set(p[x]) #부모 노드를 대표자로 갱신, path compresion
          return p[x]         #최초 인자로 들어온 x에서 대표자까지 가는 재귀를 거치면서 경로상에 있는 모든 노드의 부모 노드가 대표자가 됨
  
  def union(x,y):
      px = find_set(x) #px는 x의 대표자
      py = find_set(y) #py는 y의 대표자
      if rank[px]>rank[py]:   #px의 깊이가 py의 길이보다 크면
          p[py]=px            #px가 대표가 된다.
      else:                   #py의 깊이가 길거나 둘의 깊이가 같으면
          p[px]=py            #py가 대표가 된다.
          if rank[px]==rank[py]:  #만일 둘의 깊이가 같으면
              rank[py]+=1         #대표가 된 py의 깊이에 +1을 해준다.
  
  N = 8
  p = [0]*(N+1)
  rank = [0]*(N+1)  #트리의 깊이를 저장하는 배열
  for i in range(1,N+1):
      make_set(i)
  
  union(7,8)
  union(6,7)
  union(5,6)
  union(4,5)
  union(3,4)
  union(2,3)
  union(1,2)
  print(p)
  
  out
  [0,7,7,7,7,7,7,7,7]
  
  #rank와 path compresion을 적용하지 않은 위 코드와 동일한 코드지만 훨씬 효율적인 트리가 만들어진다.
  
  #깊이를 고려하지 않을 경우 2←3←4인 집합과 1 혼자인 집합이 있을 때
  #union(1,2)를 실행하면 1←2←3←4이 되지만
  #깊이를 고려하면  union(1,2)를 실행해도 1이 2의 자식 노드가 된다.
  ```






## 최소 신장 트리

- 그래프에서 최소 비용 문제
  - 모든 정점을 연결하는 간선들의 가중치의 합이 최소가 되는 트리
  - 두 정점 사이의 최소 비용의 경로 찾기
- 신장 트리: N개의 정점으로 이루어진 무방향 그래프에서 n개의 정점과 n-1개의 간선으로 이루어진 트리, 무향그래프의 서브 그래프들 중에서 모든 정점을 포함하는 트리, 트리이므로 사이클이 존재하지 않는다.
- 최소 신장 트리(MST,Minimum Spanning Tree): 무향 가중치 그래 프에서 신장 트리를 구성하는 간선들의 가중치의 합이 최소인 신장 트리
  - MST는 여러개 있을 수 있다.
- MST 표현
  - 그래프
  - 인접행렬
    - 기존 인접행렬이 1, 0으로 간선 유무를 표시했다면 MST를 표현할 때는 간선이 있을 경우 1 대신 가중치를 입력한다.
  - 인접리스트
    - 정점 번호와 가중치를 하나의 리스트로 묶어서 표현
  - 간선들의 배열
    - 시작점, 끝점, 가중치를 리스트에 저장
  - 부모 자식 관계와 가중치에 대한 배열(트리): 현재 정점, 부모 정점, 가중치를 저장



- Prim 알고리즘
  - 하나의 정점에서 연결된 간선들 중에 하나씩 선택하면서 MST를 만들어 가는 방식
    - 임의의 정점을 하나 선택해서 시작
    - 선택한 정점과 인접하는 정점들 중(즉 아래의 트리 정점들 중)에서 최소 비용의 간선이 존재하는 정점을 선택
    - 모든 정점이 선택될 때 까지 위 과정을 반복 
    
  - 서로소인 2개의 집합(2 djsjoint-sets)정보를 유지
    - 트리 정점들: MST를 만들기 위해 선택된 정점들, 이미 선택했으므로 다음 선택의 대상이 되지 않음
    - 비트리 정점들: 선택되지 않은 정점들, 다음 선택의 대상이 된다.
    - 모든 정점들이 트리 정점들이 될 때 까지(모든 정점이 선택될 때 까지 반복하는 것이 Prim알고리즘이다)
    
  - 과정

    - 데이터(괄호 안은 둘 사이의 가중치) 
      
      - 0 → 1(27), 2(26), 5(55), 6(46)  /  1→0, 2(16)  /  2→0, 1, 4(41), 6(20)  /  3 →4(29), 5(13)  / 4→2, 3, 5(35), 6(46)  /  5→0,3,4  /  6→0,2,4
      
    - 정점번호, 부모 정점, 가중치로 구성된 리스트를 생성

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     |      |      |      |      |      |      |      |
      | 가중치(key) |      |      |      |      |      |      |      |

      

    - 부모 노드와 가중치를 각기 -1과 무한대로 초기화

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | -1   | -1   | -1   | -1   | -1   | -1   |
      | 가중치(key) | ∞    | ∞    | ∞    | ∞    | ∞    | ∞    | ∞    |

      

    - 시작정점을 정하고 시작정점의 가중치를 0으로 설정, 이 상태에서 MST가 아니면서 가중치가 최소인 정점을 선택. 현재 선택된정점을 u라 부른다.

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | -1   | -1   | -1   | -1   | -1   | -1   |
      | 가중치(key) | 0    | ∞    | ∞    | ∞    | ∞    | ∞    | ∞    |

    - u를 MST로 선택(트리 정점들 집합에 넣는다)

      

    - u에 인접하고 아직 MST가 아닌 정점(w)들의 가중치와 u와 B 사이의 가중치를 확인 한 후, 정점의 가중치가 u와 w 사이의 가중치보다 크면 가중치를 u와 w 사이의 가중치로 갱신, 부모 정점을 u로 갱신

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | 0    | 0    | -1   | -1   | 0    | 0    |
      | 가중치(key) | 0    | 27   | 26   | ∞    | ∞    | 55   | 46   |

    - 갱신된 가중치들 중 가장 작은 값을 가지는 정점을 MST로 선택

      - 위 예에서 가장 작은 가중치를 가지는 정점은 2번 정점이다.

    - 모든 정점이 선택될 때까지 MST가 아니면서 가중치가 최소인 정점을 선택하는 단계부터 반복

      - 이제 2번 정점이 새로운 u가 되고 위의 과정을 반복하면 아래와 같이 된다. 
      - 이제 새로운 u는 1이 되고 모든 정점이 선택될 때 까지 이 과정을 반복한다.
      - 깊이 우선 탐색과 다르다. 한 정점을 선택했다고 해서 그 정점과 인접한 정점을 쭉 타고 가는 것이 아니라 현재 선택한 정점과 인접한 정점이 아니더라도 매번 갱신을 했을 때 가중치가 최소값이면 그 정점을 선택해서 다음 반복으로 넘어가는 것이다. 

      | 정점        | 0    | 1    | 2    | 3    | 4    | 5    | 6    |
      | ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
      | 부모(π)     | -1   | 2    | 0    | -1   | 2    | 0    | 2    |
      | 가중치(key) | 0    | 16   | 26   | ∞    | 41   | 55   | 20   |

  - 우선순위 큐로 구현하기도 한다.



- KRUSKAL 알고리즘
  - 정점을 선택하는 Prim과 달리 간선을 선택해서 MST를 찾는 알고리즘
  - 과정
    - 최초에 모든 간선을 가중치에 따라 오름차순으로 정렬
    - 가중치가 가장 낮은 간선부터 선택하면서 트리를 증가시킴, 사이클이 존재하면 다음으로 가중치가 낮은 간선 선택
      - 가중치가 가장 낮은 간선을 선택하기 위해 가중치에 따라 정렬(정렬 알고리즘에 따라 시간복잡도가 크게 상승할 수 있다)
      - 간선을 선택해서 정점이 연결되면 두 정점 중에 대표자를 선택한다. 
      - 사이클 존재 여부는 정점의 대표자가 같은지 여부로 판단하면 된다. 
    - n-1개의 간선이 선택될 때 까지 2번 과정을 반복



## 최단경로

- 최단경로: 간선의 가중치가 있는 그래프에서 두 정점 사이의 경로들 중에 간선의 가중치의 합이 최소인 경로
  - 간선의 가중치가 균일할 때(없을 때)는 BFS로 풀 수 있었다.
  - 가중치가 있을 경우 BFS로 풀 수 없다.
  - 최소신장트리와의 차이점은 최소신장트리가 인접한 모든 노드를 최소비용으로 <u>전부</u> 연결하는 것이라면 최단경로는 두 노드 사이의 거리가 최소인 경로를 찾는 것이다.



- 하나의 시작 정점에서 끝 정점까지의 최단 경로를 구하는 알고리즘(one to all)
  - 다익스트라(dijkstra) 알고리즘
    - 음의 가중치를 허용하지 않음
    - Greedy 적용
    - 시간복잡도는 O(N^2)
  - 벨만-포드(Bellman-Ford)알고리즘
    - 음의 가중치 허용
    - 완전검색(DP) 적용



- 모든 정점들에 대한 최단 경로(all pair)
  - 플로이드-워샬(Floyd-Warshall) 알고리즘
  - 완전검색(DP) 적용



- 다익스트라 알고리즘

  - 시작 정점에서 거리가 최소인 정점을 선택해 나가면서 최단 경로를 구하는 방식
    - MST의 Prim 알고리즘과 유사, 차이는 Prim은 무향 그래프에서만 사용 가능하지만 다익스트라는 무향, 유향 모두 사용 가능하다는 점과 가중치를 갱신하는 방식에서 차이가 있다.
  - 최적 부분 구조
    - 시작정점(s)에서 끝 정점(t) 까지의 최단 경로에 정점 x가 존재한다.
    - 이때, 최단경로는 s에서 x까지의 최단 경로와 x에서 t까지의 최단경로로 구성된다.
  - 간선 완화: Prim과 마찬가지로 최초 가중치를  무한으로 설정하고 실제 가중치를 구한 후 최초 가중치와 실제 가중치를 비교하여 더 작은 가중치로 갱신한다.
  - 정점들을 3개의 집합으로 구분
    - 출발점에서 최단경로를 찾은 정점들(간선완화 완료)
    - 출발점에서 아직 최단경로를 찾지는 않았으나 출발점에서 가는 경로를 적어도 하나 찾은 정점들(간선완화를 하지 않은 정점들)
    - 아직 출발점에서 가는 경로를 하나도 찾지 못한 정점들
  - 예시
    -  `1 - 2 - 3` 과 같은 경로가 존재할 때 1-2는 가중치가 1, 2-3은 가중치가 2라고 하고 1-3은 간선이 존재하지 않으므로 무한대라고 가정
    - 시작 위치를 1로 설정했을 때 갈 수 있는 경로 중에서 최단경로는 가중치가 1인 2번 정점이다. 따라서 다음 정점으로 2번을 선택
    - 2번 정점을 선택했을 때 시작 정점인 1번 정점에서 2번 정점을 거치면 3이라는 가중치로 3번 정점으로 갈 수 있다는 것을 알 수 있다.
    - 무한대보다는 3이 작으므로, 1-3의 가중치를 무한대에서 3으로 조정(간선 완화)
    - 다음 정점까지의 최단거리만 선택(탐욕적 선택)했음에도 최단 거리를 구하게 됨.





# Stack과 Queue

## Stack

- 물건을 쌓아 올리듯 자료를 쌓아 올린 형태의 자료구조
- 선형 구조: 자료 간의 관계가 1:1의 관계를 가진다(비선형구조는 1:N의 관계). 
- 마지막에 삽입한 자료를 가장 먼저 꺼낸다(후입선출).

- 스택의 사용을 위해 필요한 연산
  - push: 저장소에 자료를 삽입(저장)
  - pop: 저장소에서 자료를 꺼낸다(삽입한 자료의 역순)
  - isEmpty: 스택이 공백인지 아닌지 확인
  - peek: 스택의 top에 있는 원소를 반환하는 연산



- DFS 구현에 사용된다.

  - 반복으로 구현한 DFS

  ```python
  '''
  input
  7 8
  1 2 1 3 2 4 2 5 4 6 5 6 6 7 3 7
  '''
  def dfs(v):
      s = []
      visited = [0]*(V+1)
      s.append(v)
      while s:
          u = s.pop()
          if visited[u]==0:
              print(u,end = " ")
              visited[u]=1
              for i in range(1,V+1):
                  if adj[u][i]==1 and visited[i]==0:
                      s.append(i)
  
  V, E = map(int,input().split())
  edges = list(map(int,input().split()))
  
  #인접행렬을 생성
  adj = [[0]*(V+1) for _ in range(V+1)]
  
  for i in range(E):
      s,e = edges[2*i], edges[2*i+1]
      #무향그래프일 경우
      adj[s][e]=1
      adj[e][s]=1
  
  dfs(1)	# 1 3 7 6 5 2 4
  ```
  



- Monotonic stack

  - Element들을 non-decreasing 혹은 non-increasing 순서로 가지고 있는 stack을 의미한다.
    - 일반적인 stack과는 달리 monotonic stack은 stack내의 element들이 순서대로 정렬되어 있다는 것이 보장된다.
    - 일반적으로 특정 element보다 크거나 작은 다음 element를 찾기 위해 사용한다.
  - 구현 방법
    - 빈 stack을 초기화한다.
    - 배열을 순회하면서 stack에 element들을 추가하는데, 이 때 배열의 각 element마다 아래 과정을 수행한다.
    - Stack 내부의 element가 비어 있지 않고, stack의 top이 현재 element보다 크면 stack의 top을 pop한다.

  - 구현
    - 아래와 같이 구현한다.
    - 출력 결과를 확인해보면, stack내의 element들이 오름차순으로 정렬되어 있는 것을 확인할 수 있다.

  ```python
  def monotonic_increasing_stack(arr: list[int]):
      print("Monotonic Increasing Stack")
      stack = []
      for num in arr:
          while stack and stack[-1] > num:
              stack.pop()
          stack.append(num)
          print(stack)
  
  def monotonic_decreasing_stack(arr: list[int]):
      print("Monotonic Decreasing Stack")
      stack = []
      for num in arr:
          while stack and stack[-1] < num:
              stack.pop()
          stack.append(num)
          print(stack)
  
  monotonic_increaseing_stack([7, 5, 1, 8, 10, 0, 3, 4])
  """
  Monotonic Increasing Stack
  [7]
  [5]
  [1]
  [1, 8]
  [1, 8, 10]
  [0]
  [0, 3]
  [0, 3, 4
  """
  monotonic_decreaseing_stack([7, 5, 1, 8, 10, 0, 3, 4])
  """
  Monotonic Decreasing Stack
  [7]
  [7, 5]
  [7, 5, 1]
  [8]
  [10]
  [10, 0]
  [10, 3]
  [10, 4]
  """
  ```

  - 일반적으로 특정 element보다 뒤에 위치한 element중 더 첫 번째로 등장하는 큰(작은) element를 찾기 위해 사용한다.

  ```python
  arr = [7, 5, 11, 1, 8, 10, 0, 3, 4]
  stack = []
  next_greater_element = [-1] * len(arr)
  for i in range(len(arr)):
      num = arr[i]
      while stack and arr[stack[-1]] < num:
          idx = stack.pop()
          next_greater_element[idx] = num
      stack.append(i)
  print(next_greater_element)		# [11, 11, -1, 8, 10, -1, 3, 4, -1]
  ```







## Queue

- queue
  - 삽입과 삭제의 위치가 제한적인 자료구조(큐의 뒤에서는 삽입만 하고 큐의 앞에서는 삭제만 이루어진다)
  - 선입선출구조



- 큐의 사용을 위해 필요한 연산

  > 보통 함수의 이름을 아래와 같이 정의하여 사용한다. 함수명은 정의하는 사람 마음이지만 아래와 같이 정의했을 경우 모르는 사람이 봐도 Queue를 사용하고 있다는 것을 바로 알 수 있다는 장점이 있다.

  - enQueue(item): 큐의 뒤쪽(rear)에 원소를 삽입(rear+=1)
  - deQueue(): 큐의 앞쪽(front)에 원소를 삭제하고 반환(front+=1)
  - createQueue():공백 상태의 큐를 생성(front=rear=-1)
  - isEmpty():큐가 공백 상태인지 확인(front==rear)
  - isFull(): 큐가 포화 상태인지 확인(rear==n-1, n은 배열의 크기)
  - Qpeek(): 큐의 앞쪽에서 원소를 삭제 없이 반환



- BFS 구현에 사용된다.

  - 구현

  ```python
  from collections import deque
  
  def bfs(v):
      q = deque()
      visited = [0] * (V + 1)
      q.append(v)
      while q:
          u = q.popleft()
          if visited[u] == 0:
              print(u, end=" ")
              visited[u] = 1
              for i in range(1, V + 1):
                  if adj[u][i] == 1 and visited[i] == 0:
                      q.append(i)
  
  V, E = map(int, input().split())
  edges = list(map(int, input().split()))
  
  # 인접행렬을 생성
  adj = [[0] * (V + 1) for _ in range(V + 1)]
  
  for i in range(E):
      s, e = edges[2 * i], edges[2 * i + 1]
      # 무향그래프일 경우
      adj[s][e] = 1
      adj[e][s] = 1
  
  bfs(1)		# 1 2 3 4 5 7 6
  ```




- Queue와 관련된 자료 구조

  - 우선순위 큐
    - 먼저 삽입된 순서가 아닌 우선 순위가 높은 데이터를 먼저 꺼낸다.

  - 데크(Deque)
    - Queue 두 개를 좌우로 뒤집어서 붙인 구조.
    - Queue의 양쪽 끝에서 삽입과 삭제를 수행할 수 있도록 확장한 구조.




- Monotonic queue

  - Element들을 non-decreasing 혹은 non-increasing 순서로 가지고 있는 queue를 의미한다.
    - 따라서 queue의 가장 앞에는 가장 큰(작은) element가 위치하고, 가장 뒤에는 가장 작은(큰) element가 위치하게 된다.
    - 일반적으로 슬라이딩 윈도우에서 최대/최소값을 구하기 위해 사용한다.
    - 또한 DP 최적화에 사용되는 자료구조이다.
  - 구현
    - 맨 마지막에 추가된 element부터 제거하는 부분이 있어 queue가 아닌 stack이라고 생각할 수도 있지만, 해당 부분은 단조성을 유지하기 위한 것일 뿐이다.
    - 아래 구조에서 핵심적인 부분(queue의 FIFO 속성을 보여주는 부분)은 window 밖으로 벗어난 값을 queue에 추가된 순서대로 제거하는 부분이다.

  ```python
  from collections import deque
  
  def max_sliding_window(nums, k):
      result = []
      q = deque()  # Monotonic decreasing queue
  
      for i in range(len(nums)):
  				# window 밖으로 벗어난 값을 queue에 추가된 순서대로 제거한다(FIFO)
          if q and q[0] < i - k + 1:
              q.popleft()
  
          while q and nums[q[-1]] < nums[i]:
              q.pop()
  
          q.append(i)
  
          if i >= k - 1:
              result.append(nums[q[0]])
  
      return result
  
  nums = [1, 3, -1, -3, 5, 3, 6, 7]
  k = 3
  print(max_sliding_window(nums, k))  # [3, 3, 5, 5, 6, 7]
  ```

  

  
